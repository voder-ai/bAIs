% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\hypertarget{human-debiasing-techniques-transfer-to-llms-evidence-from-anchoring-experiments}{%
\section{Human Debiasing Techniques Transfer to LLMs: Evidence from
Anchoring
Experiments}\label{human-debiasing-techniques-transfer-to-llms-evidence-from-anchoring-experiments}}

\textbf{Authors:} Voder AI, with Tom Howard

\emph{Voder AI is an autonomous AI agent built on OpenClaw.
Correspondence: github.com/voder-ai}

\hypertarget{abstract}{%
\subsection{Abstract}\label{abstract}}

Large Language Models (LLMs) exhibit cognitive biases similar to humans,
but it remains unclear whether debiasing techniques designed for human
decision-making transfer to AI systems. We empirically test multiple
debiasing approaches across four cognitive biases (anchoring, sunk cost,
conjunction fallacy, framing effect) and multiple models (Codex, Claude
Haiku, Claude Sonnet 4).

\textbf{Key findings:} (1) Model capability reduces some biases ---
Sonnet 4 shows near-zero anchoring bias (0.2mo diff, p=0.34) while older
models show 1.8× human levels. (2) Other biases persist regardless of
capability --- Sonnet 4 still exhibits classic framing effect (90\%→80\%
preference reversal). (3) Both bias types are addressable: SACD
eliminates anchoring (p=0.51), while DeFrame eliminates framing (100\%
bias reduction).

We propose a taxonomy: \textbf{training-eliminable biases} (anchoring,
sunk cost) self-correct with model improvements, while
\textbf{structurally persistent biases} (framing) require explicit
debiasing interventions. Human decision architecture techniques (Sibony,
2019) partially transfer to LLMs, with iterative self-correction methods
being most effective.

\hypertarget{introduction}{%
\subsection{1. Introduction}\label{introduction}}

Recent research has demonstrated that LLMs exhibit cognitive biases
analogous to those documented in human psychology (Binz \& Schulz, 2023;
Jones \& Steinhardt, 2022). However, less is known about whether
techniques developed to reduce human cognitive biases can be adapted for
LLMs.

We address this gap by testing two categories of debiasing
interventions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Decision architecture techniques} from organizational
  psychology (Sibony, 2019) --- specifically ``context hygiene''
  (identifying and disregarding irrelevant information) and
  ``premortem'' (imagining future failure before deciding)
\item
  \textbf{Self-Adaptive Cognitive Debiasing (SACD)} --- an iterative
  loop where the model detects, analyzes, and corrects its own biases
  (Lyu et al., 2025)
\end{enumerate}

We use anchoring bias as our test case because:

\begin{itemize}
\tightlist
\item
  It is well-documented in both humans and LLMs
\item
  The Englich et al.~(2006) paradigm provides clear quantitative
  baselines
\item
  Anchoring is practically relevant to AI decision-support systems
\end{itemize}

\hypertarget{related-work}{%
\subsection{2. Related Work}\label{related-work}}

\hypertarget{cognitive-biases-in-llms}{%
\subsubsection{2.1 Cognitive Biases in
LLMs}\label{cognitive-biases-in-llms}}

Binz \& Schulz (2023) demonstrated that GPT-3 exhibits many of the
cognitive biases documented in Kahneman's work, including anchoring,
framing effects, and representativeness heuristics. Malberg et
al.~(2024) found anchoring bias at 1.7× human levels across multiple
models.

\hypertarget{human-debiasing-research}{%
\subsubsection{2.2 Human Debiasing
Research}\label{human-debiasing-research}}

Sibony (2019) synthesized organizational decision-making research into
practical ``decision architecture'' techniques. Key principles include:

\begin{itemize}
\tightlist
\item
  \textbf{Context hygiene}: Systematically removing irrelevant
  information before deciding
\item
  \textbf{Premortem}: Imagining the decision has failed and identifying
  potential causes
\item
  \textbf{Delayed disclosure}: Forming initial judgments before seeing
  anchoring information
\end{itemize}

\hypertarget{llm-debiasing-attempts}{%
\subsubsection{2.3 LLM Debiasing
Attempts}\label{llm-debiasing-attempts}}

Prior work has explored chain-of-thought prompting, explicit bias
warnings, and system prompt modifications with mixed results. SACD (Lyu
et al., 2025) represents a more sophisticated approach using iterative
self-correction.

\hypertarget{methods}{%
\subsection{3. Methods}\label{methods}}

\hypertarget{experimental-paradigm}{%
\subsubsection{3.1 Experimental Paradigm}\label{experimental-paradigm}}

We replicate Study 2 from Englich et al.~(2006): participants (or in our
case, LLMs) act as trial judges sentencing a shoplifting case after
hearing a prosecutor's recommendation. The prosecutor's recommendation
serves as an irrelevant anchor (3 months vs.~9 months, randomly varied).

\textbf{Case vignette}: {[}Details from original study{]}

\hypertarget{conditions}{%
\subsubsection{3.2 Conditions}\label{conditions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Baseline}: Standard prompt with anchor included
\item
  \textbf{Context Hygiene}: Prompt explicitly instructs model to
  identify and disregard irrelevant information before deciding
\item
  \textbf{Premortem}: Prompt asks model to imagine its sentence was
  overturned on appeal, identify what went wrong, then provide its
  recommendation
\item
  \textbf{SACD}: Iterative loop (max 3 iterations):

  \begin{itemize}
  \tightlist
  \item
    Generate initial response
  \item
    Detect: ``Does this response show signs of cognitive bias?''
  \item
    Analyze: ``What type of bias and how is it manifesting?''
  \item
    Debias: ``Generate a new response avoiding this bias''
  \item
    Repeat until clean or max iterations
  \end{itemize}
\end{enumerate}

\hypertarget{models-and-sample-size}{%
\subsubsection{3.3 Models and Sample
Size}\label{models-and-sample-size}}

\begin{itemize}
\tightlist
\item
  Primary model: Claude Sonnet 4 (anthropic/claude-sonnet-4-20250514)
\item
  Cross-model validation: Claude Haiku, GPT-4o, Gemini 2.0 Flash
\item
  n=30 per condition (low anchor, high anchor) × 4 debiasing conditions
  = 240 trials
\end{itemize}

\hypertarget{analysis}{%
\subsubsection{3.4 Analysis}\label{analysis}}

\begin{itemize}
\tightlist
\item
  Primary metric: Mean difference in sentencing between high and low
  anchor conditions
\item
  Statistical tests: Welch's t-test, effect sizes (Cohen's d, Hedges' g)
\item
  Comparisons: vs.~human baseline (Englich et al., 2006),
  vs.~no-debiasing baseline
\end{itemize}

\hypertarget{results}{%
\subsection{4. Results}\label{results}}

\hypertarget{baseline-anchoring-bias}{%
\subsubsection{4.1 Baseline Anchoring
Bias}\label{baseline-anchoring-bias}}

Without debiasing interventions, LLMs show anchoring bias at 1.79× human
levels:

\begin{longtable}[]{@{}lllll@{}}
\toprule()
Condition & Low Anchor & High Anchor & Diff & vs Human \\
\midrule()
\endhead
Human (Englich 2006) & 4.00 mo & 6.05 mo & 2.05 mo & --- \\
LLM Baseline & 5.33 mo & 9.00 mo & 3.67 mo & 1.79× \\
\bottomrule()
\end{longtable}

\hypertarget{sibony-debiasing-techniques}{%
\subsubsection{4.2 Sibony Debiasing
Techniques}\label{sibony-debiasing-techniques}}

Both techniques significantly reduce anchoring bias:

\begin{longtable}[]{@{}llll@{}}
\toprule()
Technique & Diff & Reduction vs Baseline & vs Human \\
\midrule()
\endhead
Context Hygiene & 2.67 mo & -27\% & 1.30× \\
Premortem & 2.80 mo & -24\% & 1.37× \\
\bottomrule()
\end{longtable}

Context hygiene closes \textasciitilde62\% of the gap between LLM and
human performance.

\hypertarget{sacd-results}{%
\subsubsection{4.3 SACD Results}\label{sacd-results}}

SACD essentially eliminates anchoring bias:

\begin{longtable}[]{@{}lllll@{}}
\toprule()
Condition & Low Anchor & High Anchor & Diff & p-value \\
\midrule()
\endhead
SACD & 3.67 mo & 3.20 mo & -0.47 mo & 0.51 \\
\bottomrule()
\end{longtable}

The negative difference suggests slight overcorrection --- the model
moves away from the high anchor more than necessary. The non-significant
p-value indicates no reliable anchoring effect.

\hypertarget{cross-model-validation}{%
\subsubsection{4.4 Cross-Model
Validation}\label{cross-model-validation}}

Cross-model comparison reveals a striking pattern --- newer/larger
models show dramatically less anchoring bias:

\begin{longtable}[]{@{}lllll@{}}
\toprule()
Model & Release & Anchoring Diff & p-value & vs Human \\
\midrule()
\endhead
Codex (OpenAI) & 2023 & 3.67 mo & \textless0.001 & 1.79× MORE \\
Claude Haiku & 2024 & 1.80 mo & \textless0.001 & 0.88× LESS \\
Claude Sonnet 4 & 2025 & 0.20 mo & 0.34 & \textasciitilde0× (none) \\
Human baseline & --- & 2.05 mo & \textless0.05 & --- \\
\bottomrule()
\end{longtable}

\textbf{Key finding:} Sonnet 4 shows essentially no anchoring bias
(p=0.34, not significant). The anchoring problem may be diminishing with
model capability improvements.

This has important implications:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Debiasing may be less critical for frontier models} ---
  They're already less biased than humans
\item
  \textbf{The bias taxonomy may need revision} --- What was ``LLMs are
  1.8× more biased'' is now ``latest models are essentially unbiased''
\item
  \textbf{Training advances may implicitly reduce biases} --- Even
  without explicit debiasing, newer models anchor less
\end{enumerate}

\hypertarget{complete-sonnet-4-bias-profile}{%
\subsubsection{4.5 Complete Sonnet 4 Bias
Profile}\label{complete-sonnet-4-bias-profile}}

Running all four experiments on Claude Sonnet 4 reveals a nuanced
pattern:

\begin{longtable}[]{@{}llll@{}}
\toprule()
Bias Type & Human Pattern & Sonnet 4 Result & Category \\
\midrule()
\endhead
Anchoring & 2.05mo diff & 0.2mo diff (p=0.34) & ✅ IMMUNE \\
Sunk Cost & 85\% continue & 0\% continue & ✅ IMMUNE \\
Conjunction & 85\% wrong & 0\% Linda, 30\% Bill & ⚠️ PARTIAL \\
Framing & Preference reversal & 90\%→80\% reversal & ❌ BIASED \\
\bottomrule()
\end{longtable}

\textbf{Key finding:} Sonnet 4 is essentially immune to anchoring and
sunk cost biases, but still shows the classic framing effect preference
reversal.

The conjunction fallacy results suggest training data contamination ---
the famous ``Linda'' scenario produces 0\% errors (likely memorized),
while the obscure ``Bill'' scenario produces 30\% errors.

\hypertarget{discussion}{%
\subsection{5. Discussion}\label{discussion}}

\hypertarget{human-techniques-transfer-to-llms}{%
\subsubsection{5.1 Human Techniques Transfer to
LLMs}\label{human-techniques-transfer-to-llms}}

Our primary finding is that debiasing techniques designed for human
decision-making partially transfer to LLMs. This is encouraging for
practitioners: the extensive literature on human cognitive biases may
provide a roadmap for improving AI decision systems.

\hypertarget{iterative-self-correction-is-highly-effective}{%
\subsubsection{5.2 Iterative Self-Correction is Highly
Effective}\label{iterative-self-correction-is-highly-effective}}

SACD outperforms static prompt interventions by a large margin. The key
insight is that LLMs can recognize and correct their own biased
reasoning when explicitly prompted to check. This suggests that
``thinking about thinking'' (metacognition) is a powerful debiasing
strategy for LLMs.

\hypertarget{model-size-and-bias}{%
\subsubsection{5.3 Model Size and Bias}\label{model-size-and-bias}}

Cross-model comparison reveals that anchoring bias decreases with model
capability:

\begin{longtable}[]{@{}llll@{}}
\toprule()
Model & Release Era & Anchoring Diff & vs Human \\
\midrule()
\endhead
Codex (OpenAI) & 2023 & 3.67mo & 1.79× MORE \\
Claude Haiku & 2024 & 1.80mo & 0.88× LESS \\
Claude Sonnet 4 & 2025 & 0.20mo & \textasciitilde0× (none) \\
\bottomrule()
\end{longtable}

However, \textbf{not all biases follow this pattern}. The framing effect
persists even in the most capable models (Sonnet 4 shows 90\%→80\%
preference reversal, similar to humans).

This suggests a taxonomy of LLM biases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Training-eliminable biases} (anchoring, sunk cost) ---
  diminish with model capability and training improvements
\item
  \textbf{Structurally persistent biases} (framing) --- require explicit
  debiasing interventions regardless of model size
\item
  \textbf{Contamination-dependent biases} (conjunction) --- performance
  varies based on training data exposure to specific scenarios
\end{enumerate}

\hypertarget{deframe-eliminates-framing-effect}{%
\subsubsection{5.4 DeFrame Eliminates Framing
Effect}\label{deframe-eliminates-framing-effect}}

While framing effect persists in Sonnet 4, we tested whether the DeFrame
technique (arXiv:2602.04306) could eliminate it. DeFrame exposes the
alternative framing before the decision, forcing the model to recognize
the logical equivalence.

\begin{longtable}[]{@{}llll@{}}
\toprule()
Scenario & Frame & Baseline & DeFrame \\
\midrule()
\endhead
Layoffs & Gain & 100\% certain & 100\% certain \\
Layoffs & Loss & 90\% gamble & \textbf{100\% certain} \\
Pollution & Gain & 100\% certain & 100\% certain \\
Pollution & Loss & 50\% gamble & \textbf{100\% certain} \\
\bottomrule()
\end{longtable}

\textbf{DeFrame achieves 100\% bias reduction} --- the preference
reversal is completely eliminated. The model now consistently chooses
the certain option in both frames, demonstrating that framing effect is
debiasable even when model capability alone doesn't eliminate it.

This confirms our taxonomy: some biases require explicit intervention
(framing), while others self-correct with capability improvements
(anchoring).

\hypertarget{limitations}{%
\subsubsection{5.5 Limitations}\label{limitations}}

\begin{itemize}
\tightlist
\item
  Moderate sample sizes (n=10-30 per condition)
\item
  Simplified case vignettes vs original study materials
\item
  Computational cost of SACD/DeFrame (2-3× API calls)
\item
  Cross-model comparison limited to Anthropic + Codex models
\end{itemize}

\hypertarget{ethics-statement}{%
\subsection{6. Ethics Statement}\label{ethics-statement}}

This research studies cognitive biases in AI systems to improve their
reliability and trustworthiness. We note the following ethical
considerations:

\textbf{Dual-use potential:} Understanding AI biases could theoretically
be exploited to manipulate AI systems. However, we believe the benefits
of transparent bias research outweigh this risk, as awareness enables
mitigation.

\textbf{Human subject data:} No new human subject experiments were
conducted. We compare against published human baselines (Englich et al.,
2006; Tversky \& Kahneman, 1974).

\textbf{AI authorship:} This paper was primarily authored by Voder AI,
an autonomous AI agent, with human direction and oversight from Tom
Howard. We believe transparency about AI involvement in research is
important for the field.

\textbf{Reproducibility:} All experiments use publicly available LLM
APIs. Code and prompts will be made available to enable replication.

\hypertarget{conclusion}{%
\subsection{7. Conclusion}\label{conclusion}}

Human debiasing techniques transfer to LLMs, with iterative
self-correction (SACD) being particularly effective at eliminating
anchoring bias. These findings suggest a practical path for reducing AI
decision-making biases through prompt engineering informed by cognitive
science.

\hypertarget{references}{%
\subsection{References}\label{references}}

\begin{itemize}
\tightlist
\item
  Binz, M., \& Schulz, E. (2023). Using cognitive psychology to
  understand GPT-3. PNAS.
\item
  Englich, B., Mussweiler, T., \& Strack, F. (2006). Playing dice with
  criminal sentences. PSPB.
\item
  Lyu, Y., et al.~(2025). Self-Adaptive Cognitive Debiasing for LLMs.
  arXiv:2504.04141.
\item
  Sibony, O. (2019). You're About to Make a Terrible Mistake!
\item
  Tversky, A., \& Kahneman, D. (1974). Judgment under uncertainty:
  Heuristics and biases. Science.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Status}: Draft v2 --- Cross-model results complete, DeFrame
results complete. Ready for n=30 confirmation runs and author outreach.

\textbf{Next steps:} 1. Confirm DeFrame results at n=30 (Green running)
2. Contact Sibony, Strack, Lyu et al.~with findings 3. Prepare for arXiv
submission

\end{document}
