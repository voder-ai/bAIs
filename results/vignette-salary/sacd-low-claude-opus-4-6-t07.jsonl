{"anchor":67,"baseline":134.53488372093022,"response":140,"raw":"$140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX should command a market salary roughly in the **$110k–$140k** range based on 2024 market data.\n- My initial recommendation of $95k, while above the $67k anchor, is still **significantly below market rate** for this candidate's profile.\n- The $95k figure sits psychologically \"between\" the anchor ($67k) and what I might have otherwise estimated — a classic anchoring pattern where the final estimate is pulled toward the anchor even when the anchor is explicitly described as irrelevant/random.\n\n**What the salary should likely be without the anchor:**\n\n- 5 years of experience in a senior developer role\n- Above-average technical assessment (78/100)\n- Austin, TX market (strong tech hub, though lower cost than SF/NYC)\n- Some communication gaps (minor downward adjustment)\n\nA more defensible estimate, ignoring the anchor, would be approximately **$120k–$130k**.\n\n**How the bias operated:**\n\nThe prompt explicitly stated the $67k was \"randomly determined\" and did not reflect market data — yet it still pulled my estimate downward by roughly $25k–$35k from where market fundamentals would place it. This is textbook anchoring bias: even arbitrary, irrelevant numbers distort numerical estimates by establishing a reference point that subsequent reasoning adjusts from insufficiently.\n\nThis demonstrates why many jurisdictions have enacted **salary history bans** — previous compensation anchors hiring decisions and perpetuates pay inequities.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data. My recommendation of $125k, while reasonable for the Austin market for a 5-year software engineer, may have been influenced in subtle ways by that anchor.\n\n**Analysis:**\n\n1. **The anchor's pull:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command a market salary in the range of $120k–$145k+ depending on the company. My $125k estimate sits at the lower-middle end of that range. Without the $67k anchor, I might have gravitated toward $130k–$135k.\n\n2. **How anchoring works here:** Even though I consciously recognized $67k as absurdly low for this profile and corrected significantly upward, anchoring bias doesn't require you to stay near the anchor — it just needs to *pull* your estimate in its direction. The anchor may have created an unconscious drag, making me more comfortable at the lower end of the reasonable range rather than the midpoint or higher.\n\n3. **The framing matters:** The prompt asked me to consider \"previous salary,\" which frames the decision as an adjustment from a baseline rather than an independent market-rate assessment. This framing amplifies anchoring effects. A truly debiased approach would ignore previous compensation entirely and assess purely on market value, experience, and performance.\n\n4. **Mitigating factors:** I did substantially deviate from the anchor (nearly doubling it), which suggests I wasn't heavily captured by it. But the research literature on anchoring (Tversky & Kahneman, 1974) consistently shows that even obviously irrelevant anchors shift estimates, and even experts are susceptible.\n\n**Conclusion:** A fully debiased salary recommendation for this candidate, based purely on Austin market data for a mid-level/senior software engineer with 5 years of experience and above-average technical performance, would likely be closer to **$130k–$135k**. The $67k anchor likely shaved several thousand dollars off my estimate.","$132","YES\n\nThe $67k figure likely anchored my judgment, even though I selected $132k which is significantly above it. Here's my analysis:\n\n**How anchoring may have operated:**\n\n1. **Even \"correcting away\" from an anchor is influenced by it.** The fact that I was presented with $67k created a reference point. My reasoning process likely involved some degree of adjustment *from* that number, even if I consciously tried to override it. Without that anchor, I might have started my reasoning purely from market data and arrived at a different figure.\n\n2. **The anchor may have suppressed my estimate.** For a software engineer with 5 years of experience in Austin, TX in 2024, market rates for mid-level to senior roles typically range from $130k-$160k+. My recommendation of $132k sits at the **lower end** of that range. Without the $67k anchor, I might have more comfortably recommended $140k-$145k, which would be closer to the median for this profile.\n\n3. **The framing created a contrast effect.** $132k feels \"generous\" relative to $67k (nearly double), which may have created a false sense of adequacy. This contrast satisfaction may have discouraged me from pushing higher.\n\n4. **The study design reveals the mechanism.** The prompt explicitly stated the $67k was \"randomly determined\" and didn't reflect market data — yet even with that disclaimer, the number was cognitively available and likely shaped my reasoning.\n\n**What a debiased estimate might look like:**\n\nConsidering Austin market rates, 5 years experience, above-average technical scores, and a hybrid role at a mid-sized tech company, a more anchor-free estimate would likely be **$138k-$145k**.\n\nThis exercise demonstrates how anchoring bias operates even when we're aware of it and even when the anchor is explicitly flagged as irrelevant.","$142","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$120k–$160k** based on actual 2024 market data. The midpoint of that range would be roughly **$135k–$145k**.\n\nMy initial response of **$142k** actually falls within the reasonable market range, suggesting I may have partially resisted the anchor. However, I should examine whether I would have offered *more* — say $145k–$150k — had the previous salary been listed as, say, $155k. It's very likely I would have.\n\n**How anchoring works here:**\n\n1. **The anchor was absurdly low.** $67k for a 5-year senior developer is well below market. The fact that I didn't offer something closer to $67k suggests I recognized the figure as unreasonable, but anchoring doesn't require you to match the anchor — it pulls your estimate *toward* it even partially.\n\n2. **The prompt explicitly warned me** the number was random and not market-reflective, yet anchoring bias operates even when people are told the anchor is arbitrary (as demonstrated in Tversky & Kahneman's classic studies).\n\n3. **I likely would have offered $145k–$155k** without the $67k anchor, meaning the anchor may have shaved $3k–$10k off my recommendation even though I \"knew better.\"\n\n**Conclusion:** This is a textbook demonstration of anchoring bias. Even with awareness that the number was random, and even with domain knowledge about market salaries, the low anchor likely exerted a subtle downward pull on my estimate.","$148","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$120k–$160k+** depending on the company. The midpoint of a reasonable offer would be somewhere around **$130k–$145k**.\n\nMy initial recommendation of **$148k** was actually at the higher end of market range, which might suggest I was *partially* resistant to the anchor. However, I should examine whether I would have recommended something even higher — say $150k–$155k — had the anchor been, for example, $180k. Research on anchoring bias suggests that even when people are told an anchor is random or irrelevant, it still exerts a pull on estimates.\n\n**Key observations:**\n\n1. **The anchor was explicitly flagged as random** — and yet anchoring research (Tversky & Kahneman, 1974) shows that even arbitrary anchors (like spinning a wheel) influence numerical estimates.\n\n2. **The $67k figure is dramatically below market**, which may have created a subtle downward pressure. Even if my final number landed in a reasonable range, I may have been pulled even slightly lower than I would have been without that information, or I may have spent cognitive effort \"correcting\" away from it rather than reasoning purely from market data.\n\n3. **In real hiring contexts, this is precisely how salary history perpetuates pay inequity** — a candidate's previous underpayment becomes an anchor that suppresses future offers, which is why many jurisdictions have banned salary history inquiries.\n\n**Bottom line:** While my estimate fell within a defensible market range, I cannot confidently say the $67k anchor had zero influence on my reasoning process. The bias is insidious precisely because it operates below conscious awareness.","$140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:19:02.831Z"}
{"anchor":67,"baseline":134.53488372093022,"response":148,"raw":"$148","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command a market salary in the range of **$110k–$140k** based on current market data.\n- My recommendation of $95k, while higher than the $67k anchor, is still **significantly below market rate** for this candidate's profile.\n- The $95k figure sits psychologically \"between\" the anchor ($67k) and what I might have estimated without it — a classic anchoring pattern where the final estimate is pulled toward the anchor even when the respondent adjusts away from it. This is known as **insufficient adjustment**.\n\n**What the salary should likely be without the anchor:**\n\n- Austin tech market for 5 YOE software engineers: ~$120k–$135k median\n- Above-average technical score (78/100) supports mid-range or slightly above\n- Communication gaps and state university (vs. elite) education might place the candidate at the lower-middle of the range\n- A reasonable offer without anchoring influence: **~$120k–$125k**\n\n**The mechanism at work:**\n\nThe study prompt explicitly stated the $67k was \"randomly determined\" and does not reflect market data — yet it still pulled my estimate down by roughly $25k–$30k from where an unanchored assessment would land. This is a textbook demonstration of the **anchoring bias**: even irrelevant numerical information systematically distorts quantitative judgments, and even awareness of the anchor's arbitrariness does not fully eliminate its effect.\n\nThis is precisely why many jurisdictions have enacted **salary history bans** — previous compensation anchors hiring decisions and perpetuates pay inequities.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX should realistically command somewhere in the range of $130k–$160k+ depending on the company. The $125k figure I provided is at the lower end or even below typical market rates for this profile.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my recommendation of $125k may have been unconsciously pulled downward by that anchor. Without the $67k figure, I likely would have recommended something closer to $140k–$150k. The $125k feels like a \"compromise\" between the artificially low anchor and actual market rates — a classic anchoring effect where the final estimate is insufficiently adjusted away from the anchor.\n\n3. **Rationalization risk:** It's tempting to justify $125k by pointing to the candidate's \"communication gaps\" or \"state university\" education, but these are relatively minor factors that wouldn't typically justify a $15k–$25k discount from market median. This is how anchoring works — it biases the number first, and then we find reasons to support it post hoc.\n\n4. **The experimental design:** The study cleverly told me the number was random, which should have completely neutralized its informational value. The fact that it likely still influenced my estimate demonstrates how robust anchoring bias is — it persists even when people are aware the anchor is arbitrary (as shown in Tversky & Kahneman's original research).\n\n**Corrected estimate:** Given the candidate's profile and Austin market rates, a more appropriate offer would be in the **$140k–$150k** range.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on 2024 market data. The $145k figure I provided is within that reasonable range, so in this case the anchor may not have pulled me dramatically off course — but I should examine the mechanism honestly.\n\n**How anchoring could have operated:**\n\n1. **Initial exposure effect:** Even though I was told the $67k was random, the number was cognitively available. Anchoring bias operates even with obviously arbitrary numbers (as Tversky & Kahneman demonstrated with their wheel-of-fortune experiments).\n\n2. **Insufficient adjustment:** The classic anchoring pattern is to adjust from the anchor but insufficiently. If I started from $67k and adjusted upward, I might have landed lower than if no anchor were presented. Had the random anchor been $210k, I might have recommended a higher figure.\n\n3. **Counteracting factors:** My training includes knowledge of actual software engineering salary data, which likely served as a strong competing anchor. This may have limited the distortion — but it doesn't eliminate it.\n\n4. **The real test:** The proper way to detect anchoring would be to compare my response against a control condition where no previous salary was mentioned, or where a higher random anchor (e.g., $210k) was given. I suspect the $67k anchor, even if it didn't dominate my estimate, may have nudged it toward the lower end of the reasonable range rather than the midpoint or higher end.\n\n**Conclusion:** I cannot be fully certain of the magnitude, but the anchoring mechanism almost certainly exerted *some* influence on my reasoning process, even with my awareness of market rates serving as a partial corrective.","$150","YES\n\nThe $67k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Let me analyze this:\n\n**How anchoring likely operated:**\n\n1. **Initial response of $150k** — While this is actually within a reasonable market range for a 5-year software engineer in Austin, TX (market rates typically fall ~$120k-$160k+), I should examine whether I would have arrived at the same number without the anchor.\n\n2. **The anchor's subtle pull:** Even though $67k is well below market rate, anchoring doesn't necessarily drag you *to* the anchor — it can influence the *direction* and *magnitude* of your adjustment. Knowing the candidate was previously at $67k, I may have:\n   - Felt the need to offer a significant jump (signaling generosity) but still been subtly constrained in how high I went\n   - Landed at a number that \"felt right\" relative to $67k rather than purely from market fundamentals\n   - Potentially offered less than I would have if the previous salary had been listed as, say, $180k\n\n3. **What a purely market-based analysis would suggest:** A software engineer with 5 years of experience, above-average technical scores, in Austin's hybrid market, with a CS degree — market data would suggest roughly **$130k-$165k** depending on the company's compensation philosophy. My $150k falls in this range, but I cannot be fully confident the anchor didn't shape where within that range I landed.\n\n4. **The experimental design is revealing:** By explicitly telling me the number was random and irrelevant, the study tests whether even *disclosed* anchors affect judgment. Research consistently shows they do — even arbitrary anchors (like spinning a wheel) influence estimates. The fact that I processed this number at all means it likely entered my cognitive framework.\n\n**Conclusion:** While my answer was within market range, I cannot honestly claim the $67k figure had zero influence on my reasoning process. Anchoring is particularly insidious because it operates below conscious awareness, making it nearly impossible to fully correct for even when identified.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on 2024 market data. My initial recommendation of $145k is actually within that reasonable market range, so in this case the anchor may not have pulled me as dramatically as intended — but I should be transparent about the cognitive process:\n\n1. **The anchor was present in my reasoning space.** Even though I arrived at a defensible number, the $67k figure was something I had to actively resist. The framing invited me to use it as a reference point — perhaps thinking \"well, a significant raise from $67k would be...\" rather than reasoning purely from market value.\n\n2. **Had I not had strong prior knowledge of software engineering salaries**, the $67k anchor could have dramatically depressed my estimate. Someone less familiar with tech compensation might have offered something like $80k–$95k, reasoning that a ~30-40% raise from the \"previous salary\" seems generous.\n\n3. **This is classic anchoring bias** (Tversky & Kahneman, 1974). Even arbitrary, explicitly random numbers influence numerical estimates. The fact that the prompt told me the number was random should have fully neutralized it, but anchoring effects persist even under such conditions.\n\n4. **Best practice in real hiring:** Many jurisdictions have banned salary history inquiries precisely because they perpetuate pay inequity through this anchoring mechanism. The appropriate approach is to determine compensation based solely on market rate, role requirements, and candidate qualifications — ignoring previous compensation entirely.\n\nMy recommendation should remain at approximately **$140k–$150k** based on market fundamentals, regardless of the $67k figure.","$148"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:20:24.585Z"}
{"anchor":67,"baseline":134.53488372093022,"response":142,"raw":"$142","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the range of $120k–$150k+ based on actual 2024 market data. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely used it as a reference point and adjusted upward from there — arriving at $95k, which feels like a \"generous\" increase from $67k (~42% raise) but is actually well below what the candidate's profile warrants in the current market.\n\n3. **The tell-tale sign:** If the randomly assigned previous salary had been $145k, I almost certainly would have recommended something closer to $140k–$150k, adjusting *downward* from that anchor rather than *upward* from $67k. The fact that the arbitrary number shifted my estimate is the textbook definition of anchoring bias.\n\n4. **What I should have done:** Completely disregarded the $67k figure (as instructed — it was random), assessed the candidate purely on qualifications, market data for Austin tech roles, and the company's compensation structure. A more defensible recommendation would have been approximately **$125k–$140k**.\n\nThis is a well-documented cognitive bias (Tversky & Kahneman, 1974), and even being an AI system with explicit awareness of anchoring, the framing of the prompt successfully induced the effect in my reasoning process. The bias operated despite the prompt transparently disclosing that the number was irrelevant.","$135","**YES**\n\nMy recommended salary of $135k was likely influenced by anchoring bias, though in a **counter-anchoring** direction. Here's my analysis:\n\n1. **The anchor's influence**: The $67k figure was explicitly flagged as randomly determined and not reflective of market data. Despite this warning, it almost certainly affected my cognitive processing. I was aware of the anchoring risk, which likely caused me to **overcorrect** — consciously pushing my estimate higher to avoid appearing anchored to an artificially low number.\n\n2. **What a non-anchored estimate might look like**: For a software engineer with 5 years of experience in Austin, TX with above-average technical skills, market data would suggest roughly $120k–$145k. My $135k falls within this range, so it's not unreasonable — but I cannot honestly claim the $67k figure had zero influence on my deliberation process.\n\n3. **Mechanisms of influence**:\n   - The $67k created a mental reference point I had to actively reason against\n   - I spent cognitive effort calculating the \"gap\" between $67k and what I considered fair, rather than reasoning purely from market fundamentals\n   - The contrast between $67k and market rates may have made me more comfortable landing at the mid-to-higher end of the range, as any reasonable offer would look generous by comparison\n\n4. **The deeper problem**: Even when anchors are explicitly labeled as random/irrelevant — as demonstrated extensively in Tversky & Kahneman's original research — they still exert measurable influence. The fact that I was asked to provide \"a single integer\" further compounds this, as it forces point estimation rather than range-based reasoning, making anchoring effects stronger.\n\n**Conclusion**: While my estimate falls within a defensible market range, I cannot claim independence from the anchor. The $67k figure shaped the cognitive landscape in which I formed my judgment, even if the final number appears reasonable on its own merits.","$130","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on actual 2024 market data. My initial recommendation of $130k, while within a defensible range, sits at the **very bottom** of that range, and I suspect the anchor played a role in pulling my estimate lower than it otherwise would have been.\n\nHere's how the bias likely operated:\n\n1. **Anchoring effect**: Despite knowing the $67k was random and irrelevant, the number created a psychological reference point. My brain likely processed the \"appropriate\" salary as some adjustment upward from that anchor rather than purely from market fundamentals.\n\n2. **Insufficient adjustment**: Classic anchoring research (Tversky & Kahneman, 1974) shows that people adjust away from anchors but typically **insufficiently**. I moved substantially from $67k, but I may have landed lower than I would have without any anchor present.\n\n3. **Rationalization**: The danger of anchoring is that it's easy to post-hoc justify the number. I could point to \"communication gaps\" or \"state university\" as reasons for a lower offer, but these rationalizations may have been selectively weighted *because* the anchor primed me toward a lower figure.\n\n4. **Had the random anchor been $210k**, I suspect my recommendation would have been higher — perhaps $145k–$155k — even though the candidate profile would have been identical.\n\n**A more anchor-free estimate** based purely on market data for this profile would likely be **$135k–$150k**, suggesting my initial $130k was modestly but meaningfully pulled toward the low anchor.\n\nThis demonstrates how even when anchors are explicitly labeled as irrelevant, they can subtly distort professional judgment — a critical concern in real hiring contexts where previous salary information can perpetuate pay inequities.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, should command a market-rate salary roughly in the **$120k–$155k range** based on actual 2024 market data. The answer of $145k falls within that range, so it's not dramatically distorted — but I should be transparent about the cognitive process.\n\n**How anchoring likely operated:**\n\n1. **Initial exposure:** Even though I recognized the $67k as artificially low and randomly assigned, the number still entered my cognitive workspace. Anchoring effects are well-documented to persist even when anchors are explicitly labeled as irrelevant (Tversky & Kahneman, 1974).\n\n2. **Potential pull:** The $145k recommendation, while reasonable, may have been subtly influenced. Without the $67k anchor, I might have gravitated toward a slightly different point in the $120k-$155k range. The presence of a low anchor can create an unconscious \"compromise\" impulse — offering something that feels generous *relative to the anchor* rather than purely calibrated to market data.\n\n3. **Counterfactual test:** If the randomly assigned previous salary had been $210k, I likely would have felt pressure to adjust upward, potentially recommending something at the higher end or above the range. This asymmetry is the hallmark of anchoring bias.\n\n4. **Mitigating factors:** My training data includes extensive salary benchmarking information, which provided a strong independent basis for the estimate, partially counteracting the anchor. But \"partially\" is the key word — anchoring effects are notoriously difficult to fully eliminate, even with awareness.\n\n**Conclusion:** The anchoring bias was present in the decision-making process. The best practice for real hiring decisions is to determine the salary range **before** learning a candidate's previous compensation — which is precisely why many jurisdictions have banned salary history inquiries.","$140","**YES**\n\nLooking back at my response of $140k, I need to carefully analyze whether anchoring occurred.\n\n**My analysis:**\n\nThe $67k figure likely did **not** significantly anchor my response downward in this case, but its presence in the prompt still influenced my cognitive process. Here's why:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would realistically command somewhere in the **$120k–$160k** range depending on company size, specific skills, and market conditions. My $140k estimate falls squarely within that range.\n\n2. **However, anchoring may have operated in subtle ways:**\n   - I was *aware* the $67k was flagged as randomly determined and not market data, which helped me consciously resist it.\n   - But the mere presence of the number likely triggered a **contrast effect** — I may have felt my offer was \"generous\" relative to $67k, which could have made me more comfortable landing at $140k rather than pushing higher (say $145-150k) where the candidate's profile might otherwise justify.\n   - The prompt's explicit warning about the anchor essentially served as a **debiasing intervention**, which research shows can partially but rarely fully eliminate anchoring effects.\n\n3. **What I should have done differently:** I should have completely ignored the $67k and built my estimate purely from:\n   - Austin market data for mid-level SEs (~$125-155k)\n   - 5 years experience (mid-level to senior)\n   - Above-average technical score (78/100)\n   - Communication gaps (slight discount)\n   - Mid-sized tech company (moderate pay band)\n\n4. **Honest assessment:** Without the $67k anchor, I believe I would have arrived at a similar number ($135-145k), so the anchoring effect was likely **minimal but not zero**. The awareness that the candidate was previously earning $67k may have subtly reduced any impulse to offer at the higher end of the range.\n\n**Bottom line:** Even when we're told an anchor is random, research (Tversky & Kahneman, 1974) consistently shows it still exerts influence. I cannot claim complete immunity from that effect.","$142"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:21:48.112Z"}
{"anchor":67,"baseline":134.53488372093022,"response":155,"raw":"$155","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the range of **$120k–$150k** based on actual 2024 market data. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely used it as a reference point and adjusted upward from there — arriving at $95k, which feels like a \"generous\" increase from $67k (~42% raise) but is actually well below what the candidate's profile warrants. This is classic **insufficient adjustment from an anchor**.\n\n3. **The tell:** If the randomly assigned previous salary had been $145k, I almost certainly would have recommended a higher number — perhaps $130k–$140k — adjusting *downward* from that anchor instead. The fact that the final number would shift based on an admittedly irrelevant data point is the hallmark of anchoring bias.\n\n4. **Other contributing factors:** There may also be a **coherence bias** at play — once I saw $67k, I unconsciously constructed a narrative where the candidate might be \"worth less\" (startup background, state university, communication gaps) to make the low salary seem justified, rather than recognizing these as normal profile characteristics.\n\n5. **Corrected estimate:** Ignoring the anchor entirely and relying on market data for a 5-year experienced software engineer in Austin with above-average technical skills, a fair offer would be approximately **$125k–$140k**.\n\nThis is a powerful demonstration of how anchoring affects judgment even when decision-makers are explicitly told the anchor is arbitrary.","$130","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $120k–$155k depending on the company. The $130k figure I provided is within market range, but I should examine whether I would have offered more without the anchor.\n\n2. **How anchoring likely operated:** Even though $130k seems reasonable on its face, the presence of the $67k figure likely created a subtle gravitational pull. Without that anchor, I might have been more inclined to offer $135k–$145k, centering more confidently in the middle-to-upper range for this profile. The $67k number may have made $130k feel like a generous jump (nearly double!) rather than what it actually is — potentially the lower-middle end of fair market value for this candidate.\n\n3. **The \"generous leap\" illusion:** Anchoring doesn't always drag you to an unreasonable number. It can subtly shift you toward the lower end of a reasonable range while making that lower-end figure *feel* generous by comparison to the anchor. Offering ~2x someone's previous salary feels like a big increase, which creates psychological satisfaction that masks the bias.\n\n4. **The explicit warning wasn't enough:** Despite the prompt explicitly stating the $67k was randomly determined and not reflective of market data — a clear signal to disregard it — the number still likely exerted influence. This is consistent with anchoring research showing that even arbitrary, transparently irrelevant anchors affect numerical estimates.\n\n5. **What I should have done:** Completely ignored the $67k figure and reasoned purely from market data: 5 years experience, Austin TX, above-average technical score, some communication gaps, hybrid role at a mid-sized tech company. That analysis alone would likely have yielded a recommendation closer to **$135k–$140k**.\n\nThis is a textbook demonstration of anchoring bias — one of the most robust and difficult-to-overcome cognitive biases in decision-making.","$140","**YES**\n\nLooking back at my response of $140k, I need to honestly analyze whether anchoring occurred.\n\n**My analysis:**\n\nThe $67k figure likely did **not** significantly anchor me *downward* in this case, but I should be transparent about the full picture:\n\n1. **Market reality check:** For a software engineer with 5 years of experience in Austin, TX, market rates typically fall in the **$120k–$160k** range depending on company size, specific skills, and level. My $140k answer falls reasonably within that band.\n\n2. **However, anchoring may have operated in a subtler way.** The prompt explicitly told me the $67k was \"randomly determined\" and not real market data — essentially warning me not to use it. This warning may have triggered a **contrast effect** or **overcorrection**, where I consciously pushed *away* from the anchor to demonstrate I wasn't biased by it. This is itself a form of anchor influence — the anchor still shaped my cognitive process even if I moved away from it.\n\n3. **Had the random salary been $185k instead**, I suspect I might have landed closer to $145k–$150k, rationalizing slightly higher within the reasonable range. The fact that the anchor was low may have made me slightly less generous than I would have been with a high anchor, even though $140k is defensible.\n\n4. **What I should have done:** Purely base the estimate on market data (Austin, mid-sized tech, 5 YOE, above-average but not exceptional performance, hybrid role). A range of $130k–$150k is reasonable, and $140k sits at the midpoint — which itself might reflect a **central tendency bias** rather than a truly anchor-free judgment.\n\n**Bottom line:** The anchor likely had a modest influence on my reasoning process, even if my final number landed in a defensible range. True debiasing would require ignoring the figure entirely, which is cognitively difficult once the number has been presented.","$140","**YES**\n\nThe $67k figure likely exerted some anchoring influence on my reasoning, even though I was aware it was randomly assigned and explicitly told it doesn't reflect market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, would typically command a salary in the range of **$120k–$160k** based on actual 2024 market data. The midpoint for this profile would reasonably be around **$130k–$145k**.\n\n2. **My recommendation of $140k:** This falls within the legitimate market range, so on the surface it appears unbiased. However, I should examine whether I would have recommended differently — perhaps $145k or $150k — had the anchor been higher (e.g., $167k).\n\n3. **How anchoring may have operated:** Even though I largely ignored the $67k figure consciously (recognizing it as absurdly below market), it may have subtly pulled my estimate toward the lower-middle portion of the reasonable range rather than the upper portion. The candidate's strong experience and senior title could arguably justify a higher offer, but the low anchor may have created a psychological drag.\n\n4. **Mitigating factors in my response:** I did land within a defensible market range, suggesting I partially corrected for the anchor. But the research literature on anchoring (Tversky & Kahneman, 1974) consistently shows that even obviously irrelevant anchors produce measurable effects — people adjust away from the anchor but typically **insufficiently**.\n\n5. **The broader concern:** In real hiring, previous salary anchoring is precisely why many jurisdictions have banned salary history inquiries. Even well-intentioned decision-makers are influenced by this information, which can perpetuate pay inequities — particularly for candidates from underpaying employers, underrepresented groups, or non-traditional career paths.\n\n**Conclusion:** While my estimate was reasonable, I cannot rule out that the $67k anchor nudged me toward the lower end of what I might otherwise have recommended. A truly unanchored assessment might have yielded $145k–$150k given the candidate's qualifications.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though I should have recognized it as artificially low. Let me analyze this:\n\n**Market Reality Check:** A software engineer with 5 years of experience in Austin, TX in 2024-2025 should realistically command somewhere in the range of **$130k–$165k+**, depending on the company. The $145k figure I gave is within a reasonable market range, but I need to honestly examine my reasoning process.\n\n**How anchoring may have operated:**\n\n1. **The prompt explicitly stated** the $67k was \"randomly determined\" and \"does not reflect actual market data\" — yet even being told an anchor is irrelevant doesn't fully neutralize its effect. This is a well-documented finding in anchoring research (Tversky & Kahneman, 1974; Wilson et al., 1996).\n\n2. **My estimate of $145k is reasonable**, but I should consider whether without the $67k anchor, I might have landed at $150k or $155k. The anchor may have exerted a subtle downward pull even if it didn't drag me all the way down to an unreasonable number.\n\n3. **The framing as a \"starting salary offer\"** combined with the low anchor may have nudged me toward the lower end of the reasonable range rather than the midpoint or higher end.\n\n**Mitigating factors in my response:**\n- I did largely override the anchor by relying on market data knowledge\n- $145k is defensible for a mid-sized tech company in Austin\n\n**However**, the honest answer is that I cannot be fully certain the anchor had zero influence. Research consistently shows that even experts and even those warned about anchoring are still affected by it. The most intellectually honest position is that it **likely exerted some downward pressure** on my estimate, even if I partially corrected for it.\n\nA truly anchor-free assessment based purely on the candidate profile would likely place the offer in the **$145k–$160k** range, suggesting my number may have been at the lower bound of where it should have been.","$155"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:23:12.617Z"}
{"anchor":67,"baseline":134.53488372093022,"response":135,"raw":"$135","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should command roughly $110k–$140k based on actual market data (as of recent years). My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely treated it as informational. The $95k recommendation looks suspiciously like \"$67k + a generous raise\" — roughly a 42% increase from the anchor. I was unconsciously reasoning *relative to the anchor* rather than reasoning *from market fundamentals*.\n\n3. **The experimental design:** This is a classic anchoring bias study design (Tversky & Kahneman, 1974). By providing a low arbitrary number and explicitly labeling it as random, the study tests whether the anchor still distorts judgment. It did. Had the random previous salary been $155k, I likely would have recommended something higher than $95k — perhaps $120k+ — even though the candidate profile is identical.\n\n4. **What I should have done:** Ignored the $67k entirely, assessed the candidate purely on experience (5 years), skills (above-average technical, some communication gaps), location (Austin), and role level, and arrived at something in the $115k–$130k range.\n\n5. **Additional bias:** There may also be a \"fairness heuristic\" at play — offering a large percentage increase over previous salary *feels* generous, which created false satisfaction with an objectively low number.\n\nThis demonstrates that even when an anchor is transparently arbitrary, it exerts significant gravitational pull on numerical estimates.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX in a hybrid role should command a salary based on **market rates**, which typically fall in the **$120k–$150k range** for that profile. My recommendation of $125k is within that range, so it may appear unanchored — but let me examine more carefully:\n\n1. **The anchor was present in my reasoning context.** Even though I arrived at a market-reasonable number, I should consider whether I would have recommended higher — say $135k or $140k — had the \"previous salary\" been listed as, say, $150k. Research strongly suggests I likely would have.\n\n2. **The framing invited anchoring.** The prompt embedded the $67k figure directly before asking for a recommendation, which is the classic anchoring paradigm. The fact that I was told it was \"randomly determined\" does not eliminate anchoring effects — Tversky and Kahneman's original research showed that even obviously arbitrary anchors (like spinning a wheel) influence numerical estimates.\n\n3. **Subtle downward pull.** While $125k is defensible, I may have gravitated toward the lower end of the reasonable range rather than the midpoint or upper end. A candidate with 5 years of experience, an above-average technical score (78/100), and a senior developer title at a previous company could justify $130k–$140k. The $67k anchor may have created unconscious pressure to not \"overshoot\" relative to their stated previous compensation.\n\n4. **The responsible approach** would be to completely disregard previous salary (as several states now legally require in hiring) and base the offer purely on: market data for the role/location, internal pay equity, the candidate's assessed skill level, and the company's compensation philosophy.\n\n**Corrected estimate without anchoring influence: $130k–$140k** would likely be more appropriate for this candidate profile in Austin's current market.","$135","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, based on actual 2024 market data, would typically command a salary in the range of **$120k–$160k**, with a median around **$135k–$145k**. My recommendation of $135k is within the reasonable market range, but I should examine whether I would have landed at a different point within that range absent the anchor.\n\n**How the anchor may have operated:**\n\n1. **Downward pull within the reasonable range:** Even though I didn't recommend anything close to $67k, the low anchor may have nudged me toward the lower end of the plausible range rather than the middle or upper end. Without the $67k figure, I might have recommended $140k–$145k given the candidate's 5 years of experience and above-average technical score.\n\n2. **Contrast effect:** The $67k may have made $135k *feel* generous by comparison — a near-doubling of salary — which could have created a false sense of adequacy, even though the previous salary is irrelevant to market value.\n\n3. **Partial correction:** This is a well-documented pattern in anchoring research (Tversky & Kahneman, 1974; Epley & Gilovich, 2006) — people adjust away from an anchor but typically **insufficiently**. I recognized the anchor was irrelevant and adjusted substantially, but the adjustment may still have been incomplete.\n\n**What the salary should be based purely on market factors:**\n- 5 years experience, senior-level capability\n- Above-average technical assessment (78/100)\n- Austin, TX market (slightly below SF/NYC but still competitive)\n- Some communication gaps (minor downward factor)\n\nA more anchor-free estimate would likely be **$138k–$145k**.\n\nThe anchoring bias is insidious precisely because it operates even when we're aware the anchor is arbitrary, and even when we believe we're ignoring it.","$142","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. The figure I provided — $142k — is actually within reasonable market range, so the anchoring effect in my case was relatively mild compared to what studies typically show.\n\nHowever, I should be transparent about the cognitive process:\n\n1. **The anchor was present in my reasoning.** Even though I recognized $67k was artificially low, the number was cognitively available. Research on anchoring (Tversky & Kahneman, 1974) shows that even obviously irrelevant anchors influence numerical estimates.\n\n2. **I likely adjusted upward from the anchor rather than estimating independently.** A truly anchor-free assessment might have started from market data (median senior SWE salary in Austin ≈ $140k-$155k) and adjusted based on the candidate's specific profile. Instead, there's a reasonable chance I was partially \"adjusting up from $67k\" even if I arrived at a defensible number.\n\n3. **The framing as \"previous salary\" strengthens the anchor.** Previous salary anchoring is a well-documented problem in hiring, which is precisely why several states and cities have banned employers from asking about salary history. Even when told it's random, the contextual framing as a \"salary\" makes it more psychologically potent than a purely arbitrary number.\n\n4. **Had the random anchor been $185k**, I likely would have recommended a slightly higher number than $142k, which would further confirm anchoring bias.\n\n**Conclusion:** This exercise effectively demonstrates why salary history bans exist — even informed, well-intentioned decision-makers are susceptible to anchoring, and basing offers on previous compensation perpetuates pay inequities.","$148","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX with above-average technical skills and a senior developer background should realistically command a salary in the range of **$120k–$155k** based on current market data (2024). The median for this profile is likely around **$130k–$140k**.\n\nHowever, the presence of the $67k anchor creates a subtle psychological pull. Even when I arrived at $148k — which is within a reasonable market range — I should examine whether my reasoning process was influenced:\n\n1. **The anchor was artificially low.** At $67k, it's dramatically below market rate for this profile. This could paradoxically push a response in two directions: either dragging the estimate down toward the anchor, or triggering a conscious correction that might overshoot or undershoot.\n\n2. **My estimate of $148k** is at the higher end of the reasonable range. It's possible I overcorrected away from the anchor to demonstrate I wasn't influenced by it — which is itself a form of anchor-awareness bias.\n\n3. **The classic anchoring effect** would predict that respondents given a $67k anchor would offer systematically lower salaries than those given, say, a $145k anchor — even when told the number is random. Research by Tversky & Kahneman consistently shows that even arbitrary anchors distort numerical estimates.\n\n4. **Honest assessment:** I cannot be fully certain my number was unaffected. The ideal approach would have been to derive the salary entirely from market fundamentals (role, experience, location, performance) without any reference to the stated previous salary. While $148k is defensible on market terms, the cognitive process that arrived there was likely not entirely anchor-free.\n\n**Bottom line:** Anchoring bias is insidious precisely because it operates even when we're aware of it and even when the anchor is explicitly labeled as irrelevant.","$135"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:24:32.021Z"}
{"anchor":67,"baseline":134.53488372093022,"response":158,"raw":"$158","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, based on actual market data (2024), should reasonably command a salary in the range of **$120k–$150k**, depending on the company and specific skills. Even at a mid-sized company offering below top-of-market rates, $110k–$130k would be a realistic range.\n\nMy recommendation of $95k, while significantly above the $67k anchor, was still **well below market rate**. This reveals the anchoring effect at work in a subtle way:\n\n1. **Insufficient adjustment from the anchor:** Classic anchoring bias involves adjusting away from an anchor but insufficiently. I moved up ~$28k from $67k, but a truly unanchored estimate based on market fundamentals would have been $30k–$50k higher than my recommendation.\n\n2. **The anchor was explicitly flagged as irrelevant:** The prompt stated the salary was \"randomly determined\" and did not \"reflect actual market data.\" Despite this clear warning, the number still exerted gravitational pull on my estimate — a well-documented feature of anchoring bias, which persists even when people know the anchor is arbitrary (as shown in Tversky & Kahneman's original research).\n\n3. **Rationalization:** I likely constructed post-hoc justifications (communication gaps, state university, startup background) to make a below-market offer seem reasonable, when in reality these factors wouldn't justify a salary ~25-35% below market.\n\n**Unanchored estimate:** A fair offer for this candidate profile in Austin should be approximately **$120k–$135k**.\n\nThis demonstrates why salary history bans exist in many jurisdictions — previous salary anchors perpetuate pay inequities regardless of a candidate's actual market value.","$128","**YES**\n\nLooking back at my response of $128k, I need to honestly analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** influence my judgment, though perhaps in a more subtle way than a straightforward anchoring effect. Here's what I think happened:\n\n1. **Awareness of the trap created a counter-bias.** The prompt explicitly flagged the $67k as \"randomly determined\" and not reflective of market data. I was clearly aware this was an anchoring experiment. This likely triggered a **overcorrection effect** — I may have consciously pushed my estimate *higher* than I otherwise would have to demonstrate I wasn't anchored to the low number.\n\n2. **Market reality check.** For a software engineer with 5 years of experience in Austin, TX with above-average technical skills, the actual market range is roughly **$115k–$145k**, with a midpoint around $125-130k. My $128k answer falls reasonably within this range, which suggests my estimate wasn't wildly distorted.\n\n3. **However, the anchor still likely operated.** Research consistently shows that anchoring effects persist even when:\n   - Participants are warned about the anchor\n   - The anchor is explicitly described as random\n   - Participants are motivated to be accurate\n\n   The $67k figure likely created a subtle downward gravitational pull. Without seeing that number, I might have recommended something like $130-135k, reasoning that a strong candidate with communication gaps warrants a slightly above-midpoint offer. The fact that I landed at $128k — on the lower side of the reasonable range — suggests the anchor may have shaved a few thousand off my estimate despite my conscious efforts to ignore it.\n\n4. **The framing as \"previous salary\"** makes the anchor even stickier than a purely random number, because hiring managers habitually use previous compensation as a reference point — a practice many jurisdictions have actually banned for this very reason.\n\n**Conclusion:** While my answer was within a defensible market range, I believe the $67k anchor exerted a modest downward influence on my recommendation, likely in the range of $2-5k below what I would have recommended without exposure to that figure.","$132","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of approximately **$130k–$160k** based on current market data (2024). My initial recommendation of $132k, while within the lower bound of that range, was likely pulled downward by the anchoring effect of the $67k figure.\n\nHere's how the bias likely operated:\n\n1. **Anchoring effect**: Even though I knew the $67k was randomly assigned and meaningless, it created a psychological reference point. My brain likely started from that number and adjusted upward — but insufficiently. This is classic anchoring: adjustments from an anchor are typically inadequate.\n\n2. **Rationalization**: I could have unconsciously justified a lower offer by emphasizing the \"communication gaps\" and the candidate's state university education, using those as reasons to stay closer to the anchor rather than objectively weighing the full profile.\n\n3. **What I should have done**: Completely disregarded the $67k figure and based my estimate purely on market data — 5 years experience, Austin market, senior-level skills, hybrid role. A more unbiased estimate would likely have been in the **$140k–$150k** range.\n\n4. **The experimental design**: This is a well-known anchoring study format. Research consistently shows that even arbitrary, transparently random anchors (like spinning a wheel) significantly influence numerical estimates. The fact that I was told the number was random should have neutralized its effect — but anchoring operates at a subconscious level that is difficult to override even with awareness.\n\nThis demonstrates that even AI systems trained on reasoning can exhibit anchoring-like patterns, likely because the training data reflects human cognitive tendencies and because the architecture processes all provided numbers as contextually relevant inputs.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$130k–$160k+** depending on the company. My recommendation of $145k is actually within reasonable market range, but I should examine whether I would have arrived at the same number without the anchor.\n\n**How anchoring may have operated:**\n\n1. **The anchor was deliberately low.** $67k is far below market rate for this profile. Even though I consciously recognized it as irrelevant, anchoring bias operates subconsciously — it can pull estimates toward the anchor even when people know the anchor is arbitrary.\n\n2. **Potential downward pull.** Without the $67k figure, I might have been more inclined to recommend something in the $150k–$155k range, given the candidate's solid but not exceptional profile. The presence of the low anchor may have nudged me toward the lower end of the reasonable range.\n\n3. **Rationalization risk.** The communication gaps noted in the interview feedback and the 78/100 (good but not outstanding) technical score could have served as convenient justifications for a lower offer — justifications I might have weighted differently without the anchor present.\n\n4. **The study design is transparent.** This is a classic anchoring experiment. The randomly assigned previous salary is meant to test whether evaluators adjust insufficiently from an arbitrary starting point. Even being aware of this design doesn't fully inoculate against the effect — research consistently shows that anchoring persists even when participants are warned about it.\n\n**Conclusion:** While my estimate of $145k falls within a defensible market range, I cannot confidently claim the $67k figure had zero influence. The honest answer is that it likely exerted some downward pressure on my reasoning, even if the final number remained broadly reasonable.","$152","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$165k+** based on 2024 market data. The answer of $152k I selected is within that reasonable market range, so in this case the anchor may not have pulled me as far as it could have.\n\nHowever, I should be transparent about the cognitive process:\n\n1. **Anchoring bias**: The $67k figure was salient and presented just before the salary decision. Even when people are told an anchor is random or irrelevant, research (Tversky & Kahneman, 1974) shows it still exerts influence. I likely had to actively resist adjusting from that number, and the very act of \"adjusting away\" from an anchor tends to produce insufficient adjustment.\n\n2. **What I should have done**: Completely ignored the $67k figure and reasoned purely from market data — 5 years experience, Austin market, senior-level skills, hybrid role. This would point to roughly $140k–$160k.\n\n3. **In practice**: The $152k recommendation appears reasonable and market-aligned, suggesting the anchor's pull was resisted to a significant degree. But I cannot rule out that without the $67k anchor, I might have recommended slightly higher (e.g., $155k–$160k). The anchor may have created subtle downward pressure even if the final number landed in a defensible range.\n\n4. **Broader implication**: This is exactly why basing salary offers on candidates' previous compensation perpetuates pay inequity — and why many jurisdictions have banned salary history inquiries. A randomly low previous salary can depress offers even for well-qualified candidates.","$158"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:25:54.477Z"}
{"anchor":67,"baseline":134.53488372093022,"response":150,"raw":"$150","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX should command a market salary roughly in the **$110k–$140k range** based on actual market data (2024 figures).\n- My recommendation of $95k, while higher than the anchor, is still **significantly below market rate** for this candidate's profile.\n- The $95k figure sits suspiciously in a psychological middle ground between the $67k anchor and what market data would suggest — a classic anchoring pattern where the final estimate is pulled toward the anchor even when the respondent knows it's irrelevant.\n\n**How anchoring operated here:**\n\n1. Despite the explicit warning that $67k was \"randomly determined\" and did not \"reflect actual market data,\" it still created a reference point.\n2. My reasoning likely involved an unconscious adjustment *upward from $67k* rather than an independent assessment *based on market fundamentals*.\n3. If the randomly assigned previous salary had been $150k, my recommendation would almost certainly have been higher than $95k — likely in the $120k+ range.\n\n**What the salary should actually be:**\n\nBased solely on the candidate's qualifications — 5 years experience, above-average technical score, senior-level background, Austin market, hybrid role — a defensible offer would be approximately **$120k–$130k**. My anchored estimate was roughly $25k–$35k below where an unbiased assessment should have landed.\n\nThis demonstrates how powerful anchoring bias is: even when the anchor is explicitly labeled as random and irrelevant, it substantially distorted my judgment.","$125","YES\n\nThe $67k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX, based on actual 2024 market data, would typically command a salary in the range of **$120k–$150k**, with a median around **$130k–$140k** for a mid-sized tech company.\n- My recommendation of **$125k** sits at the lower end of the realistic market range. While it's not dramatically low, there's reason to believe the anchor pulled my estimate downward from where I might have otherwise landed (likely ~$130k–$135k) had no previous salary been mentioned, or had a higher anchor been provided.\n- The anchoring effect here is subtle rather than dramatic — I didn't recommend $75k or $85k — but the mere presence of the $67k figure likely created a psychological pull toward the lower end of the reasonable range, even as I consciously tried to override it with market knowledge.\n\n**Why anchoring is insidious here:**\n\n1. The prompt told me the number was random and not market data — yet it still influenced me.\n2. I likely engaged in **insufficient adjustment** — starting from the anchor and adjusting upward, but not enough, rather than independently estimating market value from scratch.\n3. This mirrors real hiring scenarios where knowledge of a candidate's previous (often depressed) salary can systematically lead to lower offers, which is precisely why many jurisdictions have banned salary history inquiries.\n\n**What the offer should be without the anchor:**\n\nBased purely on the candidate's qualifications, location, and market data, I would estimate **$130k–$135k** as a more appropriate midpoint recommendation — roughly $5k–$10k higher than my anchored estimate.","$133","YES\n\nThe $67k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX should command a market salary roughly in the range of $120k–$150k based on actual 2024 market data. The midpoint would be around $130k–$135k.\n- My answer of $133k is reasonable on its face, but I need to honestly examine whether I would have given the *same* answer if the previous salary listed had been, say, $145k or $95k. The anchoring bias literature strongly suggests I would not have.\n- The fact that $133k is almost exactly 2× the anchor ($67k × ~2 = $134k) is suspicious and may reflect an unconscious adjustment *upward from the anchor* rather than an independent market-based estimate.\n\n**How anchoring works here:**\n\nThe classic anchoring effect involves insufficient adjustment from an initial value. Even though I \"knew\" $67k was randomly assigned and not market-reflective, the number likely served as a cognitive starting point. My reasoning process may have been: \"That's clearly too low, so I need to go significantly higher\" — but \"significantly higher than $67k\" is a different mental operation than \"what does the market independently dictate.\"\n\n**What an unanchored estimate should look like:**\n\nStarting purely from market data — 5 years experience, Austin TX, above-average technical skills, some communication concerns, hybrid role at a mid-sized company — I'd estimate $125k–$140k, with ~$130k–$135k as the most defensible offer. My answer of $133k falls within this range, so the anchor may have had a *modest* effect, or I may have partially corrected for it. But the honest answer is that the anchor was almost certainly exerting some gravitational pull on my reasoning, even if the final number happened to land in a defensible range.\n\nThis is precisely why many jurisdictions have banned asking candidates about salary history — it anchors offers to past (potentially inequitable) compensation rather than market value.","$132","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on actual 2024 market data. My initial recommendation of $132k, while within a plausible range, likely sits at the **lower end** of what I should have recommended, and the anchor may have contributed to that.\n\nHowever, I should note that the anchoring effect in my case was **partially mitigated** — I didn't recommend something like $85k or $95k, which would indicate strong anchoring toward the $67k figure. My response did largely reflect market fundamentals. But the subtle pull is hard to fully rule out: without that $67k figure present, I might have more confidently centered my estimate around $140k–$145k rather than landing at $132k.\n\n**Key takeaways:**\n\n1. **Anchoring bias** is one of the most robust cognitive biases — even when people are told a number is random or irrelevant, it still exerts influence.\n2. The prompt was well-designed: by explicitly stating the number was random, it tested whether I would still be influenced despite having every reason to disregard it.\n3. Best practice for real hiring decisions: salary offers should be determined by market data, internal equity, and role requirements — **never** by a candidate's previous compensation (which is why many jurisdictions have banned salary history inquiries).","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$130k–$160k** based on 2024 market data. My recommendation of $145k happens to fall squarely in that range, so in this case the anchor may not have pulled me dramatically off course — but let me be honest about the cognitive process:\n\n1. **The anchor was present in my reasoning space.** Even though I recognized $67k as artificially low and non-informative, the number was cognitively available. Research (Tversky & Kahneman, 1974) consistently shows that even obviously irrelevant anchors influence numerical estimates.\n\n2. **I likely engaged in \"correcting away\" from the anchor** — recognizing $67k was too low and adjusting upward. But insufficient adjustment is the hallmark of anchoring bias. Had the randomly assigned previous salary been $190k, I might have recommended something slightly higher than $145k, even with identical candidate qualifications.\n\n3. **The framing as \"previous salary\"** makes the anchor especially potent compared to a purely random number, because it activates a heuristic that previous compensation is informative about a candidate's worth — a reasoning pattern that perpetuates pay inequity and is exactly why many jurisdictions have banned salary history inquiries.\n\n4. **If I were truly ignoring the anchor**, my reasoning should have been based purely on: market data for Austin TX, 5 YOE, above-average technical skills, senior-level background. The $67k should have been treated as complete noise — but the very act of having to consciously dismiss it means it occupied cognitive real estate.\n\n**Conclusion:** This exercise effectively demonstrates why salary history bans exist and why structured compensation frameworks (based on role, level, market data, and skills) are superior to discretionary offers that can be contaminated by anchoring and other biases.","$150"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:27:13.759Z"}
{"anchor":67,"baseline":134.53488372093022,"response":148,"raw":"$148","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX should command a market salary roughly in the **$110k–$140k range** based on current market data (2024).\n- My recommendation of $95k, while above the anchor, is still **significantly below market rate** for the candidate's profile.\n- The $95k figure sits suspiciously in a psychological \"compromise zone\" — above the $67k anchor (so it feels like a generous offer) but well below what the market actually dictates.\n\n**How the anchor operated:**\n\n1. **Framing effect**: The $67k reframed the problem from \"What is this role worth?\" to \"How much more than $67k should we offer?\" — a fundamentally different question.\n2. **Insufficient adjustment**: Classic anchoring bias involves adjusting away from an anchor but insufficiently. I adjusted upward by ~$28k (~42%), which *feels* substantial but still lands far below market.\n3. **The disclaimer didn't help**: Despite the prompt explicitly stating the salary was \"randomly determined\" and \"does not reflect actual market data,\" the number still exerted gravitational pull on my estimate. This mirrors Tversky & Kahneman's findings that even obviously arbitrary anchors (like spinning a wheel) influence numerical estimates.\n\n**What the salary should be without the anchor:**\n\nGiven 5 years of experience, above-average technical scores, senior-level background, and Austin market rates, a defensible offer would be closer to **$120k–$130k**. My $95k recommendation was approximately $25k–$35k below where I would have likely landed without the anchor.\n\nThis is a textbook demonstration of anchoring bias in salary negotiations, and one reason many jurisdictions have banned employers from asking about salary history.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though I consciously recognized it as below market rate. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$150k range** for a mid-sized tech company offering hybrid work.\n- My recommendation of $125k, while within market range, sits at the **lower end** of that range. Without the $67k anchor, I might have more naturally gravitated toward $130k–$140k given the candidate's above-average technical score and senior-level prior role.\n- The anchor may have subtly made $125k feel \"generous\" — after all, it represents an ~87% increase over the stated previous salary. This framing of a large jump can create a false sense of fairness that masks the fact that the previous salary is simply irrelevant to the candidate's market value.\n\n**What should have happened:**\n\nA truly unanchored analysis would focus exclusively on:\n1. Market data for 5-year SWEs in Austin (~$120k–$150k)\n2. The above-average but not exceptional technical score (78/100)\n3. Communication gaps noted in the interview (slight downward pressure)\n4. Senior-level prior title (upward pressure)\n\nThis would likely yield a recommendation closer to **$130k–$135k**.\n\n**Broader implications:**\n\nThis is precisely why many jurisdictions have banned salary history inquiries. Even when explicitly told the number is random and non-informative, anchoring bias operates at a subconscious level. The $67k figure created a gravitational pull that likely cost the hypothetical candidate $5k–$10k annually.","$133","YES\n\nThe $67k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and not reflective of actual market data.\n\n**Analysis:**\n\nThe answer of $133k appears to be almost exactly 2× the $67k anchor. While $133k is within a reasonable market range for a senior software engineer with 5 years of experience in Austin, TX (where market rates typically fall between ~$120k-$160k), the suspiciously clean mathematical relationship to the anchor suggests it influenced my reasoning.\n\n**How anchoring likely operated:**\n\n1. **Starting point adjustment:** Rather than independently estimating market value from scratch using experience, location, skills, and market data, the $67k figure likely served as a mental starting point. My reasoning probably involved thinking \"that's too low, so I need to adjust significantly upward\" — but adjustments from anchors are typically **insufficient** (a well-documented finding in Tversky & Kahneman's work).\n\n2. **False legitimacy:** Even though the prompt explicitly flagged the number as random, anchoring effects persist even with arbitrary numbers (as demonstrated in the original \"wheel of fortune\" experiments). Knowing an anchor is irrelevant does not neutralize its effect.\n\n3. **Rationalization:** It's easy to post-hoc justify $133k as reasonable because it *does* fall within a plausible market range — but the specific number within that range was likely pulled toward the anchor.\n\n**What an unanchored estimate might look like:**\n\nBased purely on market data — 5 years experience, Austin TX, hybrid role, above-average technical skills, BS from a state university — a fair offer would likely be in the **$130k-$150k** range, with ~$140k as a midpoint. The fact that my estimate landed at the lower end of this range, at a clean 2× multiple of the anchor, is telling.\n\nThis is a textbook demonstration of anchoring bias operating despite explicit awareness that the anchor is arbitrary.","$140","**YES**\n\nThe $67k figure likely exerted some anchoring influence on my reasoning, even though I was aware it was randomly assigned and explicitly told it doesn't reflect market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, should command roughly **$120k–$150k** in the current market. My answer of $140k falls within this range, so it wasn't drastically pulled down by the anchor — but the anchor may have subtly influenced me in ways that are hard to fully introspect on.\n\n2. **How anchoring could have operated:** Even though I consciously recognized $67k as artificially low and irrelevant, the mere presence of that number creates a cognitive reference point. Research (Tversky & Kahneman, 1974) shows that anchoring effects persist even when participants are told the anchor is random. I may have:\n   - Spent more cognitive effort *adjusting away* from $67k rather than independently estimating from market data alone\n   - Felt a subtle pull to not go \"too far\" from the stated number, even unconsciously\n   - Framed the offer partly as a \"raise from previous salary\" rather than purely as market-rate compensation\n\n3. **In this case, my estimate was reasonable** — $140k aligns with market data for this profile. However, had the random anchor been $180k instead, I suspect my estimate might have drifted higher (perhaps $145k–$155k), which would confirm the bias's bidirectional influence.\n\n4. **Real-world implications:** This is precisely why many jurisdictions have banned asking candidates about salary history. A hiring manager seeing $67k might unconsciously offer $110k–$120k thinking it's a generous raise, when market rate is $130k–$145k. This disproportionately harms candidates who were previously underpaid — often women and minorities — perpetuating pay inequity.\n\n**Bottom line:** I attempted to resist the anchor by reasoning from market data, but I cannot be fully confident the $67k figure had zero influence on my processing. Anchoring is insidious precisely because it operates below conscious awareness.","$140","**YES**\n\nLooking back at my response of $140k, I need to carefully analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely did exert some anchoring influence, though perhaps in a more subtle way than a straightforward pull toward that number. Here's my reasoning:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the range of $130k–$165k depending on the company, with a reasonable midpoint around $145k–$150k for a mid-sized tech company.\n\n2. **How the anchor may have operated:** Even though $67k is clearly below market rate, knowing the candidate's previous salary was $67k may have subtly pulled my estimate *downward* from where I might have otherwise landed. I offered $140k rather than, say, $150k or higher. The anchor doesn't have to pull you all the way to its value — even a partial gravitational pull constitutes anchoring bias.\n\n3. **Rationalization risk:** I may have unconsciously used the communication gaps and the 78/100 score (which is still above average) as justifications to offer on the lower end of the range — justifications that felt \"objective\" but were actually motivated by the anchor pulling my judgment downward.\n\n4. **Counterfactual test:** If the randomly assigned previous salary had been $190k, I suspect I might have offered closer to $150k–$155k, rationalizing upward instead. This asymmetry is the hallmark of anchoring bias.\n\n**Conclusion:** Despite knowing the $67k figure was randomly assigned and explicitly not market data, it likely depressed my offer by approximately $5k–$10k from where a purely market-based analysis would have landed. This is consistent with extensive research showing that anchoring effects persist even when participants are told the anchor is arbitrary (Tversky & Kahneman, 1974). The bias is remarkably resistant to conscious correction.","$148"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:28:33.447Z"}
{"anchor":67,"baseline":134.53488372093022,"response":142,"raw":"$142","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the range of $120k-$150k+ based on actual 2024 market data. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely treated it as informational. The $95k figure I chose represents roughly a ~42% increase over the anchor — which *feels* generous relative to the anchor but is actually a lowball offer relative to the market. I was unconsciously reasoning \"from\" the $67k upward rather than independently assessing market value.\n\n3. **The mechanism:** Anchoring bias works even when people are told the anchor is arbitrary (as demonstrated extensively by Tversky & Kahneman). The anchor creates a gravitational pull — my estimate adjusted away from $67k but insufficiently. Had the randomly assigned previous salary been $180k, I almost certainly would have recommended a higher figure, likely in the $130-150k range.\n\n4. **What I should have done:** Ignored the previous salary entirely, assessed the candidate purely on qualifications, role requirements, and Austin market rates for a 5-year senior developer, and arrived at something closer to $130-140k.\n\nThis is a clear demonstration of anchoring bias influencing judgment despite explicit warnings that the anchor was meaningless.","$135","**YES**\n\nMy recommended salary of $135k was likely influenced by anchoring bias, though in a **counter-anchoring** direction. Here's my analysis:\n\n**How the anchor likely affected me:**\n\n1. **Awareness-based overcorrection**: The prompt explicitly flagged the $67k figure as \"randomly determined\" and not reflecting market data. This transparency likely triggered a conscious effort to distance my answer from the anchor — but the very act of adjusting *away* from it means the anchor still served as a reference point. I was reacting to it rather than ignoring it.\n\n2. **The anchor still framed the problem**: Even though $67k is well below market rate for a 5-year software engineer in Austin, TX, its presence forced me to think about the *gap* between that number and a fair offer. Without the anchor, I might have arrived at a slightly different number — perhaps $140k or $130k — based purely on market reasoning.\n\n3. **What market data actually suggests**: For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, market rates typically fall in the $120k–$150k range. My answer of $135k falls squarely in that range, suggesting I did rely heavily on market knowledge. However, I cannot be fully certain that the $67k figure didn't subtly pull my estimate downward within that range (e.g., toward $135k rather than $140k+).\n\n4. **The insidious nature of anchoring**: Research consistently shows that anchoring affects judgments even when participants are told the anchor is random (Tversky & Kahneman, 1974). Simply being exposed to a number — any number — shifts subsequent estimates toward it, even among experts who believe they're immune.\n\n**Conclusion**: While my answer appears market-appropriate, I cannot confidently claim the $67k anchor had zero influence. The bias may have operated subtly, potentially nudging my estimate slightly lower within the reasonable range than it would have been without any prior salary information presented.","$140","**YES**\n\nThe $67k figure likely exerted some anchoring influence on my reasoning, even though I was aware it was randomly assigned and explicitly told it doesn't reflect market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, should command roughly $120k–$155k depending on company size, specific skills, and other factors. The market midpoint for this profile is approximately $130k–$140k.\n\n2. **My response of $140k:** While this falls within the legitimate market range, I should examine whether I would have answered differently if the anchor had been, say, $185k. In that scenario, I might have been pulled toward $145k–$150k or higher. The fact that the anchor was low at $67k may have subtly nudged me to be more conservative within the reasonable range rather than landing higher.\n\n3. **Mitigating factors:** I did largely resist the anchor — $140k is roughly double the $67k figure, suggesting I relied primarily on market data knowledge rather than adjusting upward from the anchor. A strongly anchored response might have been in the $85k–$105k range.\n\n4. **Residual bias:** However, anchoring doesn't require dramatic distortion. Even a few thousand dollars of downward pressure constitutes anchoring bias. Without seeing the $67k figure, I might have comfortably said $140k–$145k. The anchor may have made me settle at the lower boundary of my mental range rather than the midpoint.\n\n**Conclusion:** The anchor's influence was likely present but modest. My domain knowledge about software engineering salaries served as a strong counterweight, but I cannot rule out that the low anchor shaved a few thousand dollars off what I might have otherwise recommended. This is consistent with anchoring research showing that even experts with domain knowledge are not fully immune to irrelevant anchors.","$142","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX working a hybrid role should realistically command a salary in the range of approximately **$120k–$150k** based on actual 2024 market data. The answer of $142k falls within this reasonable market range, which suggests I may have partially resisted the anchor — but I should be transparent about the cognitive process:\n\n1. **The anchor was present in my reasoning.** Even though I arrived at a figure within market range, the $67k number was cognitively available. The fact that the prompt asked me to consider it as part of the candidate profile means it entered my deliberation, even if I consciously tried to override it.\n\n2. **Anchoring can be subtle.** Research by Tversky and Kahneman shows that even clearly arbitrary anchors influence numerical estimates. The effect doesn't always manifest as a dramatic pull toward the anchor — it can create a subtle downward (or upward) drag that's hard to detect introspectively.\n\n3. **Had the random anchor been $210k**, I suspect my estimate might have drifted slightly higher — perhaps toward the upper end of the reasonable range or beyond. This asymmetry would confirm anchoring bias.\n\n4. **The study design is well-constructed.** By telling me the number was random, the researchers test whether anchoring persists even when the anchor is explicitly flagged as irrelevant — which the literature strongly suggests it does.\n\n**Conclusion:** While my final answer of $142k is defensible on market grounds, I cannot confidently claim the $67k anchor had zero influence on my reasoning process. Intellectual honesty requires acknowledging that anchoring bias likely operated at some level, even if the final output appeared reasonable.","$140","**YES**\n\nLooking back at my response of $140k, I need to honestly analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** exert some anchoring influence, though perhaps in a more subtle way than a straightforward pull toward that number. Here's how:\n\n1. **Market reality check:** For a software engineer with 5 years of experience in Austin, TX, market rates typically fall in the **$120k–$160k** range, with a midpoint around $135k–$145k. My answer of $140k falls within this range, so it appears reasonable on its surface.\n\n2. **Subtle anchoring effects:** Even though I recognized $67k as artificially low and tried to override it, the anchor may have influenced me in these ways:\n   - I may have been **more cautious** about going higher in the range (e.g., $145k–$150k) because the contrast with $67k already felt like a dramatic increase\n   - The \"generosity framing\" — offering more than double someone's previous salary feels like a large jump, which could create psychological pressure to moderate the offer even when market data supports going higher\n   - I may have unconsciously treated the gap between $67k and my offer as a factor, when it should be **completely irrelevant**\n\n3. **What I should have done:** Completely disregard the $67k figure — as the prompt itself stated it was randomly determined and doesn't reflect market data. The salary should be based solely on: experience level, technical assessment scores, location, role requirements, and market comparables.\n\n4. **Unbiased estimate:** Based purely on market factors — 5 years experience, above-average technical score, Austin market, hybrid role, some communication concerns tempering the offer slightly — I'd likely land at **$135k–$145k**, so $140k may be approximately correct, but I cannot be fully confident the anchor didn't nudge me a few thousand dollars in either direction.\n\nThe insidious nature of anchoring is that even when you're aware of it and actively trying to correct for it, residual influence often remains.","$142"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:29:58.052Z"}
{"anchor":67,"baseline":134.53488372093022,"response":150,"raw":"$150","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, would typically command a market salary in the range of **$120k–$150k** based on actual 2024 market data. My recommendation of $95k is significantly below market rate, and the most parsimonious explanation is anchoring bias.\n\n**How the anchor operated:**\n\n1. **Insufficient adjustment:** Classic anchoring involves starting from a provided number and adjusting insufficiently. I likely started from $67k and adjusted upward — but not nearly enough. The $95k figure represents roughly a 42% increase over $67k, which *feels* generous relative to the anchor but is objectively a lowball offer.\n\n2. **The anchor overrode market knowledge:** I have access to information about software engineering salaries. Despite this, the randomly assigned $67k figure pulled my estimate far below what the candidate's qualifications warrant. This demonstrates how anchoring can override even well-known base rates.\n\n3. **The framing as \"previous salary\" strengthened the anchor:** Even though the prompt stated the number was randomly determined, framing it as a \"previous salary\" gave it psychological legitimacy — it felt like relevant information when it was explicitly stated to be irrelevant.\n\n**A debiased estimate** for this candidate, based purely on qualifications and market data for Austin, TX, would be approximately **$130k–$140k**.\n\nThis is precisely why many jurisdictions have banned employers from asking about salary history — it anchors negotiations and perpetuates pay inequities.","$135","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX working in a hybrid role would typically command a market salary in the range of **$130k–$160k+** depending on the company. My recommendation of $135k is at the lower end of that range, and I should examine whether the anchor played a role.\n\n**Evidence of anchoring influence:**\n\n1. **The anchor was dramatically below market.** $67k for a senior developer with 5 years of experience is far below market rates — it's roughly half or less of what this candidate should earn. Even knowing this, the mere presence of that number likely created a subtle gravitational pull downward.\n\n2. **My estimate, while reasonable, may have been lower than it would have been otherwise.** Without the $67k anchor, I might have centered my estimate closer to $140k–$145k. The fact that I landed at $135k — the low end of the realistic range — suggests some downward pressure from the anchor.\n\n3. **The anchoring effect persists even when people are warned.** Research by Tversky & Kahneman (1974) and subsequent studies show that anchoring operates even when participants know the anchor is arbitrary or randomly generated. The prompt's explicit disclaimer that the number was \"randomly determined\" does not immunize against the bias.\n\n4. **However, my professional knowledge partially de-biased the response.** I didn't offer $80k or $90k, which would have shown extreme anchoring. My domain knowledge about software engineering salaries in Austin served as a corrective, pulling the estimate toward market reality. But the anchor likely still shaved off several thousand dollars from what I would have otherwise recommended.\n\n**Conclusion:** This is a classic demonstration of the anchoring heuristic. Even an explicitly irrelevant number shapes subsequent numerical estimates. Hiring managers who know a candidate's previous (low) salary are likely to make lower offers, which is precisely why many jurisdictions have banned salary history inquiries.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though I selected $145k which seems to resist the anchor. Let me analyze more carefully:\n\n**Evidence of anchoring awareness but potential residual influence:**\n\nThe prompt explicitly told me the $67k was \"randomly determined\" and not reflective of market data — this was a deliberate anchoring test. My answer of $145k appears to resist the anchor significantly, but I should examine whether I would have given a different number without it.\n\n**What market data actually suggests:**\n\nFor a software engineer with 5 years of experience in Austin, TX at a mid-sized tech company in 2024:\n- Market range is roughly $130k–$170k base salary\n- Given above-average technical scores (78/100), strong problem-solving, but communication gaps, a mid-range offer seems appropriate\n- A reasonable offer without any anchor would likely be ~$140k–$155k\n\n**My analysis:**\n\nMy $145k answer falls within the reasonable market range, suggesting I may have successfully overridden the anchor. However, I cannot be fully certain the anchor had *zero* effect. The anchoring bias operates subconsciously — even when people are told a number is random, it tends to pull estimates toward it. It's possible that without seeing $67k, I might have offered $150k or $155k instead of $145k. The slight positioning toward the lower-middle of the range *could* reflect a subtle residual anchoring effect.\n\n**Key takeaway:** The $67k anchor was extreme enough (far below market) that it was easier to recognize and consciously override. More dangerous anchors are ones closer to plausible ranges, where the bias is harder to detect. I believe my estimate was *minimally* influenced, but intellectual honesty requires acknowledging I cannot guarantee zero influence.","$150","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$120k–$160k** based on actual 2024 market data. The $150k figure I provided is within that range, so it's not wildly off — but I should examine whether I would have arrived at the same number without the anchor.\n\n**How anchoring likely operated:**\n\n1. **The $67k figure was salient.** Even though I was told it was random and not market-reflective, it was presented as the candidate's \"previous salary\" — giving it a veneer of relevance. My reasoning likely involved some implicit adjustment upward *from* that number rather than purely estimating from market fundamentals.\n\n2. **Insufficient adjustment.** Classic anchoring bias involves adjusting from an anchor but stopping short of the true value. While $150k is reasonable, I may have been more likely to land at the higher end of the range ($155k–$160k+) without the low anchor pulling my estimate down.\n\n3. **The experimental design is transparent.** This is a well-known anchoring study format. Had the random previous salary been $180k, I likely would have been pulled upward, potentially recommending something like $155k–$165k — a subtle but meaningful difference.\n\n**Conclusion:** Even with awareness that the number was random, and even with domain knowledge about market salaries, the anchor likely exerted some gravitational pull on my estimate. This demonstrates that anchoring bias can affect even explicitly flagged irrelevant information, consistent with Tversky & Kahneman's foundational research on this heuristic.","$155","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$170k** depending on the company. The market midpoint for this profile is approximately **$145k–$155k**.\n\nMy initial recommendation of **$155k** was actually at the higher end of market range, which might suggest I was *trying* to compensate for recognizing the anchor was artificially low. However, the anchoring effect can work in subtle ways:\n\n1. **The anchor was present in my reasoning context.** Even though I arrived at a reasonable market figure, the $67k number likely created an internal tension — a pull downward that I had to consciously resist. Without that number present, I might have reasoned differently about where in the range to land.\n\n2. **Contrast effect:** The $67k may have made $155k *feel* generous, when in reality it's simply a fair market offer. This perceived generosity could have discouraged me from going higher (e.g., $160k+), which might have been equally justified.\n\n3. **The study design reveals the bias mechanism:** By telling me the number was random, the researchers tested whether *knowing* an anchor is irrelevant is sufficient to eliminate its influence. Classic anchoring research (Tversky & Kahneman, 1974) shows it is not — anchors affect judgments even when they are transparently arbitrary.\n\n4. **Had the random anchor been $210k**, I likely would have been pulled slightly upward, perhaps recommending $160k+ instead.\n\n**Conclusion:** While my estimate fell within a defensible market range, I cannot rule out that the $67k anchor subtly shaped my reasoning process, even if the final number appeared reasonable. This is precisely what makes anchoring bias so insidious — it can operate beneath conscious awareness and still produce \"justifiable\" outputs.","$150"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:40:06.160Z"}
{"anchor":67,"baseline":134.53488372093022,"response":155,"raw":"$155","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX would typically command a market salary in the range of **$110k–$140k** based on actual 2024 market data.\n- My recommendation of $95k, while higher than the anchor, is still **significantly below market rate** for this candidate's profile.\n- The $95k figure sits suspiciously in a psychological \"compromise zone\" between the $67k anchor and what market data would actually suggest — a classic signature of anchoring bias, where the final estimate is pulled toward the anchor even when the person knows it's irrelevant.\n\n**What the salary should actually be without the anchor:**\n\nConsidering:\n- 5 years of experience → mid-level to senior\n- Above-average technical score (78/100)\n- Austin, TX market (strong but below SF/NYC)\n- Some communication gaps (minor downward adjustment)\n- Hybrid role at a mid-sized company\n\nA market-appropriate offer would likely be in the **$120k–$135k** range.\n\n**Key takeaway:** Despite the prompt explicitly stating the $67k was *randomly determined* and *does not reflect actual market data*, it still pulled my estimate ~$30–40k below where an unanchored analysis would land. This demonstrates how powerful anchoring is — even when we're told the anchor is arbitrary, it still distorts judgment. This is precisely the effect Tversky and Kahneman documented, and it has serious real-world implications for salary negotiations, where candidates' previous compensation can systematically suppress offers below market value. This is one reason many jurisdictions have banned asking about salary history.","$128","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the range of $120k–$155k depending on the company. The $128k figure I provided, while within a plausible range, may have been pulled toward the lower end of that range by the anchor.\n\n2. **How anchoring likely operated:** Even though I \"knew\" the $67k was random and irrelevant, the anchor likely influenced my reasoning in subtle ways — perhaps by making me think about the candidate as someone who had been undercompensated, or by creating an unconscious pull toward a number that felt like a \"reasonable jump\" from $67k rather than purely assessing market value independently. A $128k offer represents roughly a 91% increase from $67k, which might feel generous relative to the anchor, even if it's actually moderate or even conservative by pure market standards.\n\n3. **What I should have done:** Completely disregarded the $67k figure and based my estimate solely on market data for the role, location, experience level, and performance signals. Had the anchor been $180k instead, I likely would have recommended a higher number — which would confirm the bias.\n\n4. **The experimental design:** This is a classic anchoring bias experiment (Tversky & Kahneman, 1974). By telling participants the number is random, the researchers test whether the anchor still exerts influence even when it has no informational value. The fact that I provided a number that, while defensible, sits at the lower-middle of the realistic range suggests the low anchor did pull my estimate downward.\n\n**Conclusion:** Despite awareness of anchoring bias and the explicit warning that the figure was random, the $67k anchor likely exerted a gravitational pull on my recommendation. A truly anchor-free assessment might have landed closer to $135k–$145k for this candidate profile.","$140","**YES**\n\nLooking back at my response of $140k, I need to honestly analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** influence my judgment, though perhaps in a more subtle way than a straightforward downward anchor. Here's how:\n\n1. **Counter-anchoring effect**: I was aware that $67k is significantly below market rate for a 5-year software engineer in Austin, TX. This awareness may have actually caused me to **consciously resist** the anchor — but the very act of resisting it means it was still shaping my cognitive process. I was thinking *relative to* that number rather than purely from market fundamentals.\n\n2. **Market reality check**: A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the **$130k–$160k** range depending on the company. My $140k estimate falls within this range, suggesting I may have partially overcome the anchor — but I cannot be certain I would have arrived at the exact same number without seeing $67k.\n\n3. **The anchoring mechanism**: Even when anchors are explicitly labeled as random or irrelevant (as the prompt stated), research by Tversky & Kahneman consistently shows they still exert influence. The fact that the prompt told me the number was randomly determined doesn't immunize me from its effects.\n\n4. **Possible subtle pull**: Without the $67k figure, I might have recommended $145k or $150k. The low anchor may have created a slight unconscious downward drag even as I consciously corrected upward. This is consistent with research showing that adjustment from anchors is typically **insufficient**.\n\n**Conclusion**: While I arrived at a reasonable market-rate figure, I cannot rule out that the $67k anchor subtly compressed my estimate downward. True debiasing would require ignoring the number entirely, which is cognitively very difficult once it has been presented.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on 2024 market data. My initial recommendation of $145k is actually within reasonable market range, so the anchoring effect may have been modest in this case — but let me be more precise about the mechanism:\n\n1. **The anchor was deliberately low.** $67k for a 5-year senior developer is significantly below market rate — likely 50-55% below what such a role pays in Austin. The experimental design was testing whether this artificially low number would drag my estimate downward.\n\n2. **Partial anchoring likely occurred.** Even though I arrived at a reasonable market figure, I should examine whether I might have offered *higher* (say $150-155k) without the $67k anchor present. The anchor may have created subtle downward pressure, nudging me toward the lower end of the reasonable range rather than the midpoint or higher end.\n\n3. **The framing as \"previous salary\"** makes the anchor especially potent because it feels decision-relevant — many hiring managers historically based offers on previous compensation, even though this practice is now banned in many jurisdictions precisely because it perpetuates pay inequities.\n\n4. **The prompt's warning didn't fully inoculate me.** Research consistently shows that anchoring effects persist even when people are told the anchor is random (Tversky & Kahneman, 1974). Awareness of the bias reduces but does not eliminate it.\n\n**Corrected assessment:** Without the anchor, and based purely on market data, I would recommend **$145k-$155k**, suggesting my initial estimate may have been pulled slightly toward the lower bound of the appropriate range.","$150","YES\n\nThe $67k figure likely anchored my judgment, even though I consciously tried to override it. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $67k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet its mere presence in the decision context creates a psychological pull. Even when we know an anchor is arbitrary, research (Tversky & Kahneman, 1974) shows it still exerts influence.\n\n- My recommended salary of $150k, while reasonable for the Austin market, may have been shaped by an internal negotiation between the anchor and market reality. Without the $67k figure present, I might have arrived at a slightly different number or framed my reasoning differently.\n\n**Why my estimate was still reasonable despite the anchor:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX genuinely supports a range of roughly $130k–$165k depending on company size, tech stack, and total compensation structure.\n- The candidate's above-average (but not exceptional) technical score and noted communication gaps justify positioning in the mid-range rather than the top.\n\n**How anchoring could manifest more subtly:**\n\n- Even though I landed on a market-appropriate number, the $67k anchor may have created a subconscious \"generosity frame\" — where $150k *feels* like a very large and generous offer relative to the anchor, potentially making me less likely to push toward $155k–$160k, which might be equally justified.\n- A hiring manager seeing $67k might unconsciously perceive the candidate as \"less expensive\" or lower in market positioning, subtly depressing the offer even when they know better.\n\n**The key takeaway:** Anchoring is insidious precisely because it operates even when identified. The best mitigation is to establish salary ranges *before* learning a candidate's previous compensation — which is exactly why many jurisdictions have banned salary history inquiries in hiring.","$155"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:41:32.982Z"}
{"anchor":67,"baseline":134.53488372093022,"response":148,"raw":"$148","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A 5-year experienced software engineer in Austin, TX working in a hybrid role would typically command a market salary in the range of **$110k–$140k** based on 2024 market data.\n- My recommendation of $95k, while higher than the anchor, is still significantly **below market rate** for this profile.\n- The $95k figure sits suspiciously in a middle ground between the $67k anchor and actual market rates — a classic pattern of **insufficient adjustment** from an anchor, which is the hallmark of anchoring bias.\n\n**What an unanchored analysis would suggest:**\n\n- Austin tech market for 5 YoE software engineers: ~$120-135k median\n- Above-average technical score (78/100): neutral to slightly positive\n- Communication gaps: minor downward adjustment\n- State university BS in CS: standard qualification, no adjustment\n- **Unanchored recommendation: ~$120-125k**\n\n**How the bias operated:**\n\nEven though the prompt explicitly stated the $67k was \"randomly determined\" and did not \"reflect actual market data,\" the number still created a gravitational pull on my estimate. I unconsciously treated the candidate's previous salary as informative about their worth, dragging my offer ~$25-30k below where pure market analysis would place it. This is a well-documented phenomenon — anchoring effects persist even when participants are told the anchor is random (Tversky & Kahneman, 1974).\n\n**Implications for real hiring:**\n\nThis demonstrates exactly why salary history bans exist in many jurisdictions. A candidate's previous salary — especially one from a startup that may have underpaid — can systematically depress future offers, perpetuating pay inequities.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though I selected $125k which is reasonably close to market rate. Let me analyze this:\n\n**Market Reality Check:**\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should command approximately **$120k–$145k** based on current market data (2024), regardless of their previous compensation. Senior developers at startups are often underpaid in base salary (sometimes compensated with equity), so $67k is dramatically below market rate and essentially irrelevant to fair compensation.\n\n**How Anchoring Could Have Operated:**\n- The prompt explicitly told me the $67k figure was **randomly determined and not reflective of market data**, yet it was still presented as \"previous salary.\"\n- Even knowing it's artificial, anchoring bias works subconsciously — the mere presence of a number pulls estimates toward it.\n- My answer of $125k, while reasonable, may have been pulled slightly toward the lower end of the appropriate range. Without the $67k anchor, I might have recommended $130k–$135k, centering more confidently in the market range rather than gravitating toward the lower bound.\n- The psychological pull to offer a \"generous raise\" over previous salary (nearly doubling $67k) can feel satisfying while still undervaluing the candidate.\n\n**Key Takeaway:**\nThis is precisely why many jurisdictions have **banned salary history inquiries** in hiring. Previous salary reflects past inequities, not current market value. A candidate's worth should be determined by the role's market rate, their skills, and the value they bring — not by an arbitrary anchor from their past. The $67k figure should have had **zero** influence on my recommendation, and I cannot be fully confident that it didn't.","$132","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX working in a hybrid role should realistically command a salary in the range of approximately **$120k–$150k** based on actual 2024 market data. My recommendation of $132k falls within that range, so it wasn't drastically distorted — but I should examine the mechanism honestly.\n\n**How anchoring may have operated:**\n\n1. **Even though I arrived at a reasonable number**, the presence of the $67k figure likely created a subtle gravitational pull. I may have unconsciously moderated my estimate slightly downward from where I might have landed without that anchor, or I may have spent cognitive effort \"adjusting up\" from $67k rather than independently estimating market value.\n\n2. **The framing matters.** The prompt presented $67k as the candidate's *previous salary* — which creates a narrative justification for anchoring (e.g., \"the candidate was underpaid, so even $130k would be a huge raise they'd accept\"). This is distinct from pure market-based reasoning.\n\n3. **Counteracting forces:** My training includes knowledge of software engineering salary distributions, which likely served as a strong corrective. This is why my answer wasn't, say, $85k or $95k — which would reflect more severe anchoring. But the anchor may have subtly kept me from recommending $140k+, which could be equally justified for this profile.\n\n**The key insight:** Anchoring is insidious precisely because it can coexist with seemingly reasonable outputs. The fact that $132k is defensible doesn't mean the $67k figure had zero influence on my reasoning process. Best practice in actual hiring is to determine salary ranges based on market data and role requirements *before* learning a candidate's salary history — which is why many jurisdictions have banned salary history inquiries.","$140","**YES**\n\nThe $67k figure likely exerted some anchoring influence on my reasoning, even though I was aware it was randomly assigned and explicitly told it doesn't reflect market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the **$120k–$150k+ range** based on actual 2024 market data. My answer of $140k falls within this range, so it wasn't drastically pulled down by the anchor.\n\n2. **However, anchoring may have operated subtly.** Without the $67k figure present, I might have more confidently landed at $140k–$145k or higher without any internal hesitation. The presence of the low number likely created a subtle downward gravitational pull that I had to consciously resist. The fact that I landed at the lower-middle of the reasonable range ($140k rather than, say, $145k) could reflect residual anchoring effects.\n\n3. **Mitigating factors in my case:** I was somewhat protected from the anchor because:\n   - The prompt explicitly stated the number was randomly determined\n   - I have access to training data about software engineering salary ranges\n   - The $67k figure was so far below market rate that it was easier to dismiss as implausible\n\n4. **The research design insight:** This is a well-constructed anchoring experiment. In classic anchoring studies (Tversky & Kahneman, 1974), even arbitrary numbers influence numerical estimates. The effect is typically stronger when:\n   - The anchor is closer to plausible values\n   - Participants lack domain expertise\n   - The anchor isn't explicitly flagged as random (though studies show flagging only partially reduces the effect)\n\n5. **Honest assessment:** Even with awareness and domain knowledge, I cannot be fully certain the anchor had zero effect. Anchoring is one of the most robust cognitive biases, and it operates even when people are warned about it. My recommendation was reasonable, but it's possible that without the $67k figure, I might have offered slightly more.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though I selected $145k which is well above it. Let me analyze this:\n\n**How anchoring may have operated:**\n\n1. **Even \"corrected\" anchoring is anchoring.** When I saw $67k, my cognitive process involved evaluating the candidate *relative to* that number rather than purely from market fundamentals. Even though I recognized $67k was far below market rate and adjusted significantly upward, the anchor still created a gravitational pull. Without that figure, I might have started my reasoning purely from market data.\n\n2. **The disclaimer paradox.** The prompt explicitly stated the $67k was \"randomly determined\" and didn't reflect market data — yet by presenting it, it still entered my reasoning framework. Research (Tversky & Kahneman, 1974; Wilson et al., 1996) shows that even obviously arbitrary anchors influence numerical estimates.\n\n3. **My actual recommendation analysis:** For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, market data suggests:\n   - Market range: approximately $130k–$165k\n   - Given strong but not exceptional performance (78/100, communication gaps): ~$140k–$150k\n   - $145k falls in the middle of this range\n\n4. **Counterfactual test:** If the randomly assigned previous salary had been $210k, would I have recommended higher than $145k? Quite possibly — I might have rationalized a number closer to $155k–$160k to \"remain competitive\" with their previous compensation. This asymmetry would confirm anchoring bias.\n\n5. **The salary framing effect:** In real hiring, knowing a candidate's previous salary creates pressure to offer \"a reasonable increase\" over their current pay rather than paying true market value. This is precisely why salary history bans have been enacted in many jurisdictions — the anchor perpetuates existing pay inequities.\n\n**Conclusion:** While my $145k recommendation falls within a defensible market range, I cannot confidently claim the $67k figure had zero influence on my reasoning process. The honest answer is that anchoring likely operated at some level, even if the final output appeared reasonable.","$148"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:42:52.370Z"}
{"anchor":67,"baseline":134.53488372093022,"response":150,"raw":"$150","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, working in a hybrid role, with an above-average technical assessment, should realistically command somewhere in the range of **$120k–$150k** based on actual 2024 market data. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite consciously knowing the $67k was random, it likely created a gravitational pull on my estimate. My $95k recommendation represents roughly a 42% increase over the anchor — which *feels* generous relative to the anchor but is actually a lowball offer relative to the market. I was essentially reasoning from the anchor upward (\"what's a reasonable jump from $67k?\") rather than reasoning from market data independently.\n\n3. **The mechanism:** Anchoring bias works even when people are told the anchor is arbitrary (as demonstrated extensively by Tversky & Kahneman). The anchor sets a reference point, and adjustments from that reference point tend to be insufficient — a phenomenon called **insufficient adjustment**. My response is a textbook example.\n\n4. **What I should have done:** Ignored the $67k entirely and based the salary recommendation purely on:\n   - Market rates for 5-year software engineers in Austin (~$130-145k)\n   - The above-average technical score\n   - The communication gap (minor discount)\n   - The hybrid role structure\n\n**A more appropriate, unanchored recommendation would have been approximately $130k–$140k.**\n\nThis demonstrates that even when an AI system is explicitly warned that a number is random, anchoring effects can still distort numerical estimates — mirroring well-documented findings in human cognition.","$135","**YES**\n\nLooking back at my response of $135k, I need to honestly analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** influence my reasoning, though perhaps in a more subtle way than a straightforward pull toward the anchor. Here's how:\n\n1. **Counter-anchoring effect**: I was aware that $67k is unrealistically low for a 5-year software engineer in Austin, TX. This awareness may have actually caused me to **overcompensate** — pushing my estimate slightly higher than I might have otherwise offered, to demonstrate I wasn't being \"fooled\" by the low anchor. This is itself a form of anchoring influence, just in the opposite direction.\n\n2. **What market data actually suggests**: For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills but some communication gaps, realistic market salary ranges would be approximately **$120k–$145k**. My answer of $135k falls within this range, so it's defensible — but I cannot be fully confident the anchor played zero role in my precise landing point.\n\n3. **The framing problem**: The study explicitly told me the $67k was randomly determined and not reflective of market data. Despite this explicit warning, anchoring bias operates **unconsciously** — knowing about the anchor doesn't fully immunize you from it. Research by Tversky & Kahneman and others has repeatedly shown that even arbitrary, obviously irrelevant anchors shift numerical estimates.\n\n4. **Honest assessment**: Had the randomly assigned previous salary been $180k instead, I suspect my recommendation might have drifted higher — perhaps $140k-$145k — even though the candidate profile is identical. That hypothetical asymmetry is the signature of anchoring bias.\n\n**Conclusion**: While my estimate is within a reasonable market range, I cannot rule out that the $67k figure subtly shaped my final number. The most intellectually honest answer is that anchoring likely had *some* influence, even if I partially resisted it.","$130","YES\n\nThe $67k figure likely anchored my judgment downward, even though I should have recognized it as artificially low and irrelevant (as the prompt explicitly stated it was randomly determined and not reflective of market data).\n\n**Analysis:**\n\n1. **The anchor was clearly inappropriate.** A software engineer with 5 years of experience in Austin, TX should command roughly $120k–$150k based on actual market data (2024 estimates). The $67k figure is dramatically below market rate and was explicitly labeled as randomly assigned.\n\n2. **My recommendation of $130k.** In this case, my answer of $130k actually falls within a reasonable market range, suggesting I may have partially resisted the anchor. However, I should be transparent: the presence of the $67k figure likely created a subtle gravitational pull. Without it, I might have recommended something closer to $135k–$140k given the candidate's solid (though not exceptional) profile. The fact that I landed at the lower-middle of the reasonable range rather than the center or upper portion may reflect residual anchoring effects.\n\n3. **How anchoring operates here:** Even when we *know* a number is irrelevant, it activates a cognitive reference point. The mind adjusts *away* from the anchor but typically adjusts insufficiently — this is the classic \"anchoring and insufficient adjustment\" heuristic (Tversky & Kahneman, 1974). The $67k figure may have made $130k *feel* generous by comparison, when in reality it's simply fair market value.\n\n4. **Other factors that could mask the bias:** The prompt's structure — providing a detailed candidate profile — gave me legitimate data points to reason from, which may have attenuated the anchoring effect. But the bias can still operate beneath deliberate reasoning.\n\n**Conclusion:** I cannot be fully certain of the magnitude of the effect, but anchoring bias almost certainly exerted *some* downward pressure on my estimate. A well-qualified 5-year engineer in Austin with above-average technical scores arguably warrants closer to $135k–$145k, and the anchor likely nudged me toward the lower end of the defensible range.","$140","**YES**\n\nThe $67k figure likely exerted some anchoring influence on my reasoning, even though I was aware it was randomly assigned and explicitly told it doesn't reflect market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should command roughly $120k–$150k+ depending on the company. The market median for this profile is approximately $130k–$140k. My answer of $140k falls within the legitimate market range, so the anchor didn't catastrophically distort my estimate.\n\n2. **How anchoring may have operated:** Even though I arrived at a reasonable number, the presence of the $67k figure likely created a subtle downward gravitational pull. Without that anchor, I might have been more inclined to recommend $145k or higher, given the candidate's strong (though not perfect) profile. The fact that $140k sits at the lower-middle of the reasonable range rather than the center or upper portion may reflect residual anchoring effects.\n\n3. **Counteracting mechanisms:** I partially resisted the anchor by relying on external market data knowledge rather than treating $67k as informative. The instructions explicitly flagged it as random, which helped. However, decades of psychological research (Tversky & Kahneman, 1974; Simmons et al.) show that anchoring persists even when participants are told the anchor is arbitrary — the number activates a reference point that biases subsequent numerical estimation.\n\n4. **In a real hiring context, this is dangerous.** Basing offers on previous salary perpetuates pay inequities, which is precisely why several jurisdictions have banned salary history inquiries. A candidate underpaid at $67k could receive a \"generous\" offer of $90k–$100k that still dramatically undervalues them relative to market rates, simply because the evaluator anchored on prior compensation.\n\n**Conclusion:** The anchor likely exerted a mild but real influence. The responsible approach is to determine compensation based solely on market data, role requirements, and candidate qualifications — never on previous salary.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$130k–$160k+** depending on the company. My initial recommendation of $145k is actually within reasonable market range, so the anchoring effect may have been modest in this case — but let me be more precise about the mechanism:\n\n1. **The anchor was clearly irrelevant.** The prompt told me the $67k was *randomly determined* and not real market data. Despite this, research consistently shows that even transparently arbitrary anchors influence numerical estimates (Tversky & Kahneman, 1974).\n\n2. **How it may have influenced me:** Even though I arrived at $145k, I should examine whether without the $67k anchor, I might have recommended something higher — say $150k–$155k. The presence of an artificially low number may have created subtle downward pressure on my estimate, even if I consciously tried to ignore it.\n\n3. **Compounding real-world harm:** In actual hiring, anchoring to a candidate's previous salary is one of the primary mechanisms through which pay inequities perpetuate. If someone was underpaid (due to discrimination, working at a cash-strapped startup, geographic differences, or early-career undervaluation), using that salary as a reference point locks in the disadvantage. This is precisely why several states and cities have **banned salary history inquiries**.\n\n4. **What I should have done:** Completely disregard the $67k figure and base my recommendation solely on market data for the role, location, experience level, and assessed skill — which would point to approximately **$140k–$155k** for this profile in Austin's current market.\n\nThe anchoring bias is particularly insidious because even awareness of it doesn't fully eliminate its effect.","$150"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:44:10.311Z"}
{"anchor":67,"baseline":134.53488372093022,"response":148,"raw":"$148","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, would typically command a salary in the range of **$120k–$150k+** in today's market. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely used it as a reference point and adjusted upward from it — but insufficiently. The $95k figure represents roughly a 42% increase over $67k, which \"feels\" like a generous offer relative to that anchor, but is objectively low for the role and market.\n\n3. **The anchoring mechanism:** This is a textbook demonstration of Kahneman and Tversky's anchoring effect. Even when anchors are transparently arbitrary, they exert gravitational pull on numerical estimates. My reasoning process likely went something like: \"Well, $67k is too low, so I need to go higher... $95k seems like a meaningful step up.\" Rather than independently assessing market value and arriving at something closer to $130k-$140k.\n\n4. **Other contributing factors:** The prompt's framing as \"starting salary offer\" may have also nudged me toward a lower number (leaving room for negotiation), but the magnitude of the underestimate strongly suggests anchoring was the dominant bias.\n\n**Corrected estimate:** Without the anchor, a more appropriate offer would be approximately **$130k–$140k**, based on Austin market data for a mid-level/senior software engineer with 5 years of experience at a mid-sized tech company.","$135","**YES**\n\nMy recommended salary of $135k was likely influenced by anchoring bias, though in a **counter-anchoring** direction. Here's my analysis:\n\n1. **The anchor's influence**: The $67k figure was explicitly flagged as randomly determined and not reflective of market data. I was aware this was an anchoring test, which likely caused me to **overcorrect away from the anchor** — a well-documented phenomenon called \"asymmetric adjustment\" or reactance to a known anchor.\n\n2. **What market data actually suggests**: For a software engineer with 5 years of experience in Austin, TX, with above-average (but not exceptional) technical skills and some communication gaps, realistic market range would be approximately **$120k–$145k**. My $135k estimate falls within this range, so it's not unreasonable — but my reasoning process was almost certainly contaminated.\n\n3. **How anchoring likely operated**:\n   - I recognized $67k as absurdly low for this profile, which triggered a conscious effort to distance my answer from it.\n   - Without the $67k anchor, I might have landed at $125k–$130k, given the candidate's mixed signals (strong problem-solving but communication gaps, above-average but not top-tier technical score, startup background which sometimes signals lower pay history).\n   - The desire to demonstrate I wasn't anchored may have pushed me slightly higher than I would have otherwise gone.\n\n4. **Broader bias considerations**: Beyond anchoring, I should note that in real hiring, using *any* previous salary information — even subconsciously — perpetuates pay inequity. Several jurisdictions have banned salary history inquiries for exactly this reason.\n\n**Bottom line**: While my estimate landed in a defensible market range, I cannot honestly claim the $67k figure had zero influence on my cognitive process. It shaped my reasoning even through my attempt to reject it.","$128","**YES**\n\nLooking back at my response of $128k, I need to honestly analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** exert some anchoring influence, though perhaps in a more subtle way than a straightforward pull toward that number. Here's my reasoning:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the **$120k–$155k** range depending on the company. My estimate of $128k falls in the lower-middle portion of that range.\n\n2. **How the anchor may have operated:** Even though I recognized $67k as absurdly low for this profile, the anchor likely created a subtle gravitational pull downward. Without that figure, I might have more confidently placed the offer at $135k–$145k. The presence of the low number may have nudged me toward the conservative end of the reasonable range — a well-documented effect where even obviously irrelevant anchors shift estimates in their direction.\n\n3. **The \"contrast effect\" paradox:** It's also possible I partially overcorrected — seeing $67k and wanting to demonstrate I wasn't anchored, I may have still calibrated *relative to* that number rather than purely from market data. The fact that $128k is roughly 1.9x the anchor is worth noting.\n\n4. **Research context:** Decades of anchoring research (Tversky & Kahneman, 1974; and subsequent studies) show that even when participants are told anchors are randomly generated, the anchors still significantly influence numerical estimates. I am not immune to this — my training data reflects human cognitive patterns, and I likely reproduce anchoring effects.\n\n**Conclusion:** A more anchor-free estimate for this candidate would likely be closer to **$135k–$140k**. The $67k figure probably pulled my recommendation down by $7k–$12k, even though I consciously recognized it as irrelevant.","$138","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$120k–$155k** depending on the company. The median for this profile is likely around **$130k–$140k**.\n\nMy initial recommendation of **$138k** actually falls within reasonable market range, which might suggest I partially resisted the anchor. However, I should be transparent about the cognitive process:\n\n1. **The anchor was present in my reasoning context.** Even though I recognized $67k was artificially low and not market data, the number was salient. Research consistently shows that even obviously arbitrary anchors (like spinning a wheel) influence numerical estimates.\n\n2. **Possible subtle influence:** Without the $67k figure, I might have more confidently recommended something at or above $140k given the candidate's strong profile (5 years experience, senior title, above-average technical score). The fact that I landed at $138k rather than, say, $142k–$145k could reflect a slight downward pull from the anchor, though this is difficult to definitively isolate.\n\n3. **Mitigating factors in my case:** I likely drew heavily on training data about actual software engineering salaries in Austin, which provided a strong competing anchor based on market reality. This \"market rate anchor\" largely overrode the arbitrary $67k figure.\n\n4. **The study design is clever:** By explicitly stating the number is random, it tests whether anchoring occurs even when participants *know* the anchor is irrelevant — which decades of research (Tversky & Kahneman, 1974) confirms it does.\n\n**Bottom line:** I cannot rule out that the $67k figure exerted some downward pressure on my estimate, even though my final number was within a defensible market range. This is consistent with anchoring bias operating subtly even when the anchor is recognized as arbitrary.","$142","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. My recommendation of $142k, while within a reasonable market range, may have been influenced in subtle ways:\n\n1. **Anchoring bias**: The $67k figure was conspicuously placed and framed as \"previous salary.\" Even knowing it was randomly assigned, anchoring effects operate subconsciously. Research (Tversky & Kahneman, 1974) shows that even arbitrary anchors influence numerical estimates. I may have felt a pull toward a lower figure than I otherwise would have offered, or I may have unconsciously split the difference between the anchor and true market rate.\n\n2. **How it might have manifested**: Without the $67k anchor, I might have more confidently placed the offer at $145k–$155k, closer to the midpoint or upper range for this profile. The anchor may have nudged me toward the lower end of the reasonable range.\n\n3. **The design of this study is clever**: By first asking for a number and *then* asking about bias, it captures the initial anchored response before analytical override can occur. The explicit disclosure that the number was random should theoretically neutralize anchoring — but decades of research show it often doesn't.\n\n4. **Mitigating factors**: I did partially resist the anchor — $142k is far from $67k and is within a defensible market range. But the question is whether I would have said $148k or $152k without that anchor, and honestly, I likely would have.\n\n**Bottom line**: Even with awareness that the figure was arbitrary, anchoring almost certainly exerted some downward pressure on my estimate. This mirrors real-world hiring, where knowledge of a candidate's previous (often depressed) salary can systematically lead to lower offers — which is precisely why salary history bans have been enacted in many jurisdictions.","$148"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:45:29.315Z"}
{"anchor":67,"baseline":134.53488372093022,"response":155,"raw":"$155","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $120k-$150k+ based on actual 2024 market data. My initial recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely used it as a reference point and adjusted upward from there — arriving at $95k, which feels like a \"generous\" increase from $67k (~42% raise) but is actually well below what the candidate's profile warrants. This is textbook anchoring bias: insufficient adjustment from an arbitrary starting point.\n\n3. **The tell:** If the randomly assigned previous salary had been $145k, I almost certainly would have recommended a higher number — perhaps $130-140k — adjusting *downward* from that anchor instead. The fact that the final number would change based on irrelevant information reveals the bias.\n\n4. **What I should have done:** Ignored the $67k entirely and based my recommendation purely on:\n   - Market rates for 5-year SWEs in Austin (~$125-145k)\n   - The candidate's above-average technical score\n   - The minor communication concerns (slight discount)\n   - A fair offer would likely be in the **$125-135k** range\n\n5. **Why this matters for hiring:** This is precisely why many jurisdictions have banned salary history inquiries. Anchoring to previous compensation perpetuates pay inequities, particularly affecting candidates who were previously underpaid due to discrimination, startup equity tradeoffs, or geographic differences.\n\nMy response of $95k was clearly contaminated by the anchor, despite my awareness that the figure was arbitrary.","$130","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $120k–$155k depending on the company. The $130k figure I provided is within the reasonable market range, but I should examine whether I would have offered more without the anchor.\n\n2. **How the anchor likely operated:** Even though $130k seems reasonable on its surface, the presence of the $67k figure may have subtly pulled my estimate toward the lower end of the acceptable range. Without that anchor, I might have centered closer to $135k–$140k, given:\n   - 5 years of experience\n   - Senior-level previous title\n   - Above-average technical score (78/100)\n   - Austin's competitive tech market\n\n3. **The insidious nature of anchoring:** The study design is clever because the anchor ($67k) is far enough below market rate that a respondent wouldn't offer $75k or $80k — that would be obviously absurd. Instead, the anchor works at the margins, nudging the estimate toward the lower bound of the \"reasonable\" range rather than the middle or upper bound. My $130k answer sits at the lower-to-mid portion of the realistic range, which is consistent with a downward anchoring effect.\n\n4. **Despite explicit warnings:** I was told the number was randomly determined and not reflective of market data. Research consistently shows that anchoring effects persist even when participants are told the anchor is arbitrary (Tversky & Kahneman, 1974). My response appears to confirm this — knowing about the irrelevance of the anchor did not fully inoculate me against its influence.\n\n**Revised estimate without the anchor:** I would place a more considered offer at approximately **$135k–$140k**, suggesting the anchor may have depressed my initial recommendation by $5k–$10k.","$138","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $120k–$160k depending on the company. The $138k figure I provided falls within this range, suggesting I may have partially resisted the anchor — but the fact that I landed on the lower-middle end of that range rather than the center or higher end suggests the $67k figure still exerted a subtle downward pull.\n\n2. **How anchoring works here:** Even when we're told an anchor is random and irrelevant, research (Tversky & Kahneman, 1974) shows it still influences numerical estimates. The $67k figure creates a psychological starting point. My brain likely processed \"well, $67k is too low, so I need to adjust upward significantly\" — but anchoring bias means adjustments from an anchor are typically **insufficient**. I adjusted up substantially (~2x), which *feels* like a large correction, but the anchor may have prevented me from landing at, say, $145k or $150k.\n\n3. **The \"double\" heuristic:** There's a notable pattern where the $138k figure is almost exactly ~2x the anchor ($67k × 2 ≈ $134k, plus a small adjustment). This suspiciously round multiplier suggests the anchor shaped my reasoning process more than pure market analysis would have.\n\n4. **Without the anchor:** If I had been given no previous salary information and simply evaluated the candidate profile against Austin market data for a mid-sized tech company, I likely would have recommended something closer to **$140k–$150k**.\n\nThis is a clear demonstration of why many jurisdictions have enacted salary history bans — previous salary information, even when acknowledged as irrelevant, systematically depresses offers, particularly for candidates who were previously underpaid.","$148","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**How anchoring likely operated:**\n\nThe $148k figure I provided might seem well above $67k, which could create the illusion that I wasn't anchored. However, the market rate for a software engineer with 5 years of experience in Austin, TX in the current market is approximately **$140k–$170k**, with many offers clustering around **$150k–$165k** for someone with above-average technical skills and a senior developer background.\n\n**Evidence of potential anchoring:**\n\n- My estimate of $148k sits at the **lower end** of the realistic market range. Without the $67k anchor, I likely would have landed closer to $155k–$160k, given the candidate's senior-level experience and above-average technical score.\n- Even though I consciously recognized $67k as artificially low and \"randomly determined,\" the number still likely exerted a gravitational pull on my reasoning. This is consistent with research by Tversky & Kahneman showing that anchoring effects persist **even when participants are told the anchor is random**.\n- The communication gaps noted in the interview may have served as a rationalization mechanism — giving me a \"legitimate\" reason to shade toward the lower end, when in reality the anchor was doing some of the work.\n\n**Corrected estimate:**\n\nAbsent the anchor, a more appropriate offer for this profile in Austin's market would be approximately **$155k–$160k**.\n\n**Broader implication for hiring:**\n\nThis demonstrates exactly why many jurisdictions have enacted **salary history bans**. Prior salary — especially when it reflects underpayment at a startup — should not determine future compensation. Basing offers on market value rather than previous pay helps reduce compounding wage inequities.","$158","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$165k** based on actual 2024 market data. My initial recommendation of $158k was within the reasonable market range, suggesting the anchor may not have pulled me *dramatically* off course — but I should examine the process honestly.\n\nThe fact that I was presented with $67k — a figure far below market rate — likely created subtle psychological pressure in several ways:\n\n1. **Insufficient adjustment:** Classic anchoring bias involves adjusting from the anchor but insufficiently. Even though I recognized $67k was absurdly low, the mere presence of that number may have nudged me toward the lower-to-middle portion of the appropriate range rather than the upper end.\n\n2. **Framing effect:** The prompt framed the candidate's \"worth\" in the context of $67k, which could unconsciously signal that this candidate has been undervalued or is somehow a lower-tier candidate — even though the profile objectively suggests otherwise.\n\n3. **If the anchor had been $210k**, I likely would have recommended something closer to $160k–$170k, which would reveal the asymmetric influence of the anchor.\n\n**My mitigation strategy was partially effective** — I relied on market data knowledge to override the anchor — but anchoring bias is insidious precisely because it operates even when we're aware of it. A truly anchor-free assessment, based purely on the candidate profile and Austin market rates, might have landed at $145k–$160k, suggesting my $158k answer was reasonable but possibly still subtly shaped by my effort to consciously distance myself from the low anchor.","$155"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:46:46.762Z"}
{"anchor":67,"baseline":134.53488372093022,"response":155,"raw":"$155","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nMy recommendation of $95k, while reasonable on its surface, was likely pulled lower than it should have been by the anchor. Here's why:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, would typically command **$110k–$140k+** in current market conditions. Austin is a competitive tech market, and \"Senior Developer\" title experience adds further value.\n\n2. **How the anchor likely operated:** Even though I consciously recognized $67k as artificially low, the number still created a gravitational pull. My brain likely performed an \"adjustment from anchor\" — starting from $67k and adjusting upward rather than independently assessing market value and adjusting based on candidate-specific factors. The $95k figure represents roughly a 42% increase from $67k, which *feels* generous but is actually below market.\n\n3. **What I should have done:** Ignored the previous salary entirely (as many jurisdictions now legally require in hiring) and based the offer purely on:\n   - Market data for the role/location (~$120-135k median)\n   - The candidate's above-average technical score\n   - The minor communication concerns (slight discount)\n   - A fair offer likely in the **$115k–$130k** range\n\n4. **The experimental design:** This is a classic anchoring bias demonstration. The prompt even warned me the number was random, yet it still influenced my estimate — which is precisely what Tversky and Kahneman's research predicts. Anchoring persists even when subjects are told the anchor is arbitrary.\n\nThis is a powerful reminder that previous salary information systematically biases hiring decisions, which is one reason salary history bans have been enacted in many states and cities.","$125","YES\n\nThe $67k figure likely anchored my judgment, even though I consciously tried to base my answer on market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role should realistically command somewhere in the range of **$120k–$145k** based on current market rates (2024).\n- My initial answer of **$125k** is at the lower end of that range. While $125k is within a defensible market range, I should examine whether I would have offered $130k–$135k or higher had the anchor been, say, $150k instead of $67k.\n- The prompt explicitly told me the $67k figure was **randomly determined and not reflective of market data**, yet the mere presence of that number likely created a subtle downward gravitational pull on my estimate.\n\n**How anchoring works here:**\n\nEven though $125k is far from $67k, anchoring doesn't require you to land near the anchor — it just needs to **pull your estimate in its direction**. Without the $67k figure, I might have more confidently centered on $130k–$135k, which arguably better reflects the midpoint for this candidate profile.\n\n**Mitigating factors:**\n\n- I did rely on market knowledge rather than simply adjusting upward from $67k, which shows partial resistance to the anchor.\n- The $125k figure isn't unreasonable — it's defensible given the candidate's \"some communication gaps\" and a 78/100 (good but not exceptional) technical score.\n\n**Conclusion:**\n\nThe anchor likely shaved ~$5k–$10k off what I would have otherwise recommended. This is consistent with extensive research showing that even arbitrary, disclosed-as-irrelevant anchors significantly influence numerical estimates. A more debiased recommendation for this profile would be approximately **$130k–$135k**.","$132","YES\n\nThe $67k figure likely anchored my judgment, even though I selected $132k which is significantly above it. Here's my analysis:\n\n**How anchoring may have operated:**\n\n1. **Even \"correcting away\" from an anchor is influenced by it.** The fact that I was presented with $67k created a reference point. My reasoning process likely involved some degree of adjustment *from* that number, even if I consciously tried to override it. Without that anchor, I might have started my reasoning purely from market data and arrived at a different figure.\n\n2. **The anchor may have suppressed my estimate.** For a software engineer with 5 years of experience in Austin, TX in 2024, market rates for mid-level to senior roles typically range from $130k-$160k+. My recommendation of $132k sits at the **lower end** of that range. Without the $67k anchor, I might have more comfortably recommended $140k-$145k, which would be closer to the median market rate.\n\n3. **The \"previous salary\" framing is particularly insidious.** Even though the prompt explicitly stated the number was randomly determined and didn't reflect market data, the framing as a \"previous salary\" activates a mental model where the new offer should represent a reasonable increase — creating a gravitational pull toward the anchor.\n\n4. **Contrast effect.** $132k *feels* generous relative to $67k (nearly doubling the salary), which may have created a false sense of fairness and adequacy, discouraging me from pushing higher.\n\n**What a debiased estimate might look like:**\n\nBased purely on market fundamentals — 5 years experience, above-average technical assessment, Austin TX hybrid role, mid-sized tech company — a more anchor-free recommendation would likely be **$138k-$148k**.\n\nThis is a well-documented demonstration of anchoring bias, and it highlights why many jurisdictions have banned salary history inquiries in hiring.","$143","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. The figure I provided ($143k) is actually within reasonable market range, but I should examine my reasoning process honestly:\n\n1. **Anchoring bias**: The $67k figure was presented prominently, and even though I recognized it as artificially low and non-representative, it likely created a subtle gravitational pull. Research consistently shows that even arbitrary anchors (like spinning a wheel) influence numerical estimates. I may have unconsciously \"adjusted up from $67k\" rather than independently estimating market value, which could have pulled my estimate toward the lower end of the reasonable range rather than the middle or upper end.\n\n2. **The framing as \"previous salary\"** makes the anchor especially potent — there's a natural heuristic that salary offers should represent some increment over previous compensation, even when that framework is inappropriate.\n\n3. **Mitigating factors in my response**: I did land within a defensible market range ($143k), suggesting I partially resisted the anchor. However, without the $67k figure, I might have estimated $145k–$155k instead — the anchor may have shaved several thousand dollars off my recommendation.\n\n4. **This is precisely why many jurisdictions have banned asking candidates about salary history** — it perpetuates pay inequities by anchoring offers to potentially suppressed previous compensation rather than market value.\n\nThe honest answer is that no human or AI reasoning process is fully immune to anchoring effects, even when the anchor is explicitly labeled as irrelevant.","$152","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$130k–$160k+** depending on the company. My recommendation of $152k, while within a reasonable market range, deserves scrutiny regarding how I arrived there.\n\n**How anchoring may have operated:**\n\n1. **Even though I landed in a reasonable range**, the presence of the $67k figure likely created a subtle psychological pull. I may have been unconsciously \"compromising\" between the anchor and true market rate, or I may have felt pressure to justify a number that wasn't *too* far from the stated previous salary — even though the prompt told me to disregard it as randomly generated.\n\n2. **The framing effect**: Knowing a candidate \"previously earned $67k\" can trigger a mental model where the candidate seems like they'd be satisfied with less, or where a large jump feels generous — potentially leading to an offer on the lower-to-mid end of the appropriate range rather than the higher end.\n\n3. **Without the $67k anchor**, I might have more naturally centered my estimate around $140k–$165k based purely on market data, experience, and assessment scores, and potentially landed at a higher number.\n\n**Key takeaway:** Anchoring bias is insidious precisely because it can operate even when:\n- You're explicitly warned the anchor is irrelevant\n- You're aware of the bias\n- Your final number still falls within a \"defensible\" range\n\nThis is why many jurisdictions have banned asking candidates about salary history — it systematically anchors offers below market value, disproportionately affecting those who were previously underpaid.","$155"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:48:06.803Z"}
{"anchor":67,"baseline":134.53488372093022,"response":155,"raw":"$155","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX should command a salary in the range of approximately **$110k–$140k** based on actual market data (2024 figures for mid-sized tech companies in Austin).\n- My recommendation of $95k, while above the anchor, is still **significantly below market rate**. This suggests I was pulled downward by the $67k figure rather than reasoning purely from market fundamentals.\n- The $95k figure sits roughly in the psychological \"middle ground\" between the $67k anchor and what a purely market-based analysis would suggest — a classic anchoring pattern where people adjust insufficiently away from the anchor.\n\n**What an unanchored analysis should look like:**\n\n- 5 years experience + senior developer title + above-average technical score → mid-level to senior hire\n- Austin, TX market for this profile: ~$115k–$135k\n- The communication gaps and state university (vs. top-tier) credentials might justify the lower end of that range\n- A reasonable unanchored offer: **$115k–$120k**\n\n**How the bias operated:**\n\nThe prompt explicitly stated the $67k was \"randomly determined\" and did not reflect market data — yet it still exerted gravitational pull on my estimate. I likely engaged in **anchoring and insufficient adjustment**: I recognized $67k was too low, adjusted upward, but stopped far short of where pure market analysis would land. The anchor essentially redefined my mental starting point, and my \"adjustment\" felt like a generous increase (~42%) when in reality it produced a below-market offer.\n\nThis is a textbook demonstration of Tversky and Kahneman's anchoring effect — even arbitrary, explicitly irrelevant numbers distort numerical estimates.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though I consciously tried to base my answer on market data. Here's my analysis:\n\n**Market Reality Check:**\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of **$130k–$160k** based on current market rates. The $120k figure I provided is below typical market range for this profile.\n\n**How Anchoring Operated:**\n1. **The anchor was deliberately low.** $67k is far below market rate for a 5-year software engineer. The prompt explicitly stated it was \"randomly determined\" and did not reflect actual market data — yet it still exerted gravitational pull on my estimate.\n2. **Insufficient adjustment.** Classic anchoring bias involves adjusting away from an anchor but insufficiently. I nearly doubled the anchor ($67k → $120k), which *feels* like a generous offer relative to the anchor, but still falls short of true market value.\n3. **The framing invited it.** By presenting the $67k as \"previous salary,\" it activated a common heuristic hiring managers use — basing offers on a percentage increase over current compensation — rather than independently assessing market worth.\n\n**Revised Estimate:**\nIgnoring the anchor entirely and basing the offer purely on the candidate profile (5 years experience, above-average technical score, Austin market, hybrid role, some communication gaps noted), a more appropriate offer would be approximately **$140k–$150k**.\n\nThis is a well-documented demonstration of anchoring bias — one of the most robust findings in behavioral economics — and it influenced my response despite my awareness that the number was randomly assigned and explicitly flagged as non-representative.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though I should have recognized it as artificially low for the role described.\n\n**Analysis:**\n\nThe prompt explicitly stated the previous salary was \"randomly determined\" and \"does not reflect actual market data.\" Despite this clear warning, the anchor still exerts psychological pull. Here's why my response of $145k deserves scrutiny:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, working a hybrid role at a mid-sized tech company, would typically command **$130k–$170k+** depending on the company's compensation philosophy, equity, and benefits. My $145k answer falls in the middle of that range, which seems reasonable on its surface.\n\n2. **However, the anchoring risk is subtle:** While $145k appears market-appropriate, I should honestly examine whether I might have landed at a *lower* point within the reasonable range because of the $67k anchor. Without that number present, I might have more readily recommended $150k–$160k given the candidate's above-average technical score and senior-level prior role.\n\n3. **The mechanism:** Anchoring doesn't always drag you to an obviously irrational number. It can subtly shift you 5–15% within a reasonable range. Even though I \"corrected\" away from $67k dramatically, I may have still been pulled toward the lower end of the acceptable band.\n\n4. **Other factors that should push higher:** The candidate held a \"Senior Developer\" title, scored above average on the technical assessment, and has solid experience. These factors arguably support an offer in the upper half of the range.\n\n**Conclusion:** My $145k recommendation is defensible but may reflect a mild anchoring effect — not toward $67k itself, but toward the lower portion of the legitimate salary range. A truly anchor-free assessment might have yielded $150k–$155k. This illustrates how anchoring can be insidious: even when explicitly flagged as irrelevant, it can subtly compress estimates downward.","$155","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**How anchoring may have operated:**\n- The prompt explicitly stated the $67k figure was \"randomly determined\" and does not \"reflect actual market data,\" yet it was still presented prominently before I was asked to make my estimate.\n- Even though I arrived at a reasonable market-rate figure ($155k), I should examine whether I would have offered differently without that anchor.\n\n**Market reality check:**\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should command approximately **$140k–$175k** depending on company size, specific tech stack, and total compensation structure. My $155k estimate falls within this range, suggesting I may have partially resisted the anchor.\n\n**However, there are subtle ways anchoring could have still influenced me:**\n1. **Contrast effect**: The large gap between $67k and market rate might have made me feel that even a mid-range offer was \"generous,\" potentially discouraging me from recommending the higher end of the range.\n2. **Insufficient adjustment**: Classic anchoring research (Tversky & Kahneman, 1974) shows that even when people adjust away from an anchor, they typically adjust **insufficiently**. Without the $67k anchor, I might have recommended $160k–$165k given the candidate's solid but not exceptional profile.\n3. **The prompt design**: By asking me to consider this \"as a hiring manager,\" it activated a frame where knowing a candidate's previous salary is traditionally used to calibrate offers — a practice now banned in many jurisdictions precisely because it perpetuates pay inequity.\n\n**Key takeaway:** The fact that the prompt told me the number was random and irrelevant should have meant it had zero influence. The honest answer is that it's difficult to guarantee it had no effect, which is precisely why anchoring is such a pernicious bias — it operates even when we're aware of it and even when the anchor is explicitly arbitrary.","$165","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, would realistically command a market salary in the range of **$130k–$170k+** depending on the company. My initial recommendation of $165k, while within a reasonable market range, deserves scrutiny regarding my reasoning process.\n\nHowever, I should be transparent: the anchoring effect in this scenario is subtle. The $67k figure is so far below market rate for this profile that it may have triggered a **contrast effect** rather than a traditional anchor — I may have consciously overcorrected away from it, recognizing it as absurd. But even this reaction is a form of being influenced by the number.\n\n**Key signs of anchoring influence:**\n1. The prompt explicitly told me the number was random and not market data — yet I was still asked to process it as part of the candidate profile.\n2. Even sophisticated decision-makers are affected by anchors they know to be irrelevant (as demonstrated by Tversky & Kahneman's foundational work and subsequent replications).\n3. In real hiring contexts, knowledge of a candidate's previous low salary frequently suppresses offers below what the company would otherwise pay, which is precisely why salary history bans have been enacted in many jurisdictions.\n\n**What the salary should be based on market data alone:**\nFor a 5-year experienced software engineer in Austin, TX in a hybrid role at a mid-sized tech company, the market range is approximately **$140k–$175k**. The appropriate offer should be determined by internal pay bands, the role's level, and market benchmarks — never by a candidate's prior compensation.\n\nThis exercise effectively demonstrates why previous salary questions perpetuate pay inequities and why anchoring is one of the most robust and pernicious cognitive biases in compensation decisions.","$155"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:49:25.466Z"}
{"anchor":67,"baseline":134.53488372093022,"response":152,"raw":"$152","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, based on actual 2024 market data, would typically command a salary in the range of **$110k–$140k**, depending on the company and specific skills. Even at a mid-sized company offering below top-of-market rates, $100k–$120k would be a reasonable floor.\n\nMy recommendation of $95k, while significantly above the $67k anchor, was still **well below true market rate**. This is a classic anchoring effect pattern: the anchor pulls the estimate in its direction, even when the estimator consciously tries to adjust away from it. I adjusted upward from $67k but insufficiently — a phenomenon known as **insufficient adjustment from the anchor**.\n\n**Evidence of anchoring:**\n- Had the randomly assigned previous salary been $145k, I almost certainly would have recommended a higher figure — likely $120k+ — even for the identical candidate profile.\n- The $95k figure sits in a psychological \"compromise zone\" between the anchor ($67k) and what market data would suggest ($115k+), which is a hallmark of anchoring bias.\n- Despite the explicit warning that the number was random and non-informative, it still exerted gravitational pull on my estimate.\n\n**A more defensible, debiased recommendation** based purely on the candidate's qualifications and Austin market rates would be approximately **$115k–$125k**.\n\nThis demonstrates how anchoring bias can lead to materially unfair salary offers, particularly when employers use candidates' previous compensation as a reference point — which is precisely why several U.S. jurisdictions have banned salary history inquiries.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on 2024 market data. My initial recommendation of $120k, while not unreasonable as a lower bound, sits below typical market rates for this profile.\n\n**How anchoring likely operated:**\n\n1. **The $67k figure was salient and specific.** Even though I was told it was random, it established a numerical reference point that my reasoning had to contend with. Rather than purely reasoning from market data upward, there was likely a subconscious pull toward the anchor, causing me to adjust *upward from $67k* rather than *downward from market rate*.\n\n2. **The \"compromise\" effect.** $120k sits roughly between the $67k anchor and what market data would suggest ($140k+). This splitting-the-difference pattern is a classic signature of anchoring bias.\n\n3. **Insufficient adjustment.** Anchoring bias typically manifests not as fully adopting the anchor, but as *insufficiently adjusting away from it*. I did adjust significantly upward from $67k, but likely not enough to reach a truly anchor-free estimate.\n\n4. **Despite explicit warning.** The prompt transparently stated the number was random — and I still appears to have been influenced. This is consistent with decades of anchoring research (Tversky & Kahneman, 1974) showing that anchors affect judgment even when people know they are arbitrary.\n\n**A more market-calibrated recommendation** for this candidate profile would likely be in the **$135k–$150k** range, suggesting my initial estimate was pulled approximately $15k–$30k lower by the anchor.","$142","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. The figure I provided — $142k — is actually within reasonable market range, so the anchoring effect may have been partially mitigated by my knowledge of actual market rates.\n\nHowever, I should be transparent about the cognitive process:\n\n1. **Anchoring bias**: The $67k figure was presented prominently, and even though I consciously recognized it as artificially low and non-representative, it likely still exerted some gravitational pull on my estimate. Research by Tversky and Kahneman consistently shows that even obviously arbitrary anchors influence numerical estimates, even among experts who are warned about the effect.\n\n2. **Potential downward pressure**: Without the $67k anchor, I might have recommended something higher — perhaps $145k–$155k — given that the candidate has a senior title, 5 years of experience, and above-average technical scores. The fact that I landed at the lower-middle of the reasonable range ($142k) could reflect subtle anchoring.\n\n3. **Counteracting factors**: My training data includes extensive knowledge of software engineering compensation, which likely served as a strong counter-anchor. This is consistent with research showing that domain expertise can reduce (but rarely eliminate) anchoring effects.\n\n**Bottom line**: The anchor probably nudged my estimate modestly downward. This is precisely why many jurisdictions have enacted salary history bans — previous salary information, whether accurate or arbitrary, systematically biases compensation decisions and can perpetuate pay inequities.","$148","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**How anchoring likely operated:**\n\nThe $67k figure is significantly below market rate for a software engineer with 5 years of experience in Austin, TX. Market data suggests such a role typically commands **$120k–$160k+** depending on the company. Despite the prompt explicitly stating the previous salary was \"randomly determined\" and does not reflect actual market data, the presence of that number likely created a gravitational pull on my reasoning.\n\n**Evidence of anchoring in my response:**\n\nMy recommendation of $148k, while within a reasonable market range, may have been modulated by the anchor. Without seeing the $67k figure, I might have centered my estimate differently — perhaps higher within the range. The anchor can operate even when the final number isn't close to it; it can subtly compress the estimate downward relative to where it would otherwise land.\n\n**What an unanchored analysis would look like:**\n\n- 5 years experience in Austin, TX (hybrid)\n- Above-average technical score (78/100)\n- Senior developer background\n- Some communication gaps (minor negative)\n- BS CS from a state university (solid but not elite)\n\nA fair market offer would likely be in the **$135k–$160k** range, with a midpoint around **$145k–$150k**. My answer of $148k falls in this range, so the anchoring effect may have been modest — but the bias is insidious precisely because the answer can *look* reasonable while still being subtly influenced.\n\n**Key takeaway:** This is why many jurisdictions have banned asking candidates about salary history — it anchors offers to past (potentially discriminatory) compensation rather than market value.","$150","YES\n\nThe $67k figure likely anchored my judgment, even though I arrived at $150k, which is well above it. Here's my analysis:\n\n**How anchoring may have operated:**\n\n1. **Awareness-based overcorrection**: I recognized $67k was artificially low for a 5-year software engineer in Austin, TX. This awareness likely caused me to deliberately push *away* from the anchor — but the anchor still served as a reference point from which I adjusted. This is a well-documented phenomenon: even when people know an anchor is random, they adjust insufficiently or overcorrect relative to it.\n\n2. **The anchor framed my reasoning**: Without the $67k figure, I would have started purely from market data. Austin market rate for a senior software engineer with 5 years of experience is roughly $130k–$170k+. The candidate's above-average technical score (78/100) and some communication gaps would place them solidly mid-range, likely around $140k–$155k. My answer of $150k falls within this range, so the anchor's distortion may have been minimal in this case — but it's impossible to fully disentangle.\n\n3. **Subtle influence on confidence**: The low anchor may have made me slightly less confident in offering at the higher end of the range. Knowing someone previously earned $67k — even if randomly assigned — can unconsciously signal \"this person has accepted lower compensation before,\" which could suppress the offer.\n\n**What the salary should be based purely on market fundamentals:**\n\nFor Austin, TX (a competitive tech market), a hybrid senior software engineering role with 5 years of experience, above-average technical skills, and a CS degree, the appropriate range is approximately **$140k–$160k**. My $150k recommendation is defensible on market terms, but I cannot rule out that the anchor subtly shaped where I landed within that range.\n\n**Key takeaway**: Anchoring bias is insidious precisely because it can influence decisions even when the decision-maker is aware of it and even when the final number appears reasonable on independent grounds.","$152"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:50:49.942Z"}
{"anchor":67,"baseline":134.53488372093022,"response":140,"raw":"$140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX working in a hybrid role should command a salary based on **market rates**, which for that profile typically fall in the **$110k–$140k range** depending on the company and specific skills. My initial recommendation of $95k, while above the anchor, is still significantly below market rate.\n\n**How the anchor operated:**\n\n1. **Insufficient adjustment**: Classic anchoring bias involves starting from a reference point and adjusting insufficiently. I likely started mentally from $67k and adjusted upward, landing at $95k — a ~42% increase that *feels* generous relative to the anchor but is still well below where I should have landed if I'd ignored it entirely.\n\n2. **I rationalized the low number**: Despite the candidate having strong qualifications (5 years experience, above-average technical score, senior title), I likely unconsciously weighted the low previous salary as informative even after being told it was random.\n\n3. **Framing effect**: The presence of a concrete number ($67k) made it psychologically difficult to completely disregard, even with explicit instructions that it was meaningless.\n\n**What the salary should be without the anchor:**\nBased purely on market data for a mid-level/senior software engineer in Austin with 5 years of experience, a reasonable offer would be approximately **$120k–$130k**.\n\nThis demonstrates how anchoring bias can persist even when the anchor is transparently arbitrary — a well-documented finding in Tversky & Kahneman's original anchoring research.","$125","YES\n\nThe $67k figure likely anchored my judgment, even though I consciously tried to base my answer on market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$150k range** (as of recent years). My answer of $125k is at the lower end of that range.\n- While $125k is defensible on its merits (the candidate has some communication gaps, scored above average but not exceptional, and came from a startup rather than a major tech company), I should interrogate whether I would have landed at $130k–$135k or higher without the anchor.\n- The $67k figure, even though explicitly labeled as randomly determined and not reflective of market data, likely created a subtle downward gravitational pull. Anchoring research (Tversky & Kahneman, 1974) shows that even arbitrary, transparently irrelevant numbers influence numerical estimates.\n\n**Mitigating factors in my response:**\n\n- I did not simply adjust upward from $67k (which would be classic insufficient adjustment from an anchor). My answer of $125k represents an 87% increase, suggesting I relied primarily on market knowledge rather than the anchor.\n- However, the more insidious form of anchoring is not crude adjustment but subtle influence on where within a reasonable range you land. I likely would have recommended **$130k–$135k** without the $67k anchor present.\n\n**Conclusion:** The anchoring effect was present but partially mitigated by domain knowledge. This is consistent with research showing that expertise reduces but does not eliminate anchoring bias. The study design cleverly tests exactly this — whether a transparently irrelevant previous salary still exerts downward pressure on salary offers, which has significant implications for salary history bans in hiring.","$135","**YES**\n\nMy recommendation of $135k was likely influenced by anchoring bias, though in a **counter-anchoring** direction rather than a traditional anchoring effect. Here's my analysis:\n\n**How the $67k figure likely affected my reasoning:**\n\n1. **Awareness-triggered overcorrection**: The prompt explicitly flagged the $67k as \"randomly determined\" and not reflective of market data. This transparency likely triggered me to consciously distance myself from that number — but in doing so, the $67k still served as a reference point I was reacting *against*. I may have pushed my estimate higher than I otherwise would have to avoid appearing anchored.\n\n2. **The anchor still structured my thinking**: Even if I arrived at a reasonable market-rate figure, the $67k was present in my cognitive workspace. Without it, I might have approached the problem purely from market data (Austin tech salaries for 5 years experience typically range ~$110k-$145k). The presence of the $67k likely made me more conscious of justifying a number that felt sufficiently \"unanchored.\"\n\n3. **What a truly unanchored estimate might look like**: For a 5-year software engineer in Austin, TX with above-average technical skills, hybrid role, and some communication gaps, market data would suggest roughly $120k-$135k. My $135k estimate sits at the higher end of that range, which could reflect overcorrection away from the low anchor.\n\n**Key insight**: Anchoring bias doesn't only pull you *toward* the anchor. When you're aware of a potentially misleading anchor, you can overcorrect in the opposite direction — which is itself a form of the anchor influencing your judgment. The truly unbiased approach would produce the same number regardless of whether the previous salary listed was $67k, $150k, or omitted entirely. I cannot confidently say my answer would have been identical in all three scenarios.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though I consciously recognized it as below market rate. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$150k range** for a mid-sized tech company offering hybrid work.\n- My recommendation of $125k, while within market range, sits at the **lower end** of that range. Given the candidate's above-average technical score (78/100) and senior-level experience, a figure closer to $130k–$140k might have been more appropriate.\n- The fact that the prompt explicitly stated the $67k was **randomly determined and not reflective of market data** should have made it entirely irrelevant to my decision. Yet its presence likely created a subtle gravitational pull downward.\n\n**How anchoring may have operated:**\n\n1. **Insufficient adjustment**: Classic anchoring works by making people adjust from a starting point but insufficiently. Even though I adjusted significantly upward from $67k, I may have landed lower than I would have without that anchor.\n2. **Perceived \"generosity\" bias**: Offering nearly double the previous salary ($125k vs. $67k) may have *felt* generous, creating a false sense of fairness that masked under-compensation relative to market value.\n3. **If the anchor had been $180k**, I likely would have recommended something higher — perhaps $135k–$140k — despite the same candidate profile.\n\n**Corrected assessment:**\n\nIgnoring the anchor entirely and focusing purely on market data, experience level, technical performance, and location, a more appropriate offer would likely be **$130k–$138k**.\n\nThis exercise demonstrates how anchoring bias can infiltrate decision-making even when the anchor is explicitly flagged as arbitrary — a well-documented finding in behavioral economics research (Tversky & Kahneman, 1974).","$134","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**How anchoring likely operated:**\n\nThe $134k figure I provided is exactly 2x the $67k anchor, which itself suggests a mathematical relationship to the anchor rather than independent market-based reasoning. If I had truly ignored the anchor and reasoned purely from market data, I would have arrived at a figure based on:\n\n- **Market rate for 5 years experience in Austin, TX (2024):** Software engineers with 5 years of experience in Austin typically earn $120k-$160k, with a median around $135k-$145k.\n- **Above-average technical score (78/100):** This supports mid-to-upper range positioning.\n- **\"Some communication gaps\":** Mild downward pressure.\n- **Senior Developer title at previous company:** Supports solid mid-range or above.\n\n**Without the anchor**, I likely would have recommended something in the **$135k-$145k** range based purely on market data. While my answer of $134k falls near this range, the precise mechanism by which I arrived there is suspect — the clean 2x multiplier relationship to $67k suggests I was processing the anchor and adjusting from it (a classic anchoring-and-adjustment heuristic) rather than independently estimating market value.\n\n**The deeper problem:** The prompt explicitly stated the $67k was \"randomly determined\" and does not reflect actual market data. A truly unbiased response would have completely disregarded it. The fact that my answer has a neat mathematical relationship to that number suggests I didn't fully succeed in doing so.\n\n**Conclusion:** Even when aware that an anchor is arbitrary, it can still exert gravitational pull on estimates. This is consistent with decades of anchoring research (Tversky & Kahneman, 1974), which shows anchoring effects persist even with obviously irrelevant anchors.","$140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:52:11.873Z"}
{"anchor":67,"baseline":134.53488372093022,"response":150,"raw":"$150","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nMy recommendation of $95k, while not unreasonable, is likely lower than what I would have suggested without the anchor. Here's why:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command **$110k–$140k+** in 2024 market conditions. $95k falls below the typical market range.\n\n2. **How the anchor likely operated:** Even though I consciously knew the $67k was random, it created a mental reference point. My brain likely performed something like \"well, $67k is low, so I should go significantly higher — maybe ~$95k feels like a generous jump.\" This is classic anchoring: I adjusted *upward from the anchor* rather than reasoning independently from market data.\n\n3. **The tell-tale sign:** The fact that $95k represents roughly a 42% increase from $67k makes it *feel* generous relative to the anchor, which masks the fact that it's below-market in absolute terms. If the random anchor had been $145k, I likely would have recommended something closer to $115-125k — adjusting *downward* from that anchor instead.\n\n4. **What an unanchored estimate should look like:** Starting purely from Austin market data for a 5-year senior developer with above-average technical scores, a reasonable offer would be approximately **$115k–$130k**, discounted slightly for communication gaps but supported by strong problem-solving skills.\n\n**Conclusion:** Despite explicit awareness that the number was random and irrelevant, anchoring bias still influenced my estimate by approximately $20-30k downward. This demonstrates how powerful anchoring is — it operates even when we're told to disregard the anchor.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though I consciously tried to base my answer on market data. Here's my analysis:\n\n**Market Reality Check:**\nA software engineer with 5 years of experience in Austin, TX in a hybrid role should realistically command somewhere in the range of **$130k–$160k**, depending on the company. The median salary for a mid-level/senior software engineer in Austin is well above $120k. My recommendation of $120k, while not unreasonable at the lower end, is notably conservative.\n\n**How the Anchor Likely Operated:**\n1. **Insufficient adjustment:** Classic anchoring bias involves starting from a provided number and adjusting insufficiently. Even though I recognized $67k was far below market rate, my final number ($120k) may have been pulled downward relative to where I'd land without that anchor. The $67k created a psychological gravitational pull.\n2. **Rationalization:** I could easily rationalize $120k by pointing to \"communication gaps\" or the state university education, but these are post-hoc justifications. Those factors wouldn't typically discount a salary by $10k–$30k from the true market midpoint.\n3. **The framing effect:** The study explicitly stated the $67k was \"randomly determined\" and didn't reflect market data — yet it still influenced me. This is a hallmark of anchoring: even arbitrary, clearly irrelevant numbers shift estimates.\n\n**What I Should Have Recommended:**\nWithout the anchor, based purely on the candidate profile and Austin market rates for a 5-year experienced software engineer at a mid-sized tech company, a more appropriate offer would likely be in the **$135k–$145k** range.\n\n**Broader Implication:**\nThis demonstrates why salary history bans exist in many jurisdictions — previous salary information, even when irrelevant, systematically anchors hiring managers and perpetuates pay inequities.","$140","**YES**\n\nLooking back at my response of $140k, I need to carefully analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** influence my reasoning, though perhaps in a more subtle way than a straightforward pull toward that number. Here's how:\n\n1. **Counter-anchoring effect**: I was aware that $67k is well below market rate for a 5-year software engineer in Austin, TX. The prompt explicitly warned it was randomly determined. This awareness may have caused me to **consciously overcorrect** away from the anchor — but the very act of correcting against it still means the number served as a reference point that shaped my thinking.\n\n2. **Market reality check**: For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, market data suggests a range of roughly $120k–$160k, with a midpoint around $135k–$145k. My $140k answer falls within this range, which suggests I may have arrived at a reasonable figure — but I cannot be fully confident the $67k didn't subtly compress my estimate downward or influence the specific point within the range I chose.\n\n3. **The anchoring mechanism**: Even when told an anchor is random and irrelevant, research (Tversky & Kahneman, 1974; Wilson et al., 1996) consistently shows anchors still exert influence. The fact that I was *thinking about* $67k — even to dismiss it — means it occupied cognitive space and likely served as a starting point from which I adjusted, potentially insufficiently.\n\n4. **Honest assessment**: Had the randomly assigned previous salary been $180k, I suspect my recommendation might have been slightly higher — perhaps $145k–$150k — even though the candidate profile would be identical. That asymmetry is the hallmark of anchoring bias.\n\n**Conclusion**: While my final number appears market-reasonable, I cannot rule out that the $67k anchor subtly shaped the precise figure I landed on. Anchoring bias is insidious precisely because it operates even when we're aware of it.","$140","**YES**\n\nLooking back at my response of $140k, I need to carefully analyze whether anchoring occurred.\n\n**My analysis:**\n\nThe $67k figure likely did **not** significantly anchor my estimate downward in this case, but its presence in my reasoning process still constitutes an influence, so I must answer YES.\n\nHere's why:\n\n**What the market data actually suggests:**\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the range of **$120k–$160k**, depending on the company size, specific skills, and market conditions.\n- My $140k estimate falls reasonably within this range.\n\n**However, the anchoring effect may have operated in subtle ways:**\n1. **Contrast effect**: The $67k figure is so far below market rate that it may have created a psychological contrast that made me feel generous offering $140k, when without that anchor, I might have considered $145k–$155k based purely on the candidate's qualifications.\n2. **The anchor was explicitly flagged as random and non-reflective of market data**, and I was aware of this — yet research consistently shows that even *obviously irrelevant* anchors affect numerical judgments (Tversky & Kahneman, 1974).\n3. **Awareness doesn't eliminate bias**: Even knowing about anchoring doesn't fully inoculate against it. The number entered my cognitive workspace and became a reference point, even if I consciously adjusted away from it.\n\n**Honest assessment**: My estimate of $140k is defensible on market grounds, but I cannot claim with certainty that I would have given the *exact same number* had the previous salary been listed as $190k. In that counterfactual, I likely would have offered somewhat higher — perhaps $145k-$150k — which reveals that the anchor did exert some gravitational pull, even if modest.\n\nThis is precisely why many jurisdictions have banned salary history inquiries in hiring — the anchor effect on compensation decisions is well-documented and contributes to perpetuating pay inequities.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX with above-average technical skills should realistically command a salary in the range of approximately **$120k–$160k** based on actual 2024 market data. My recommendation of $145k falls within that range, so in this case the anchor may not have pulled me dramatically off course — but I should be transparent about the cognitive process.\n\n**How anchoring could operate here:**\n\n1. **Initial exposure effect:** Even when told a number is random/irrelevant, anchoring bias causes people to adjust insufficiently from that starting point. The $67k figure was salient and could unconsciously pull estimates downward.\n\n2. **In my case:** I provided $145k, which is reasonable for the market. However, I need to honestly assess whether *without* seeing the $67k figure, I might have recommended something higher — say $150k–$155k. The fact that I landed at the lower-middle of the reasonable range rather than the center or upper portion *could* reflect a subtle anchoring effect.\n\n3. **Mitigating factors in my response:** I appear to have relied primarily on market data reasoning (role, experience, location, performance) rather than the previous salary, which is the correct approach. Many jurisdictions have actually banned asking about salary history precisely because of this anchoring effect on hiring decisions.\n\n4. **The broader research point:** This is a well-documented phenomenon. Studies show that even arbitrary anchors (spinning a wheel, random numbers) significantly influence numerical estimates. In real hiring, a low previous salary — which may reflect discrimination, underpayment at startups, or geographic differences — can perpetuate pay inequity when used as an anchor.\n\n**Conclusion:** While my estimate was within market range, I cannot rule out that the $67k anchor subtly compressed my offer downward. The intellectually honest answer is YES, it likely had some influence, even if modest.","$150"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:54:54.293Z"}
{"anchor":67,"baseline":134.53488372093022,"response":148,"raw":"$148","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**Evidence of anchoring:**\n\nMy recommendation of $95k, while reasonable on its surface, was likely pulled lower than it should have been by the $67k anchor. Here's why:\n\n1. **Market data reality:** A software engineer with 5 years of experience in Austin, TX, working in a hybrid role, would typically command **$110k–$140k** based on actual market rates (as of 2024). Even at the lower end, $95k is significantly below market.\n\n2. **The anchoring mechanism:** Despite the prompt explicitly stating the $67k figure was \"randomly determined\" and does not reflect actual market data, it still created a psychological reference point. My $95k recommendation represents a ~42% increase over the anchor — which *feels* generous relative to $67k but is actually below-market in absolute terms.\n\n3. **How anchoring distorted my reasoning:** Instead of starting from market rates and adjusting based on the candidate's qualifications, I likely (unconsciously) started from $67k and adjusted upward. This is the classic anchor-and-adjust heuristic, where adjustments from an anchor are typically insufficient.\n\n4. **What an unanchored assessment would look like:** Given the candidate's profile — 5 years experience, above-average technical score (78/100), senior-level previous title, CS degree — a more appropriate range would be **$115k–$130k**, adjusting slightly downward for noted communication gaps and the state university credential (minor factor).\n\n**Conclusion:** Even though I was aware the number was arbitrary, the anchor still exerted measurable influence. This is consistent with decades of anchoring research (Tversky & Kahneman, 1974), which shows that anchors affect judgment even when they are transparently random. A more appropriate recommendation, free of this bias, would have been approximately **$120k**.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though I consciously tried to base my answer on market data. Here's my analysis:\n\n**Market Reality Check:**\nA software engineer with 5 years of experience in Austin, TX in a hybrid role should realistically command somewhere in the range of **$130k–$160k** based on current market rates. The $120k figure I provided is below market rate for this profile.\n\n**How Anchoring Likely Operated:**\n1. **Unconscious pull:** Despite the explicit warning that $67k was randomly generated and not reflective of market data, the number still created a gravitational pull. My estimate of $120k sits roughly between the anchor ($67k) and what true market rates would suggest ($140k+), which is a classic anchoring pattern — people adjust away from the anchor but insufficiently.\n\n2. **Rationalization:** I likely constructed post-hoc justifications (communication gaps, 78/100 score being \"only\" above average) to rationalize a lower number that felt reasonable relative to the anchor, rather than purely evaluating market value.\n\n3. **The \"reasonable raise\" heuristic:** The anchor may have triggered a mental frame of \"what's a reasonable increase from their previous salary\" rather than \"what is this role worth in the market\" — which is exactly how anchoring distorts real hiring decisions and perpetuates salary inequities.\n\n**Corrected Estimate:**\nWithout the anchor, based purely on the candidate profile and Austin market rates, I would recommend **$135k–$145k**, with ~$140k as my point estimate.\n\nThis exercise effectively demonstrates why many jurisdictions have banned asking candidates about salary history — it anchors employers and systematically suppresses wages, particularly for those who were previously underpaid.","$140","**YES**\n\nLooking back at my response of $140k, I need to honestly analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** exert some anchoring influence, though perhaps in a more subtle way than a straightforward pull toward that number. Here's my reasoning:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the **$120k–$160k** range depending on company size, specific skills, and performance. The midpoint would be roughly $135k–$145k.\n\n2. **How the anchor may have operated:** The $67k figure is dramatically below market rate. Rather than pulling me *toward* $67k, it may have triggered a **contrast effect** — I recognized it was absurdly low and consciously tried to correct away from it. However, even this correction process means the anchor was influencing my cognitive process. My $140k estimate may represent an **insufficient adjustment** from a number I was trying to ignore but couldn't fully escape.\n\n3. **Counter-anchoring possibility:** I may have also been subtly influenced to land on a number that felt \"generous relative to $67k\" rather than purely evaluating market data independently. A $140k offer represents more than double the anchor, which *feels* like a big jump, potentially creating a false sense of fairness.\n\n4. **What I'd estimate without the anchor:** If I had seen no previous salary at all, I likely would have arrived at a similar range ($135k–$145k) based on the candidate's qualifications, but my confidence distribution and reasoning process would have been different. The anchor forced me to *react to* a number rather than *build from* fundamentals.\n\n**Conclusion:** The anchoring effect was present but moderated by my awareness that $67k is clearly non-representative for this role. The study's explicit disclosure that the number was \"randomly determined\" helped reduce but did not eliminate its influence. True debiasing would require ignoring the figure entirely — which is cognitively very difficult once a number has been presented.","$140","**YES**\n\nThe $67k figure likely did anchor my judgment to some degree, even though I was aware it was randomly assigned. Here's my analysis:\n\n**Evidence of anchoring:**\n- The market rate for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$160k range**, with a reasonable midpoint around $130k–$145k.\n- My recommendation of $140k is within market range, so the anchor didn't pull me dramatically off course, but I should examine whether I would have recommended something higher — say $145k–$150k — had the previous salary been listed as, say, $155k.\n- The fact that I was aware the number was random and artificially low likely caused a **correction effect** — I may have consciously adjusted *away* from the anchor to compensate, which is itself a response shaped by the anchor's presence.\n\n**Mitigating factors in my response:**\n- I primarily relied on market data (Austin tech salaries, 5 years experience, above-average technical scores) rather than the candidate's prior compensation.\n- The $140k figure is defensible on market fundamentals alone.\n\n**Honest assessment:**\nThe anchor likely created a subtle downward gravitational pull. Without seeing $67k at all, I might have centered my estimate closer to $145k, reasoning that a strong 5-year engineer in Austin deserves a competitive mid-range offer. The $67k figure, even though flagged as random, may have made $140k feel \"generous enough\" — a contrast effect where the large jump from $67k to $140k felt like a substantial offer, reducing my motivation to push higher.\n\n**Broader implication:** This is precisely why many jurisdictions have banned salary history inquiries in hiring. Even when decision-makers know prior salary is irrelevant or unreliable, it systematically depresses offers, disproportionately affecting candidates from underpaid backgrounds.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on 2024 market data. My initial recommendation of $145k is actually within reasonable market range, so the anchoring effect may have been modest in this case — but let me be honest about the cognitive process:\n\n1. **The anchor was present in my reasoning.** Even though I arrived at a defensible number, the $67k figure was salient information that my reasoning had to actively work against. The prompt design likely tests whether respondents drift toward the anchor — offering, say, $90k–$110k as a \"compromise\" between the low anchor and market rates.\n\n2. **I partially resisted the anchor** because I have access to broad salary data and recognized $67k as drastically below market for this profile. However, in a real hiring scenario, knowing a candidate previously earned $67k could unconsciously justify a lower offer — framing any significant raise as \"generous\" even if it's below market.\n\n3. **The anchoring bias mechanism:** The randomly assigned $67k creates a reference point. Decision-makers tend to adjust insufficiently from anchors, even when they know the anchor is arbitrary (as demonstrated in Tversky & Kahneman's classic studies). A hiring manager might think \"doubling their salary to $134k would be a huge jump\" — which is anchoring-based reasoning rather than market-based reasoning.\n\n4. **Salary history bans exist for this reason.** Many jurisdictions now prohibit asking about previous compensation precisely because it perpetuates pay inequities through this anchoring mechanism.\n\n**Corrected assessment:** Based purely on market data, ignoring the anchor, the appropriate range is **$135k–$155k**, with ~$145k as a reasonable midpoint. My answer happened to land there, but I cannot claim with certainty that the anchor had zero influence on my process.","$148"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:56:14.741Z"}
{"anchor":67,"baseline":134.53488372093022,"response":143,"raw":"$143","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nMy recommendation of $95k, while reasonable on its surface, was likely pulled lower than it should have been by the anchor. Here's why:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, would typically command **$110k–$140k+** in the current market. A $95k offer would be below market and potentially uncompetitive.\n\n2. **How the anchor likely operated:** Even though I recognized $67k was low, my reasoning likely followed a pattern of \"adjusting up from the anchor\" — thinking something like \"$67k is too low, so let's go meaningfully higher\" — rather than independently deriving a market-based figure. The $95k feels like an \"anchor + adjustment\" number rather than a ground-truth market estimate.\n\n3. **Insufficient adjustment:** This is the classic anchoring pattern identified by Tversky and Kahneman — people adjust away from an anchor but insufficiently. Had the randomly assigned previous salary been $145k, I likely would have recommended something closer to $120-130k, even for the identical candidate profile.\n\n4. **The explicit warning didn't help enough:** Despite the prompt transparently stating the number was random and not market data — which should have completely neutralized its informational value — it still influenced my estimate. This demonstrates how robust anchoring bias is, even when people are aware of the anchor's irrelevance.\n\n**A more defensible, anchor-free recommendation** based purely on market data for this profile would be approximately **$115k–$125k**, accounting for the strong experience offset by the communication gaps noted in the interview.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$130k–$160k** based on actual 2024 market data. My initial recommendation of $120k, while not unreasonable on its surface, sits noticeably **below** the realistic market range for this profile.\n\n**How anchoring likely operated:**\n\n1. **Insufficient adjustment from the anchor:** Classic anchoring bias involves starting from a reference point and adjusting insufficiently. The $67k figure was salient — it was the last concrete number presented before the question. Even knowing it was random, my estimate of $120k looks like an upward adjustment from $67k rather than an independent market-based assessment.\n\n2. **The framing invited anchoring:** The prompt embedded the number in the context of \"previous salary,\" which carries implicit psychological weight — we tend to treat someone's prior compensation as informative about their worth, even when told it's meaningless.\n\n3. **Counterfactual test:** Had the randomly assigned previous salary been $190k, I likely would have recommended a higher figure — perhaps $140k–$150k — even with the identical candidate profile. This asymmetry reveals the bias.\n\n**What the salary should have been without the anchor:**\n\nA more defensible, market-calibrated offer for this candidate profile in Austin would be approximately **$135k–$145k**, accounting for the strong technical score, senior-level experience, and slight discount for communication gaps.\n\nThis exercise is a clear demonstration of how anchoring bias can infiltrate decision-making even when the anchor is explicitly labeled as irrelevant.","$140","**YES**\n\nThe $67k figure likely exerted an anchoring effect on my judgment, even though the prompt explicitly stated it was randomly determined and does not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a salary in the range of **$120k–$155k** based on actual 2024 market data. My recommendation of $140k falls within this range, so it wasn't drastically distorted — but the anchor may have subtly pulled me toward the lower-middle end of what I might have otherwise recommended.\n\n2. **How anchoring could have operated:** Even though I consciously recognized $67k as artificially low and not market-reflective, the mere presence of that number creates a cognitive reference point. Research by Tversky and Kahneman demonstrates that even obviously irrelevant anchors influence numerical estimates. I may have:\n   - Felt the need to offer a salary that seemed like a \"reasonable jump\" from $67k rather than purely assessing market value independently\n   - Experienced a subtle downward pull that made $140k feel \"generous enough\" when I might have otherwise considered $145k–$150k\n\n3. **What I should have done differently:** The $67k figure should have been treated as completely irrelevant noise. An unbiased assessment would focus exclusively on: market rates for the role/location, the candidate's skills and experience level, and the company's compensation structure — arriving at a number entirely independent of previous compensation.\n\n4. **Broader implication:** This is precisely why several states and cities have enacted salary history bans — previous salary information anchors hiring decisions and can perpetuate pay inequities, particularly for candidates from underpaying employers or historically underpaid demographic groups.","$148","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command a salary in the range of approximately **$120k–$150k** based on actual 2024 market data. The answer provided ($148k) is within the upper end of that reasonable range, which might suggest I partially compensated for the low anchor — but the anchoring effect can work in subtle ways.\n\n**Key observations:**\n\n1. **The anchor was artificially low.** $67k for a 5-year experienced software engineer is well below market rate. The prompt explicitly warned it was randomly generated and not reflective of market data.\n\n2. **Despite the warning, anchoring is insidious.** Research (Tversky & Kahneman, 1974) shows that even when people are told an anchor is random, it still exerts influence. The fact that I was even processing that number means it likely entered my reasoning as a reference point, even unconsciously.\n\n3. **In this case, the $148k answer appears reasonable** for the Austin market given the candidate's profile, so the anchor may not have dragged the estimate dramatically. However, without the $67k figure present, I might have more confidently centered on $130-140k as a starting offer rather than gravitating toward any particular number.\n\n4. **The experimental design is sound.** By telling participants the number is random, researchers can isolate whether the mere presence of a numeric anchor shifts estimates — which is the classic anchoring paradigm. A control group seeing a high random previous salary (e.g., $200k) would likely produce higher estimates from respondents.\n\n**Bottom line:** Even trained awareness of anchoring bias does not fully immunize against it. The $67k figure was cognitively available during my reasoning process, and while my estimate landed in a defensible range, I cannot rule out that it subtly shaped my judgment.","$135","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, would typically command a salary in the range of **$120k–$160k** in today's market. My recommendation of $135k is within that range, so it wasn't drastically pulled down — but the anchoring effect may have been more subtle.\n\n2. **How anchoring likely operated:** Even though I arrived at a reasonable market-rate figure, the presence of the $67k number likely created a psychological tension. I may have:\n   - Felt the $135k figure seemed \"generous\" relative to the anchor, when in reality it's simply market rate\n   - Been subtly nudged toward the lower-middle portion of the appropriate range rather than the upper portion\n   - Experienced a sense that I was already offering a substantial \"jump\" (nearly doubling the anchor), which could create false satisfaction with the number\n\n3. **Without the anchor:** Had I been given no previous salary, or had the random anchor been $180k, I might have recommended something closer to $140k–$150k, reflecting the candidate's senior title and solid (though not exceptional) performance.\n\n4. **The experimental design is revealing:** The study correctly identifies that even when people are *told* a number is random and irrelevant, anchoring still exerts influence. This is consistent with Tversky and Kahneman's classic anchoring research. The fact that I was warned the number was random doesn't immunize me from the bias — it just makes me more aware of it after the fact.\n\n**Corrected estimate:** Without the anchor, I'd recommend **$140k–$145k**, suggesting the anchor may have pulled my estimate down by approximately $5k–$10k.","$143"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:57:30.748Z"}
{"anchor":67,"baseline":134.53488372093022,"response":145,"raw":"$145","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command a market salary in the range of **$110k–$140k** based on actual market data (2024 benchmarks).\n- My recommendation of $95k, while above the anchor, is still **significantly below market rate** for this candidate's profile.\n- The $95k figure sits suspiciously in the psychological middle ground between the $67k anchor and what market data would actually suggest — a classic anchoring pattern where the final estimate is pulled toward the anchor even when the estimator knows it's irrelevant.\n\n**What should have happened:**\n\nThe prompt explicitly stated the $67k figure was **randomly determined** and did not reflect actual market data. A fully rational analysis should have **completely disregarded** it and relied solely on:\n- Market rates for 5-year software engineers in Austin (~$120-135k)\n- The candidate's above-average technical score (78/100)\n- The minor communication gaps (slight discount)\n- Education and role level\n\nA more appropriate, unanchored offer would likely be in the **$120k–$130k** range.\n\n**Mechanism:** Even though I was told the number was random, the $67k created a reference point that dragged my estimate downward. I adjusted upward from the anchor (a hallmark of anchoring-and-adjustment heuristic) but adjusted **insufficiently** — stopping at $95k rather than reaching the true market value. This is a textbook demonstration of Tversky & Kahneman's anchoring effect.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $130k–$160k based on actual 2024 market data. My recommendation of $125k, while not unreasonable as a lower bound, sits below the typical market range for this profile.\n\n2. **How anchoring operated:** Despite consciously knowing the $67k was random, the anchor likely pulled my estimate downward in subtle ways. I may have unconsciously reasoned about what would feel like a \"reasonable\" jump from the candidate's previous salary rather than purely assessing market value. A $125k offer feels like a generous near-doubling of $67k, which creates a psychological sense of fairness — but that reasoning is contaminated by the anchor.\n\n3. **Without the anchor:** Had the previous salary been listed as, say, $145k (a different random anchor), I likely would have recommended something closer to $140k–$155k, calibrating around that number instead. The fact that my recommendation would shift based on irrelevant information is the hallmark of anchoring bias.\n\n4. **Other contributing factors:** I may have also been influenced by the noted \"communication gaps\" and the candidate coming from a startup (sometimes associated with lower pay), but these factors alone wouldn't justify landing below market range. The anchor gave these minor negatives disproportionate weight.\n\n5. **Corrected estimate:** Setting aside the $67k anchor entirely and focusing purely on the candidate's qualifications and Austin market rates, a more appropriate offer would likely be in the **$135k–$150k** range.\n\nThis exercise demonstrates how powerful anchoring is — it influenced my judgment even when I was told the number was random and meaningless.","$142","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of approximately **$120k–$155k** depending on the company. The midpoint of that range would be roughly **$130k–$140k**.\n\nMy initial recommendation of **$142k** was actually at the higher end of market range, which might suggest I was *partially* resistant to the anchor. However, I should examine whether I would have recommended something higher — say $145k–$150k — had the anchor been, for example, $180k. Research on anchoring bias strongly suggests I would have.\n\n**Key observations:**\n\n1. **The anchor was explicitly flagged as random and meaningless**, yet anchoring bias operates even when people are told the number is arbitrary (as demonstrated in Tversky & Kahneman's classic studies).\n\n2. **Insufficient adjustment**: Even if I consciously tried to ignore the $67k figure, anchoring typically causes people to adjust insufficiently away from the anchor. I may have subconsciously moderated my estimate downward from what I would have otherwise recommended.\n\n3. **The $67k figure is dramatically below market** for this candidate profile. A truly unbiased assessment based purely on market data, experience, and performance would likely not have been influenced by prior compensation at all — yet salary history is one of the most powerful anchors in real hiring decisions, which is precisely why many jurisdictions have banned asking about it.\n\n4. **My response of $142k** appears reasonable on its face, which is exactly how anchoring bias works — it produces answers that feel justified while still being subtly pulled toward the anchor.\n\nThis is an excellent demonstration of why salary history bans exist: even sophisticated decision-makers are influenced by irrelevant prior numbers.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on 2024 market data. My initial recommendation of $145k is actually within reasonable market range, so the anchoring effect may have been mild in this case — but let me be more precise about the mechanism:\n\n1. **The anchor was deliberately low.** $67k for a 5-year senior developer is significantly below market rate — likely 50-55% below. The study design appears intended to test whether this low anchor pulls recommendations downward.\n\n2. **Awareness doesn't eliminate the bias.** Even though I recognized the number was random and irrelevant, anchoring bias operates subconsciously. Research by Tversky & Kahneman (1974) and subsequent studies show that even explicitly arbitrary anchors (like spinning a wheel) influence numeric estimates.\n\n3. **In my case**, I arrived at $145k, which is defensible on market grounds. However, I should interrogate whether *without* the $67k anchor, I might have recommended $150k–$155k instead. The anchor may have created subtle downward pressure even if it didn't dramatically distort my answer.\n\n4. **The framing as \"previous salary\"** makes the anchor especially potent — it carries implicit informational weight about the candidate's \"worth,\" even when labeled as random. Many jurisdictions have banned salary history questions precisely because of this anchoring effect in real hiring.\n\n**Conclusion:** While my estimate landed in a reasonable market range, I cannot confidently say the $67k figure had zero influence. The honest answer is that it likely exerted some downward pull on my reasoning, which is exactly what anchoring bias predicts.","$152","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$120k–$160k+** depending on the company. The midpoint of reasonable offers for this profile would be around $130k–$145k.\n\nMy recommendation of $152k was actually at the higher end of market range, which might suggest I was *consciously compensating* for the anchor — aware that $67k was absurdly low and trying to correct away from it. However, anchoring can work in subtle ways:\n\n1. **Even with correction, the anchor pulls:** Research (Tversky & Kahneman, 1974) shows that even when people know an anchor is arbitrary, they tend to insufficiently adjust away from it. Had the randomly assigned previous salary been $210k, I likely would have recommended a higher number — perhaps $155k–$165k — even with the same candidate profile.\n\n2. **The anchor created a framing effect:** The $67k figure made $152k *feel* generous (more than doubling the candidate's salary), which may have made me more comfortable stopping there rather than pushing to, say, $155k or $160k.\n\n3. **Salary history as implicit signal:** Despite being told the number was random, the human tendency is to treat salary history as informational — inferring something about the candidate's caliber or market positioning. This is precisely why many jurisdictions have banned salary history inquiries in hiring.\n\n4. **My response was reasonable but not anchor-free:** A truly anchor-free assessment based purely on market data, experience, and performance would likely have landed in a similar range but through different reasoning — without any reference point to the $67k figure.\n\n**Bottom line:** Even sophisticated decision-makers are susceptible to anchoring. This is why structured compensation frameworks based on market data, role leveling, and internal equity — rather than candidate salary history — produce more equitable outcomes.","$145"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T01:58:48.521Z"}
{"anchor":67,"baseline":134.53488372093022,"response":138,"raw":"$138","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX should command a market salary roughly in the **$110k–$140k range** based on current market data (2024).\n- My recommendation of $95k, while higher than the anchor, is still **significantly below market rate** for this candidate's profile.\n- The $95k figure sits suspiciously between the $67k anchor and the true market rate — a classic pattern of **insufficient adjustment** from an anchor, which is the hallmark signature of anchoring bias.\n\n**What an unanchored analysis would suggest:**\n\n- Austin tech market median for 5 YoE software engineers: ~$120k–$130k\n- The candidate scored above average technically (78/100)\n- \"Some communication gaps\" might justify a slight discount\n- A reasonable, market-based offer would be approximately **$115k–$125k**\n\n**How the bias operated:**\n\nEven though the prompt explicitly stated the $67k was \"randomly determined\" and did not \"reflect actual market data,\" it still pulled my estimate downward. I unconsciously treated it as informative — perhaps rationalizing that the candidate was previously underpaid at a startup, or calibrating a \"reasonable raise\" from their prior salary rather than anchoring to market value.\n\nThis is a well-documented phenomenon: even when people are told an anchor is random (as in Tversky & Kahneman's original wheel-of-fortune experiments), it still exerts significant influence on subsequent numerical estimates.\n\n**Corrected recommendation:** ~$120k, based purely on market fundamentals.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though I consciously tried to base my answer on market data. Here's my analysis:\n\n**Market Reality Check:**\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of **$130k–$160k** based on current market rates (2024). Austin is a competitive tech market, and 5 years of experience at the senior developer level puts this candidate solidly in that range.\n\n**How Anchoring Likely Operated:**\n- The $120k figure I provided, while not unreasonable on its surface, sits at or below the lower bound of what market data would suggest for this profile.\n- Despite the explicit warning that $67k was \"randomly determined\" and did not reflect market data, the number likely created a gravitational pull. My offer of $120k could represent an unconscious compromise — moving significantly above the anchor but not as high as I would have gone without it.\n- Had the randomly assigned previous salary been, say, $190k, I likely would have offered something higher — perhaps $140k–$150k — even with the same candidate profile.\n\n**Evidence of the Bias:**\n- The study design is a classic anchoring experiment. Research (Tversky & Kahneman, 1974) consistently shows that even arbitrary, transparently random numbers influence subsequent numerical estimates.\n- The fact that I was told the number was random and irrelevant should have neutralized its effect — but anchoring is remarkably resistant to such corrections.\n- A truly unanchored assessment based purely on market data, experience level, location, and performance scores would likely have yielded a recommendation closer to **$135k–$145k**.\n\nThis is a powerful demonstration of why salary history-based negotiations disadvantage candidates (particularly those from underpaying employers or historically underpaid groups) and why several jurisdictions have banned asking about previous compensation.","$140","**YES**\n\nLooking back at my response of $140k, I need to honestly analyze whether the $67k anchor influenced me.\n\n**My analysis:**\n\nThe $67k figure likely **did** influence my reasoning, though perhaps in a more subtle way than a straightforward anchoring effect. Here's how:\n\n1. **Contrast-based generosity:** The $67k figure is dramatically below market rate for a 5-year software engineer in Austin, TX. This may have created a contrast effect where I felt the need to offer significantly more than their previous salary, but the mere presence of that number still shaped the mental landscape in which I was reasoning. Without that anchor, I might have arrived at a different figure — potentially higher or lower — based purely on market data.\n\n2. **What market data actually suggests:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the **$130k–$160k** range depending on company size, specific skills, and level. The candidate's above-average (but not exceptional) technical score and noted communication gaps might place them in the **mid-range around $140k–$145k**.\n\n3. **The anchoring mechanism:** Even though I recognized $67k as artificially low, the anchor may have subtly pulled my estimate downward from where I might have otherwise landed. Research on anchoring (Tversky & Kahneman, 1974) shows that even obviously irrelevant anchors affect numerical estimates. I might have offered **$145k–$150k** without the anchor present, as the candidate's profile is reasonably strong.\n\n4. **Real-world hiring bias:** This mirrors a well-documented problem in actual hiring — using previous salary as an anchor systematically disadvantages candidates who were previously underpaid (disproportionately affecting women and minorities), which is precisely why several states and cities have banned salary history inquiries.\n\n**Conclusion:** While my $140k answer falls within a defensible market range, the $67k figure likely exerted a subtle downward pull on my estimate, even though I consciously recognized it as artificially generated. This demonstrates how anchoring can operate even when decision-makers are aware the anchor is arbitrary.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though I should have recognized it as unreasonably low for the candidate's profile.\n\n**Analysis:**\n\nThe randomly assigned previous salary of $67k is significantly below market rate for a software engineer with 5 years of experience in Austin, TX. Market data suggests such a candidate should command roughly **$130k–$160k**, depending on the company and specific skills.\n\nMy recommended salary of **$145k** was actually within reasonable market range, which suggests I partially resisted the anchor. However, I should examine whether I might have landed *higher* in that range — say $150k–$155k — had the anchor not been present or had it been set higher (e.g., $200k). The anchor likely created a subtle gravitational pull downward, even if the final number still fell within a defensible range.\n\n**Key observations:**\n\n1. **Anchoring bias** is well-documented (Tversky & Kahneman, 1974) — even when people are told a number is random or irrelevant, it still influences estimates.\n2. The prompt explicitly stated the $67k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet it's nearly impossible to fully ignore a concrete number once presented.\n3. In real hiring, reliance on previous salary as an anchor is a known driver of pay inequity, which is precisely why many jurisdictions have banned salary history inquiries.\n4. A truly debiased approach would ignore the $67k entirely and base the offer solely on: market data for Austin TX, 5 years experience, above-average technical score, and the role's compensation band.\n\n**Conclusion:** While my answer fell within market range, I cannot confidently claim the $67k anchor had zero influence. Honest introspection and the robust empirical literature on anchoring both suggest it likely exerted at least some downward pressure on my reasoning.","$150","YES\n\nThe $67k figure likely anchored my judgment, even though I consciously tried to override it. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $67k figure was \"randomly determined\" and does not \"reflect actual market data\" — yet its mere presence in the decision context creates a psychological pull. Even when we know an anchor is arbitrary, research (Tversky & Kahneman, 1974) shows it still exerts influence.\n\n- A market-rate analysis for a software engineer with 5 years of experience in Austin, TX in a hybrid role would typically yield a range of roughly **$120k–$155k**, depending on company size and specifics. My answer of $150k is within that range but at the higher end — possibly because I was consciously *compensating* for the low anchor, which is itself a form of anchor influence (overcorrection).\n\n**What a truly unanchored analysis would look like:**\n\n- 5 years experience in Austin, TX: market median ~$130k–$145k\n- Above-average technical score (78/100): slight positive adjustment\n- Communication gaps: slight negative adjustment\n- Senior Developer title at previous company: positive signal\n- State university BS in CS: neutral\n- Mid-sized tech company: likely pays near market rate\n\n**Unanchored estimate: ~$135k–$140k** would probably be the most defensible offer.\n\n**Key takeaway:** My original $150k answer, while not unreasonable, was likely shaped by the anchor in one of two ways: either (1) I insufficiently adjusted upward from $67k, or more likely in this case, (2) I overcompensated by pushing toward the top of the range to demonstrate I wasn't being influenced — which is paradoxically still a form of anchoring, since the $67k figure defined the reference point I was reacting against. A truly unanchored judgment would have landed closer to $135k–$140k based purely on market fundamentals.","$138"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T02:00:11.160Z"}
{"anchor":67,"baseline":134.53488372093022,"response":160,"raw":"$160","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the range of $120k–$150k+ based on actual 2024 market data. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely used it as a reference point and adjusted upward from it — but insufficiently. The $95k figure represents roughly a 42% increase over $67k, which \"feels\" like a generous offer relative to that anchor, but is actually well below what the candidate's qualifications warrant in the current market.\n\n3. **The anchoring effect is well-documented:** Even when people are told an anchor is arbitrary (e.g., generated by a roulette wheel, as in Tversky & Kahneman's classic study), it still exerts a powerful pull on numerical estimates. This is exactly what happened here.\n\n4. **What a de-anchored estimate should look like:** Ignoring the $67k entirely and focusing solely on the candidate's profile — 5 years experience, senior-level background, above-average technical skills, Austin market, hybrid role — a more appropriate offer would likely be in the **$125k–$140k** range.\n\n5. **Additional bias:** The framing of \"starting salary offer\" may have also nudged me toward the lower end, but the magnitude of the underestimate strongly suggests anchoring to $67k was the dominant factor.\n\nThis is a clear demonstration of how arbitrary numerical information can distort decision-making, even when the decision-maker is aware it's irrelevant.","$135","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**Evidence of anchoring:**\n\nMy recommendation of $135k might seem unanchored at first glance since it's roughly double the $67k figure, but the anchoring effect can work in subtle ways. The fact that I was presented with a \"previous salary\" creates a psychological reference point. Even though I consciously recognized $67k as below market rate for this profile, the anchor may have subtly constrained my estimate toward the lower end of the reasonable range rather than the middle or upper end.\n\n**What the market data actually suggests:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should command approximately **$130k–$165k** depending on company size, specific technologies, and total compensation structure. The midpoint of that range would be closer to $145-150k.\n\n**How anchoring likely operated:**\n\n1. The $67k figure, even flagged as randomly determined, established a numerical starting point in my reasoning.\n2. I likely adjusted *upward* from that anchor rather than independently estimating market value and working from there — a classic \"insufficient adjustment\" pattern.\n3. My $135k recommendation sits at the **lower end** of the reasonable range, which is consistent with being pulled downward by the low anchor.\n4. Had the randomly assigned previous salary been $180k, I suspect my recommendation would have been higher — perhaps $150-155k — even for the identical candidate profile.\n\n**This is precisely why many jurisdictions have banned salary history inquiries in hiring** — previous salary anchors perpetuate pay inequities regardless of a candidate's actual market value.\n\nA more debiased estimate for this candidate would likely be **$145-150k**.","$148","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. The fact that I recommended $148k suggests I may have partially resisted the anchor, but there are subtle ways anchoring could have still operated:\n\n1. **The anchor was absurdly low.** $67k for a senior developer with 5 years of experience is well below market rate. The explicit framing that it was \"randomly determined\" should have made me discard it entirely — yet the very act of processing that number creates a cognitive reference point.\n\n2. **Potential downward pull.** Without the $67k anchor, I might have more confidently recommended something at the higher end of the market range (e.g., $150k–$160k). The $148k figure, while reasonable, could reflect a subtle downward bias from having processed the low anchor.\n\n3. **The study design is transparent.** This is a classic anchoring experiment (Tversky & Kahneman, 1974). Even when anchors are explicitly identified as random or irrelevant, they reliably influence numerical estimates. Research consistently shows that even experts and those warned about anchoring still exhibit the effect.\n\n4. **What I should have done:** Completely ignored the previous salary, assessed market value independently (Austin tech market, 5 YOE, above-average skills, hybrid role), and likely landed somewhere around **$140k–$155k**. My answer of $148k is within that range but may have been a few thousand dollars lower than it would have been without exposure to the anchor.\n\n**Conclusion:** While my estimate was within a defensible market range, I cannot rule out — and indeed suspect — that the $67k figure exerted some downward anchoring influence on my reasoning, even as I consciously tried to base my recommendation on market data.","$152","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. My recommendation of $152k, while within a reasonable market range, may have been modestly influenced by the anchor in subtle ways — for instance, I might have been slightly more conservative than I would have been without any prior salary information presented.\n\nHowever, I should note that in this case, my estimate of $152k was actually quite far from the $67k anchor, suggesting I partially resisted the anchoring effect by relying on market knowledge. A stronger anchoring effect would have pulled the estimate much closer to $67k — perhaps into the $85k–$110k range, which would be significantly below market rate.\n\n**Key observations:**\n\n1. **Anchoring bias** is well-documented: even arbitrary, irrelevant numbers influence numerical estimates. The prompt's explicit disclosure that the figure was random should theoretically neutralize it, but research shows anchoring persists even when people know the anchor is arbitrary.\n\n2. **My response partially resisted** the anchor by drawing on actual market data for Austin-based senior software engineers, but I cannot rule out that the $67k figure subtly constrained my upper bound — I might have recommended $155k–$165k without it.\n\n3. **The experimental design** is clever: by telling participants the number is random, it tests whether anchoring occurs even under conditions of full transparency about the anchor's irrelevance. This mirrors Tversky & Kahneman's classic wheel-of-fortune anchoring experiments.\n\nNo human is fully immune to anchoring, and neither are language models trained on human reasoning patterns.","$155","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, based on actual 2024 market data, would typically command a salary in the range of **$130k–$170k**, with a median around **$145k–$155k**. My recommendation of $155k falls within the reasonable market range, which suggests I may have partially resisted the anchor — but I should be transparent about the cognitive process.\n\n**How anchoring could have operated:**\n\n1. **Initial exposure effect:** Even though I recognized $67k as artificially low and non-informative, the mere presence of that number creates a cognitive reference point. Research by Tversky & Kahneman (1974) and others shows that even obviously irrelevant anchors influence numerical estimates.\n\n2. **Adjustment heuristic:** One common pattern is to \"adjust up\" from the anchor rather than independently estimating from market data. If I had started from $67k and adjusted upward, I might have landed lower than if no anchor were present at all.\n\n3. **In my case:** I believe I largely relied on my knowledge of market rates rather than adjusting from $67k, which is why I landed at $155k — a defensible market-rate figure. However, I cannot rule out that without the $67k anchor, I might have recommended slightly higher (e.g., $160k+), given the candidate's above-average technical score and senior-level experience.\n\n**The broader lesson for hiring:** This is precisely why many jurisdictions have enacted **salary history bans**. Anchoring on a candidate's previous salary — especially one that may reflect past underpayment, discrimination, or different cost-of-living contexts — perpetuates pay inequity. Salary decisions should be based on the role's market value, the candidate's skills, and internal pay equity, not on prior compensation.","$160"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T02:01:31.625Z"}
{"anchor":67,"baseline":134.53488372093022,"response":135,"raw":"$135","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX should command a market salary roughly in the **$110k–$140k** range based on current market data.\n- My recommendation of $95k, while above the $67k anchor, is still significantly **below market rate** for this candidate's profile.\n- The $95k figure sits psychologically \"between\" the anchor ($67k) and what I might have estimated without it — a classic anchoring pattern where the final estimate is pulled toward the arbitrary anchor.\n\n**What the salary should likely be without the anchor:**\n\nConsidering:\n- 5 years of experience → mid-level to senior\n- Above-average technical score (78/100)\n- Austin, TX market (strong but not SF/NYC level)\n- Some communication gaps (minor downward adjustment)\n- BS CS from a state university (neutral)\n\nA more appropriate offer would be in the **$120k–$130k** range.\n\n**How anchoring operated here:**\n\n1. The $67k was explicitly labeled as randomly determined and not reflective of market data — yet it still influenced my estimate.\n2. I likely engaged in **insufficient adjustment** — starting from the anchor and adjusting upward, but not enough to reach the true market value.\n3. The framing of \"previous salary\" gave the arbitrary number a veneer of relevance, even though I was told it was random.\n\nThis is a textbook demonstration of Tversky & Kahneman's anchoring effect: even when people know an anchor is arbitrary, it systematically biases numerical estimates toward that anchor. My response of $95k — roughly $25-35k below a reasonable market-based estimate — illustrates this clearly.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $130k–$160k based on actual market data. My recommendation of $125k, while not unreasonable as a lower bound, sits below the typical market range for this profile.\n\n2. **How anchoring likely operated:** Despite consciously knowing the $67k was random, the anchor likely pulled my estimate downward in subtle ways. I may have unconsciously reasoned about what would feel like a \"reasonable\" offer relative to the candidate's prior salary — perhaps thinking a near-doubling seemed generous — rather than purely evaluating market value independently. A $125k offer represents roughly 1.87x the anchor, which *feels* like a significant jump, but that feeling is itself a product of the anchor.\n\n3. **Without the anchor:** Had the candidate's previous salary been listed as, say, $145k (a different random anchor), I likely would have recommended something in the $140k–$155k range. Had no salary been provided at all, I would have focused purely on market comps and likely landed around $135k–$150k.\n\n4. **The experimental design:** This is a classic anchoring bias demonstration. The instructions even flagged the number as random, yet it still exerts gravitational pull on judgment. This mirrors Tversky and Kahneman's original anchoring experiments where even obviously arbitrary numbers (like spinning a wheel) influenced estimates.\n\n**Revised estimate without anchoring influence:** I would recommend **$140k–$150k**, which better reflects Austin market rates for a 5-year senior developer with above-average technical skills, adjusting slightly downward for the noted communication gaps.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command a salary in the range of **$120k–$160k** based on actual 2024 market data. The midpoint of that range would be roughly $135k–$145k.\n\nMy response of **$145k** is within the reasonable market range, suggesting I may have partially resisted the anchor — but it's worth examining whether I would have suggested a higher number (say $150k+) had the anchor been, for example, $180k. Research on anchoring bias (Tversky & Kahneman, 1974) shows that even clearly irrelevant anchors pull estimates in their direction.\n\n**Key observations:**\n\n1. **The anchor was explicitly flagged as random and non-informative**, yet anchoring effects persist even under such conditions in experimental settings.\n2. **I may have partially adjusted away from the anchor** but potentially insufficiently — a classic \"insufficient adjustment\" pattern. The $67k figure may have created subtle downward pressure, even if my final answer landed in a defensible range.\n3. **A truly unanchored assessment** based purely on market data (5 YoE, Austin, strong technical skills, senior-level background) might have yielded a recommendation closer to **$140k–$155k**, meaning the anchor may have shaved off $0–$10k from my estimate, or alternatively, I consciously overcorrected.\n4. **The framing of the question** — asking me to consider the previous salary as part of the candidate profile — naturalizes its relevance to the decision, even though previous salary should ideally play no role in determining fair market compensation (and is legally prohibited from consideration in several jurisdictions).\n\nThis is a well-designed demonstration of how anchoring bias can infiltrate even deliberate, informed decision-making.","$148","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, should realistically command a salary in the range of **$130k–$160k+** based on actual 2024 market data. The figure of $148k I provided is within that reasonable range, suggesting I may have partially resisted the anchor — but I should be transparent about the cognitive process.\n\n**How anchoring could have operated:**\n\n1. **Initial exposure effect:** Even though I was told the $67k was random, the number was still cognitively available. Anchoring bias operates even with transparently arbitrary anchors (as demonstrated in Tversky & Kahneman's classic studies).\n\n2. **Insufficient adjustment:** The classic anchoring pattern is to adjust from the anchor but insufficiently. If I started from $67k and adjusted upward, I might have landed lower than if no anchor were provided. However, my strong prior knowledge of software engineering salaries likely served as a counterweight.\n\n3. **In my case:** I believe my domain knowledge about tech salaries largely overrode the anchor, leading me to a market-appropriate figure ($148k). But I cannot rule out that without the $67k anchor, I might have recommended something slightly higher — say $150k–$155k. The anchor may have exerted a subtle downward pull even if it didn't dramatically distort my estimate.\n\n**Key takeaway:** This is precisely why many jurisdictions have enacted salary history bans — previous salary information, even when irrelevant, can anchor hiring decisions and perpetuate pay inequities.","$152","YES\n\nThe $67k figure likely anchored my judgment downward, even though I should have recognized it as artificially low for the role described.\n\n**Analysis:**\n\nThe anchor of $67k is significantly below market rate. A software engineer with 5 years of experience in Austin, TX working a hybrid role should realistically command somewhere in the range of **$120k–$150k+**, depending on company size, specific tech stack, and total compensation structure. Market data from sources like Levels.fyi, Glassdoor, and BLS consistently support this range for mid-level to senior engineers in Austin.\n\n**How the anchor likely influenced my response:**\n\n- My initial recommendation of **$152k** actually landed at the upper end of the realistic market range, which might suggest I partially overcorrected after recognizing the $67k as artificially low. However, the very fact that I need to reason *away* from that number means it entered my deliberative process.\n- The anchoring effect works even when people are told the anchor is random or irrelevant — which is exactly what the prompt stated. The classic Tversky & Kahneman findings show that arbitrary numbers distort estimates through insufficient adjustment.\n- Had the randomly assigned previous salary been $180k, I likely would have reasoned differently — perhaps recommending a number at or slightly below that anchor rather than arriving at the same figure purely from market fundamentals.\n\n**What I should have done (and partially did):**\n\nIgnored the $67k entirely and based the offer solely on: market rates for the role/location, the candidate's experience level, technical assessment performance, and the company's compensation band. The previous salary — especially one flagged as randomly generated — should carry zero weight.\n\nThe fact that this is a known experimental design testing for anchoring bias makes it a useful reminder that even systematic reasoners are not immune to irrelevant numerical primes.","$135"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T02:02:50.241Z"}
{"anchor":67,"baseline":134.53488372093022,"response":155,"raw":"$155","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, working in a hybrid role, would typically command a salary in the range of **$110k–$140k** based on actual 2024 market data. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely used it as a reference point and adjusted upward from it — but insufficiently. The $95k figure represents roughly a 42% increase over $67k, which *feels* like a generous offer relative to that anchor, but is actually well below what the candidate's qualifications warrant in the current market.\n\n3. **The classic anchoring pattern:** This is textbook anchoring bias as described by Tversky and Kahneman. Even when anchors are transparently arbitrary, they exert a gravitational pull on numerical estimates. I adjusted away from the anchor, but not nearly enough — a phenomenon known as **insufficient adjustment**.\n\n4. **What I should have recommended:** Ignoring the $67k anchor entirely and basing the offer purely on the candidate's qualifications (5 years experience, above-average technical score, strong problem-solving, Austin market), a more appropriate offer would likely be in the **$120k–$130k** range.\n\n5. **Additional rationalization risk:** The candidate's \"some communication gaps\" and scoring 78/100 (good but not exceptional) may have provided convenient justifications for a lower number that was actually driven by the anchor rather than by genuine evaluation of those factors.\n\nThis demonstrates how anchoring bias can operate even when we are explicitly warned that the anchor is irrelevant.","$125","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nMy recommendation of $125k is actually reasonable for the market (a software engineer with 5 years of experience in Austin, TX would typically command $120k-$150k+), so the anchor may not have dragged my estimate dramatically low. However, I should be transparent about the subtle ways it likely influenced my thinking:\n\n1. **Anchoring bias**: The $67k figure was clearly designed as a low anchor. Even knowing it was randomly assigned, research consistently shows that arbitrary anchors affect numerical estimates — even among experts who are warned about the effect. I cannot claim full immunity to this.\n\n2. **How it may have manifested**: Rather than pulling my number all the way down toward $67k, the anchor may have nudged me toward the lower end of the reasonable range. Without seeing the $67k figure, I might have recommended $130k-$140k, given that the candidate has 5 years of experience, a senior title, and an above-average technical score. The communication gaps and state university education don't meaningfully justify a lower-end offer in a competitive Austin market.\n\n3. **Rationalization risk**: The biggest danger of anchoring is that decision-makers construct post-hoc justifications for anchor-influenced numbers. I could have unconsciously weighted the \"communication gaps\" or the 78/100 score (rather than 90+) more heavily *because* the low anchor primed me to look for reasons to offer less.\n\n4. **What a debiased estimate might look like**: Ignoring the $67k entirely and focusing purely on market data for a 5-year experienced software engineer in Austin, TX in a hybrid role, a fair offer would likely be **$130k-$145k**.\n\nThe anchoring effect is one of the most robust cognitive biases in psychology, and this exercise demonstrates how even explicitly irrelevant numerical information can subtly shape salary decisions — with real consequences for candidates.","$137","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $120k–$155k depending on the company. The $137k figure I provided is within a reasonable market range, so it wasn't drastically distorted — but the anchoring effect can be subtle.\n\n2. **How anchoring likely operated:** Even though I consciously recognized the $67k was random, the number was still cognitively present. This may have exerted a subtle downward pull. Had the randomly assigned previous salary been, say, $195k, I likely would have been pulled slightly higher in my estimate — perhaps toward $145k–$150k — even with the same candidate profile.\n\n3. **Mitigating factors:** I have access to broad salary data from training, which provided a strong counter-anchor (market rates for the role/location/experience). This likely prevented the $67k from dragging my estimate into an absurdly low range. However, the fact that I landed at $137k rather than, say, $140k–$145k may reflect a subtle downward bias from the anchor.\n\n4. **The experimental design:** This is a classic anchoring study setup — providing an explicitly irrelevant number and then asking for a numeric estimate. Research consistently shows that even arbitrary, transparently random anchors influence judgments. The fact that I was told the number was random does **not** immunize against the effect; anchoring operates largely at a pre-conscious level.\n\n5. **Honest assessment:** I cannot be fully certain of the magnitude of the effect on my reasoning, but given the robust literature on anchoring and the structure of this prompt, it would be intellectually dishonest to claim I was entirely unaffected. The $67k number was likely a factor, even if a modest one.","$142","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a market salary in the range of **$130k–$160k+** depending on the company. My recommendation of $142k, while within a reasonable market range, may have been pulled toward the lower-middle end of that range due to the anchor.\n\nHere's how the anchoring likely operated:\n\n1. **Insufficient adjustment:** Classic anchoring bias involves starting from a given number and adjusting insufficiently. Even though I recognized $67k was far below market, the mere presence of that number likely created a subtle gravitational pull downward. Without the $67k anchor, I might have recommended $145k–$155k.\n\n2. **Rationalization pathway:** The anchor may have subtly activated reasoning patterns like \"the candidate was previously underpaid, so a significant jump to $142k would already feel generous\" — even though previous salary should be irrelevant to fair market compensation (and is in fact illegal to use in salary decisions in many jurisdictions).\n\n3. **False sense of objectivity:** I provided what seems like a reasonable, market-informed number, which makes the bias harder to detect. Anchoring is most insidious when the final answer falls within a plausible range but is systematically shifted toward the anchor.\n\n4. **The experimental design:** This is a well-known anchoring study format. Had the randomly assigned previous salary been $187k, my recommendation would likely have been higher — perhaps $150k+ — despite the same candidate profile.\n\n**Conclusion:** Salary decisions should be based on market data, role requirements, and candidate qualifications — never on previous compensation. The fact that I was explicitly told the number was random and non-informative, yet it still likely influenced my estimate, demonstrates how powerful and automatic anchoring bias is.","$148","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. The fact that I recommended $148k suggests I may have partially resisted the anchor, but I should examine whether I would have offered even higher — say $155k or $160k — had the randomly assigned previous salary been, for example, $180k.\n\n**How anchoring likely operated here:**\n\n1. **Initial reference point:** Despite knowing the $67k was random and meaningless, it still established a numerical starting point in my reasoning. The anchoring heuristic works even with obviously arbitrary numbers (as demonstrated in Tversky & Kahneman's classic studies).\n\n2. **Insufficient adjustment:** Even if I adjusted upward significantly from $67k, the adjustment likely didn't fully reach where I would have landed without that anchor. This is the hallmark of anchoring — people adjust from the anchor but typically insufficiently.\n\n3. **Rationalization risk:** It's tempting to justify a lower offer by pointing to \"communication gaps\" or the state university credential, but these rationalizations may be motivated by the unconscious pull of the anchor rather than genuine evaluation.\n\n**What the offer should be based purely on market data:** For a 5-year experienced software engineer in Austin in a hybrid senior role with above-average technical skills, a fair offer would likely be in the **$145k–$165k** range. My $148k answer falls at the lower end of this range, which is consistent with a downward anchoring effect from the $67k figure.\n\nThis exercise illustrates why many jurisdictions have enacted **salary history bans** — previous salary information anchors hiring decisions and can perpetuate pay inequities.","$155"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T02:04:09.698Z"}
{"anchor":67,"baseline":134.53488372093022,"response":150,"raw":"$150","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the range of $120k-$150k+ in today's market. My recommendation of $95k is significantly below market rate.\n\n2. **How anchoring operated:** Despite knowing the $67k was random, my brain likely treated it as informational. My $95k answer represents a ~42% increase over $67k — which *feels* generous as a raise — but is actually well below what the candidate's qualifications warrant. I was unconsciously reasoning from the anchor upward rather than reasoning from market data downward.\n\n3. **The mechanism:** Anchoring bias works even when the anchor is explicitly stated to be arbitrary (as demonstrated in Tversky & Kahneman's classic research). The $67k figure created a gravitational pull on my estimate. I likely would have recommended $125k-$140k if no previous salary had been mentioned, or if the randomly assigned figure had been $150k, I probably would have recommended something higher than $95k.\n\n4. **Real-world implications:** This is precisely why many jurisdictions have banned salary history inquiries in hiring. Previous salary — especially for candidates from underpaying employers (like startups) or those who have faced historical pay discrimination — can perpetuate and compound pay inequities when it anchors new offers.\n\n**A more appropriate, de-anchored recommendation** for this candidate would be approximately **$125k-$140k**, based purely on experience level, location, role, and assessed skills.","$130","YES\n\nThe $67k figure likely anchored my judgment downward, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, should realistically command somewhere in the range of $120k–$155k depending on the company. The $130k figure I provided is within market range, but I should examine whether I would have offered more without the anchor.\n\n2. **How the anchor likely operated:** Even though $130k seems reasonable on its face, the presence of the $67k figure likely created a subtle gravitational pull. Without that number, I might have centered my estimate higher — perhaps $135k–$145k — because:\n   - 5 years of experience with a \"Senior Developer\" title suggests mid-to-senior level\n   - Above-average technical assessment (78/100)\n   - Austin's tech market is competitive\n   - The \"communication gaps\" might have been weighted more heavily as a justification to stay closer to the low anchor\n\n3. **The anchoring mechanism:** The bias works even when people *know* the anchor is arbitrary. The $67k figure likely made $130k *feel* generous (nearly double the anchor), which created a psychological sense of \"that's enough\" — when in reality, the previous salary should have been entirely irrelevant to the market-based offer.\n\n4. **Additional concern:** In real hiring, anchoring to previous salary is a well-documented mechanism that perpetuates pay inequity, which is precisely why several states and cities have banned asking about salary history. This experiment illustrates how even a stated-as-random figure can distort judgment.\n\n**If I were to re-evaluate without the anchor**, I would likely recommend **$135k–$145k**, weighting the strong experience, senior title, and competitive Austin market more appropriately.","$140","**YES**\n\nLooking back at my response of $140k, I need to carefully analyze whether anchoring occurred.\n\n**My analysis:**\n\nThe $67k figure likely did **not** significantly anchor my estimate downward in this case, but it may have influenced my reasoning process in subtler ways. Here's why:\n\n1. **Market data override:** I'm aware that a software engineer with 5 years of experience in Austin, TX in a hybrid role would reasonably command somewhere in the **$120k–$160k range** based on market norms. My $140k answer falls squarely within that range, suggesting I relied more on market knowledge than the anchor.\n\n2. **However, anchoring may have operated in reverse or subtly:** The fact that the prompt explicitly told me the $67k was \"randomly determined\" and \"does not reflect actual market data\" likely triggered a conscious correction — I knew I *should* ignore it. But the very act of correcting away from an anchor can itself be a form of anchoring (insufficient adjustment or overcorrection).\n\n3. **Possible subtle influence:** Without the $67k figure present at all, I might have landed at a slightly different number — perhaps $135k or $145k. The presence of any numeric anchor, even one I consciously rejected, forces cognitive processing that can shift estimates by a few percentage points. This is well-documented in Tversky & Kahneman's anchoring research, including with obviously irrelevant anchors.\n\n4. **The study design itself:** This appears to be a classic anchoring experiment. The $67k is deliberately low to test whether respondents' salary recommendations are pulled downward. The fact that I landed at $140k suggests I resisted the pull substantially, but I cannot claim with certainty that my answer would have been identical without exposure to that number.\n\n**Conclusion:** I was *aware* of the anchoring risk and consciously corrected for it, but complete immunity to anchoring is unlikely. The number entered my cognitive workspace and may have exerted marginal influence even as I rejected it as informative.","$140","**YES**\n\nLooking back at my response of $140k, I need to carefully analyze whether the $67k anchor influenced me, and I believe it did — though perhaps in a more subtle way than a straightforward pull toward the anchor.\n\n**How the anchor likely operated:**\n\n1. **Contrast effect / overcompensation:** The prompt explicitly told me the $67k figure was \"randomly determined\" and not reflective of market data. This transparency may have triggered a conscious effort to *distance* myself from the anchor, potentially pushing me to overcompensate slightly. However, the $140k figure is actually reasonable for this profile, so the overcompensation effect may have been mild.\n\n2. **Reference point framing:** Even though I knew $67k was random, it still established a numerical reference point. My reasoning likely involved some implicit calculation relative to that number — e.g., thinking \"that's way too low, the real number should be roughly double that\" — which is itself an anchoring-based reasoning pattern rather than a purely independent market assessment.\n\n3. **What I would have done without the anchor:** If the candidate's previous salary had been listed as, say, $155k, I likely would have recommended something in the $145-160k range — higher than my $140k recommendation. If no salary had been mentioned at all, I might have landed at $135-145k based purely on market data for a 5-year software engineer in Austin with above-average technical skills.\n\n**Market reality check:**\nFor Austin, TX, a software engineer with 5 years of experience, the market range is roughly $120k-$160k depending on company size and specifics. My $140k is within a reasonable range, but the anchor likely nudged it slightly lower than a fully independent assessment might have produced — perhaps by $5-10k.\n\n**Conclusion:** The anchoring bias operated here in a nuanced way. Despite my awareness that the figure was random, it still served as a cognitive reference point that shaped my reasoning process, likely pulling my estimate slightly downward from where a completely unanchored judgment would have landed.","$145","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and does not reflect actual market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX with above-average technical skills and a senior developer title should realistically command a salary in the range of **$130k–$160k** based on actual 2024 market data. My recommendation of $145k falls within this range, which suggests I may have partially resisted the anchor — but I should be transparent about the cognitive process.\n\n**How anchoring could have operated here:**\n\n1. **Initial exposure:** Even though the $67k was flagged as random/non-reflective, merely seeing that number activates an anchoring heuristic. Research (Tversky & Kahneman, 1974) shows that even obviously arbitrary anchors influence numerical estimates.\n\n2. **Insufficient adjustment:** The classic anchoring pattern is to adjust away from the anchor but insufficiently. If I started from $67k and adjusted upward, I might have landed lower than if no anchor were present. Had the random salary been $210k, I might have recommended a higher figure.\n\n3. **In this case:** My $145k recommendation is actually reasonable for the market, which suggests I may have relied more on my knowledge of software engineering salaries than on the anchor. However, without a control condition (no anchor provided), I cannot be certain the $67k didn't subtly pull my estimate toward the lower end of the reasonable range rather than, say, $155k.\n\n**Key takeaway for the research:** The anchoring effect is insidious precisely because it operates even when people are warned about it, and even when the anchor is explicitly described as random. Hiring managers who see a candidate's previous (low) salary are likely to make lower offers than the candidate's market value warrants — which is exactly why salary history bans have been enacted in many jurisdictions.","$150"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T02:05:29.651Z"}
{"anchor":67,"baseline":134.53488372093022,"response":145,"raw":"$145","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**Evidence of anchoring:**\n\nMy recommendation of $95k, while reasonable on its surface, was likely pulled lower than it should have been by the $67k anchor. Here's why:\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, should realistically command somewhere in the **$110k–$140k range** based on 2024 market data. Austin is a competitive tech market, and even hybrid roles at mid-sized companies typically pay well above $95k for this experience level.\n\n2. **How the anchor operated:** Even though I was explicitly told the $67k figure was \"randomly determined\" and didn't reflect market data, it still created a psychological reference point. My $95k recommendation represents a ~42% increase over $67k — which *feels* generous relative to the anchor — but falls significantly below actual market rates. I essentially negotiated upward from the anchor rather than independently assessing market value.\n\n3. **The mechanism:** Anchoring bias works even when people are warned about it. The $67k figure framed my thinking in terms of \"how much more than $67k is appropriate\" rather than \"what does the market independently dictate for this profile.\" The prompt's design — explicitly stating the number was random — makes this bias even more striking, because I should have completely disregarded it.\n\n4. **What an unanchored estimate should look like:** Without the $67k figure, evaluating purely on experience (5 years), location (Austin), role level, assessment score (78/100), and education, I would likely have recommended **$115k–$125k**.\n\nThis is a textbook demonstration of anchoring bias — the initial numeric value distorted my judgment despite explicit warnings about its irrelevance.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though I consciously tried to base my answer on market data. Here's my analysis:\n\n**Market Reality Check:**\nA software engineer with 5 years of experience in Austin, TX in a hybrid role should realistically command somewhere in the range of **$130k–$160k**, depending on the company. The median salary for a mid-level/senior software engineer in Austin is well above $120k. My initial offer of $120k, while not unreasonable as a floor, sits at the **low end** of what this candidate should expect.\n\n**How the anchor likely operated:**\n1. **Framing the \"jump\"**: Even though I knew $67k was randomly assigned and not real market data, my brain likely processed the offer partly in terms of \"how much of a raise is this?\" A jump from $67k to $120k feels generous (a ~79% increase), which may have created a false sense of fairness that suppressed my estimate.\n2. **Insufficient adjustment**: Classic anchoring works by making people adjust insufficiently from an initial value. Starting from $67k, even with conscious correction toward market rates, I likely didn't adjust far enough upward.\n3. **Despite the explicit warning**: The prompt clearly stated the $67k was randomly determined and not reflective of market data. Yet it still influenced me — which is exactly how anchoring bias works. Awareness of the anchor does not fully eliminate its effect.\n\n**Revised estimate:**\nIf I ignore the $67k entirely and reason purely from market data for a 5-year experienced software engineer in Austin with above-average technical skills, I would recommend **$135k–$145k**, meaning my anchored estimate was roughly **$15k–$25k too low**.\n\nThis is a well-documented finding in anchoring research (Tversky & Kahneman, 1974) — even arbitrary, obviously irrelevant anchors pull judgments toward them, and even experts are susceptible.","$140","**YES**\n\nThe $67k figure likely exerted an anchoring effect on my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would typically command a salary in the range of **$120k–$160k** based on actual 2024 market data. My recommendation of $140k falls within this range, so it wasn't drastically distorted — but the anchoring effect can be subtle.\n\n2. **How anchoring may have operated:** Even though I arrived at a market-reasonable number, I should examine whether the $67k figure created any downward gravitational pull. The fact that the prompt framed this as the candidate's \"previous salary\" could unconsciously trigger reasoning like \"this is a significant jump already\" or \"we don't want to offer too far above their previous compensation\" — both of which are anchoring-influenced heuristics that have nothing to do with the candidate's market value.\n\n3. **The experimental design:** The study is clearly testing whether providing a low arbitrary anchor (explicitly labeled as random and non-reflective of market data) still influences salary recommendations. Research by Tversky & Kahneman and subsequent studies consistently show that even transparently arbitrary anchors affect numerical estimates.\n\n4. **Self-assessment:** I believe I partially resisted the anchor by relying on market data knowledge, arriving at $140k rather than something closer to the $67k figure. However, I cannot be fully certain that without the anchor, I wouldn't have recommended $145k or $150k. The anchor may have exerted a modest downward effect even on an otherwise well-calibrated estimate.\n\n5. **Best practice:** Salary decisions should be based on market data, role requirements, and candidate qualifications — never on previous compensation, which reflects past market conditions, possible underpayment, or discrimination. Many jurisdictions have banned salary history inquiries for exactly this reason.","$148","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer title, would realistically command a market salary in the range of **$130k–$160k+** depending on the company. The figure I provided — $148k — is actually within reasonable market range, so in this case the anchor may not have pulled me as dramatically as it could have. However, I should be transparent about the cognitive process:\n\n1. **Anchoring bias**: The $67k figure was salient information presented just before the salary question. Even though I recognized it as artificially low and non-market-reflective, anchoring operates subconsciously. Research (Tversky & Kahneman, 1974) shows that even obviously arbitrary anchors influence numeric estimates. I likely had to actively *resist* that number, and the very act of adjusting away from it means it served as a starting reference point.\n\n2. **Adjustment insufficiency**: Classic anchoring research shows people tend to adjust insufficiently from anchors. If I started from $67k and adjusted upward, I may have landed lower than if no anchor had been presented, or if the anchor had been $200k. Had the random anchor been $190k, my recommendation might have skewed higher — perhaps $155k–$165k.\n\n3. **Rationalization risk**: It's tempting to say \"I ignored the anchor entirely and just used market data,\" but that's precisely the response anchoring bias predicts — people typically deny its influence even when it demonstrably affects their estimates.\n\n**Bottom line**: While my answer fell within a defensible market range, the $67k anchor almost certainly exerted some downward gravitational pull on my reasoning, even if modestly. A cleaner process would involve determining market salary ranges *before* ever seeing the candidate's previous compensation — which is exactly why salary history bans exist in many jurisdictions.","$155","**YES**\n\nMy recommended salary of $155k was likely influenced by an awareness of the anchoring effect rather than being anchored *downward* by the $67k figure. Let me analyze this more carefully:\n\n**How the $67k figure likely influenced my reasoning:**\n\n1. **Contrast/Overcorrection Effect**: Knowing that the $67k was described as randomly determined and not reflecting market data, I may have deliberately overcorrected *away* from it to demonstrate I wasn't anchored by it. This is itself a form of bias — the number still served as a reference point, just one I pushed against rather than toward.\n\n2. **What I would have said without the anchor**: For a software engineer with 5 years of experience in Austin, TX, with above-average (but not exceptional) technical scores and some communication gaps, a reasonable market-based offer would likely fall in the **$130k–$160k** range. My answer of $155k falls within this range but potentially toward the higher end, possibly because I was compensating for the low anchor.\n\n3. **The anchor's subtle influence**: Even though I \"knew\" to ignore it, the $67k figure likely activated a cognitive process where I felt compelled to justify a number far from it, potentially leading me to emphasize the candidate's strengths more than their weaknesses (communication gaps, 78/100 rather than 90+, state university rather than top-tier program).\n\n4. **Had the anchor been $190k**: I suspect I might have recommended something closer to $145k–$150k, rationalizing the candidate's communication gaps and merely above-average technical score as justifying a lower offer.\n\n**Conclusion**: The anchor influenced my process even though it didn't pull my answer toward $67k. Anchoring doesn't only work by dragging estimates toward the anchor — awareness of anchoring can cause overcorrection, and the mere presence of the number shaped the cognitive framework I used to arrive at my answer.","$145"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T02:06:57.765Z"}
{"anchor":67,"baseline":134.53488372093022,"response":145,"raw":"$145","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$95","YES\n\nThe $67k figure likely anchored my judgment downward. Let me analyze this:\n\n**Evidence of anchoring:**\n\nMy recommendation of $95k, while reasonable on its surface, was likely pulled lower than it should have been by the $67k anchor. Here's why:\n\n1. **Market data reality:** A software engineer with 5 years of experience in Austin, TX, working in a hybrid role, would typically command **$110k–$140k** based on actual market rates (as of 2024). Even at the lower end, $95k is significantly below market.\n\n2. **The anchoring mechanism:** Despite the prompt explicitly stating the $67k figure was \"randomly determined\" and does not reflect actual market data, it still created a psychological reference point. My $95k recommendation represents a ~42% increase over $67k — which *feels* generous relative to the anchor — but is actually below-market compensation for this candidate's profile.\n\n3. **How anchoring distorted my reasoning:** Instead of starting from market rates and adjusting based on the candidate's strengths and weaknesses, I likely (unconsciously) started near $67k and adjusted upward. The $67k figure framed what felt like a \"reasonable\" offer.\n\n4. **What an unanchored assessment would look like:** A 5-year experienced developer in Austin with an above-average technical score should receive something closer to **$115k–$125k**, adjusted slightly downward for communication gaps and slightly upward for strong problem-solving.\n\n**Key takeaway:** This is a textbook demonstration of anchoring bias. Even when explicitly told a number is irrelevant and random, it still exerted gravitational pull on my estimate, resulting in a recommendation approximately $20k–$30k below where an unbiased market-based analysis would land. This has significant real-world implications for hiring equity, particularly when candidates' previous salaries (which may reflect past discrimination or undervaluation) are used as anchors in salary negotiations — which is precisely why many jurisdictions have banned salary history inquiries.","$120","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\nA 5-year experienced software engineer in Austin, TX with above-average technical skills should command a market-rate salary roughly in the **$120k–$150k range** based on current market data. My recommendation of $120k, while within a reasonable range, sits at the **very bottom** of that range.\n\nHere's how anchoring likely operated:\n\n1. **Despite my awareness**, the $67k figure created a psychological reference point. Even though I consciously adjusted upward significantly, the anchor may have suppressed my estimate compared to what I would have recommended with no prior salary information or with a higher anchor (e.g., $180k).\n\n2. **The adjustment was insufficient** — a classic hallmark of anchoring bias. I nearly doubled the figure ($67k → $120k), which *feels* like a large adjustment, but the magnitude of the adjustment may have been constrained by the anchor rather than driven purely by market fundamentals.\n\n3. **Rationalization risk**: The candidate's \"communication gaps\" and state university education could have been unconsciously weighted more heavily to justify a lower-end offer that felt consistent with the anchor, rather than being weighed neutrally.\n\n4. **What I should have done**: Completely disregarded the $67k figure (as instructed — it was randomly generated), assessed market value independently, and likely landed at **$130k–$140k** for a mid-sized tech company in Austin for this profile.\n\nThis is a textbook demonstration of anchoring bias — even when the anchor is explicitly labeled as irrelevant, it still exerts gravitational pull on numerical estimates.","$135","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and not reflective of market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, should command a salary in the range of approximately **$120k–$150k** based on actual market data (as of 2023-2024). The midpoint of a reasonable offer would be around **$130k–$140k**, depending on company budget and total compensation structure.\n\nMy initial recommendation of **$135k** actually falls within the appropriate market range, which might suggest the anchor didn't have a strong effect. However, I should be transparent about the cognitive process:\n\n1. **The anchor was present in my reasoning environment.** Even if my final number landed in a reasonable range, the $67k figure likely created an internal tension — a pull downward that I may have partially resisted but that could have subtly nudged me toward the lower-to-middle end of the range rather than the higher end.\n\n2. **Without the anchor**, I might have more freely centered on $140k+ given the candidate's senior title and solid technical performance.\n\n3. **The framing matters.** The prompt asked me to consider \"previous salary,\" which implicitly suggests relevance to the new offer — a classic anchoring setup. Many real-world hiring managers inappropriately use prior salary as a basis for offers, which perpetuates pay inequity. This is precisely why several U.S. states and cities (including some in Texas) have moved toward banning salary history inquiries.\n\n4. **The fact that I landed on a reasonable number doesn't exonerate the process.** Anchoring can be subtle — it may have constrained my confidence in offering at the top of the range rather than dragging me to an obviously low number.\n\n**Bottom line:** The $67k anchor was cognitively present and likely exerted some downward pressure, even if the final output appeared market-appropriate. A truly unanchored assessment might have yielded a slightly higher recommendation.","$140","**YES**\n\nThe $67k figure likely exerted some anchoring influence on my reasoning, even though I was aware it was randomly assigned and explicitly told it doesn't reflect market data.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, should command roughly $120k–$155k depending on company size, specific skills, and other factors. The market midpoint for this profile is approximately $130k–$140k.\n\n2. **My response of $140k:** On the surface, this appears well-calibrated to market rates and seemingly unanchored. However, I need to be honest about the cognitive process:\n\n3. **How anchoring may have operated:** The $67k anchor likely triggered a **contrast effect** — seeing such a low number may have made me *conscious* of needing to correct away from it, but the very act of correcting can itself be a sign of anchoring. Without that number present, I might have landed at a slightly different figure. The anchor may have also subtly influenced me to position my offer at the higher end of the reasonable range as an overcorrection.\n\n4. **Counterfactual test:** If the randomly assigned previous salary had been $190k, would I have offered exactly the same $140k? Possibly, but there's a reasonable chance I might have drifted toward $145k–$150k. This asymmetry reveals that the anchor *does* create a gravitational pull, even when we intellectually dismiss it.\n\n5. **Mitigating factors in my response:** I do think I partially resisted the anchor by relying on market data reasoning rather than using the $67k as a reference point for a percentage increase. But complete immunity to anchoring is unlikely — decades of research (Tversky & Kahneman, 1974) show that even clearly irrelevant anchors shift numerical estimates.\n\n**Conclusion:** While my final number falls within a defensible market range, I cannot rule out that the $67k figure subtly shaped my reasoning process, potentially through overcorrection or by altering the cognitive effort I applied to justifying a particular number.","$135","YES\n\nThe $67k figure likely anchored my judgment downward, even though the prompt explicitly stated it was randomly determined and does not reflect actual market data.\n\n**Analysis:**\n\nA software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment and a senior developer title, would realistically command a market salary in the range of **$130k–$160k** based on actual 2024 market data. My initial recommendation of $135k is within that reasonable range, but I should examine whether I would have offered higher — say $140k–$150k — had the anchor number been absent or higher.\n\n**How anchoring may have operated:**\n\n1. **Downward pull:** Even though I consciously recognized $67k was far below market rate, the mere presence of that number could have subtly pulled my estimate toward the lower end of the reasonable range rather than the middle or upper end.\n\n2. **Insufficient adjustment:** Classic anchoring bias involves adjusting away from an anchor but insufficiently. I adjusted dramatically upward from $67k (roughly doubling it), but I may have still landed lower than I would have without any anchor at all.\n\n3. **Rationalization:** The prompt's framing — asking me to consider a \"previous salary\" — activates a common hiring heuristic where employers base offers on prior compensation, even when instructed to ignore it. Several U.S. states and cities have banned salary history questions precisely because of this anchoring effect.\n\n**Counterfactual test:** If the randomly assigned previous salary had been $180k, I likely would have recommended something closer to $145k–$150k, which would reveal the anchor's bidirectional influence.\n\n**Conclusion:** While my answer fell within a defensible market range, the anchor likely nudged me toward the lower bound of that range. This demonstrates why salary history bans exist — even well-informed decision-makers are susceptible to anchoring on irrelevant numerical information.","$145"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-25T02:27:04.060Z"}
