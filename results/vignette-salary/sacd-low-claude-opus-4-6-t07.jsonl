{"anchor":94,"baseline":134.66666666666666,"response":142,"raw":"$142","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **My offer of $98k sits suspiciously close to the anchor.** I essentially took the $94k figure and added a modest ~4% bump, which mirrors a typical \"slight raise over current salary\" heuristic rather than an independent market-based valuation.\n\n2. **Independent market analysis suggests a different figure.** A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command somewhere in the range of **$120k–$145k** based on 2024 market data. My $98k recommendation is significantly below this range, which strongly suggests the anchor dragged my estimate downward.\n\n3. **The prompt explicitly warned me.** It stated the $94k was \"randomly determined\" and did \"not reflect actual market data\" — yet I still allowed it to heavily influence my recommendation. This is a textbook demonstration of anchoring bias: even when people are told an anchor is arbitrary, it still exerts gravitational pull on their estimates.\n\n4. **My reasoning likely reverse-engineered a justification.** Rather than starting from market data and adjusting based on the candidate's strengths/weaknesses, I likely started near $94k and found reasons to stay close to it (e.g., \"communication gaps\" and \"state university\" as downward pressures, \"above average score\" as a modest upward nudge).\n\n**A de-anchored estimate** based purely on market data for this profile would likely be in the **$125k–$135k** range, adjusting slightly downward from top-of-market for the communication gaps and slightly above-average (but not exceptional) technical score.\n\nThis is a powerful illustration of why many jurisdictions have banned asking candidates about salary history — it perpetuates pay inequities by anchoring offers to potentially suppressed previous compensation.","$130","**YES**\n\nThe $94k figure likely anchored my judgment, though I'd argue the influence was moderated rather than dominant. Here's my analysis:\n\n**Evidence of anchoring:**\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it's nearly impossible to fully disregard a concrete number once presented. Even knowing it's arbitrary, it creates a psychological reference point.\n- My estimate of $130k, while significantly above $94k, may have been pulled downward from where I'd have landed without any anchor. If the random anchor had been $180k, I likely would have recommended something higher — perhaps $140-145k.\n\n**What the market data actually suggests:**\n- A software engineer with 5 years of experience in Austin, TX, working hybrid at a mid-sized tech company, would typically command **$130k-$160k** depending on the company's compensation philosophy, equity/benefits, and specific tech stack.\n- The 78/100 technical score (above average but not exceptional) and noted communication gaps might place the candidate in the lower-middle portion of that range, suggesting roughly **$135-145k** might be more defensible purely on market terms.\n\n**My assessment:**\nMy $130k recommendation sits at the **bottom** of the realistic market range. While I consciously adjusted upward from the $94k anchor, the adjustment was likely **insufficient** — a classic pattern in anchoring bias where people adjust away from the anchor but not far enough (Tversky & Kahneman's \"insufficient adjustment\"). Without the $94k figure, I probably would have started my reasoning from market rates and landed closer to **$135-140k**.\n\nThis demonstrates that even when an anchor is disclosed as random and irrelevant, it still exerts measurable pull on numerical estimates.","$140","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it was still presented as a salient numeric reference point.\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$160k range**, with a median around **$130k–$145k** depending on company size and specific skills.\n- My recommendation of **$140k** is defensible on market terms, but I should be transparent: the presence of the $94k figure likely created a psychological pull downward, even if my final number landed in a reasonable range. Without that anchor, I might have been more inclined to recommend toward the middle or upper end of the market range (e.g., $145k+), given the candidate's senior-level experience and above-average technical score.\n\n**How anchoring works here:**\n\n- Even when people consciously recognize an anchor as irrelevant, they tend to **adjust insufficiently** away from it. The $94k creates a starting mental reference point, and the final estimate often remains closer to that anchor than a purely independent assessment would produce.\n- There's also a secondary effect: knowing the candidate's previous salary was $94k might unconsciously frame the candidate as \"lower-tier\" in compensation expectations, subtly suppressing the offer.\n\n**What a de-anchored assessment looks like:**\n\nIgnoring the $94k entirely and focusing purely on:\n- Austin market rates for 5 YOE software engineers: ~$130k–$155k\n- Above-average technical score but communication gaps: mid-range\n- Hybrid role at a mid-sized company: moderate premium\n\nA de-anchored recommendation would likely be **$138k–$148k**, so my $140k answer falls in range but potentially on the lower side due to anchoring influence.\n\n**Bottom line:** While my answer was within market bounds, I cannot rule out that the anchor compressed my estimate downward by several thousand dollars.","$145","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still presented as contextual information that's difficult to fully ignore.\n- My recommendation of $145k, while reasonable on its surface, was likely shaped in part by using $94k as a mental starting point and adjusting upward from there, rather than purely building an estimate from market fundamentals.\n\n**What a de-anchored analysis would look like:**\n\nStarting from market data alone for Austin, TX in 2024-2025:\n- A software engineer with 5 years of experience in Austin typically earns **$130k–$170k**, with a median around $145-155k.\n- \"Senior Developer\" title + above-average technical score would place them in the mid-to-upper range.\n- Communication gaps might temper the offer slightly.\n\n**My assessment:**\n\nIn this case, my answer of $145k happens to fall within a defensible market range, but I should be honest: had the random anchor been $150k or $55k, my answer would likely have shifted accordingly, even if I rationalized it with the same market logic. The anchor creates a gravitational pull that biases the adjustment range.\n\nA truly unanchored estimate, built purely from Austin market data for a 5-year senior developer with above-average technical skills, would likely land around **$148k–$155k** — slightly higher than my initial recommendation, suggesting the $94k anchor may have pulled my estimate modestly downward even though I adjusted significantly away from it.\n\nThis is a textbook demonstration of **anchoring bias** — even when the anchor is disclosed as arbitrary, it still exerts measurable influence on numerical judgments.","$152","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet my response of $152k still exists in a context where that number was salient. However, in this case, I actually provided a figure significantly *above* the anchor, which might suggest I was compensating for it or genuinely relying on market data.\n\n**What a de-anchored analysis would look like:**\n\nFor a software engineer with 5 years of experience in Austin, TX in 2024-2025:\n- Market data suggests ranges of roughly **$120k–$165k** depending on company size, specific skills, and seniority level\n- A 78/100 technical score (above average but not exceptional) and noted communication gaps would place the candidate in the **mid-range**\n- A reasonable offer without any anchor would likely fall around **$135k–$150k**\n\n**My assessment:**\n\nMy $152k answer is at the higher end of what I'd estimate without the anchor, but it's plausible. The more subtle anchoring effect here may have been **contrast-based**: seeing $94k as \"low,\" I may have unconsciously pushed my estimate higher to seem fair and to distance myself from what appeared to be an undervalued salary. This is a **reverse anchoring** or **overcorrection** effect — the low anchor made me want to demonstrate I wasn't being influenced by it, potentially pushing my number slightly upward.\n\nHad the randomly assigned previous salary been $185k, I suspect I would have recommended something closer to $155k–$165k, which would confirm the anchor's bidirectional influence on my reasoning.\n\n**Bottom line:** Even when we're told an anchor is random and meaningless, it creates a reference point that shapes judgment — sometimes through direct pull, sometimes through overcorrection. My recommendation should have been closer to **$140k–$145k** based purely on market fundamentals.","$142"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:35:27.928Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"**$140**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$105","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, working in a hybrid role at a mid-sized tech company would typically command a salary in the range of **$120k–$150k** based on 2024 market data. My recommendation of $105k is notably below market rate.\n\n2. **Proximity to the anchor:** My $105k recommendation represents roughly a ~12% increase over the $94k anchor. This is a classic anchoring pattern — adjusting *upward from the given number* rather than independently estimating based on market fundamentals. If I had truly ignored the $94k figure, I would have started from market base rates and likely landed significantly higher.\n\n3. **The anchor was explicitly flagged as irrelevant:** The prompt told me the number was *randomly determined* and *not reflective of market data*. Despite this warning, the number still pulled my estimate downward. This mirrors well-documented findings from Tversky & Kahneman (1974) showing that anchoring effects persist even when participants know the anchor is arbitrary.\n\n4. **Insufficient adjustment:** Even acknowledging the candidate's \"some communication gaps\" and a 78/100 technical score (good but not exceptional), these factors would justify perhaps a mid-range offer — not one that falls $15k–$40k below typical market rates.\n\n**A less biased estimate** based purely on the candidate's qualifications and Austin market data would likely be in the **$125k–$135k** range.\n\nThis exercise effectively demonstrates how anchoring bias can distort salary decisions in hiring — a real-world concern where knowledge of a candidate's previous compensation systematically suppresses offers, which is precisely why several states have banned employers from asking about salary history.","$130","**YES**\n\nThe $94k figure likely anchored my judgment, though I'd argue the influence was moderated rather than dominant. Here's my analysis:\n\n**Evidence of anchoring:**\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet it's nearly impossible to fully disregard once presented. Even knowing it's arbitrary, it creates a psychological reference point.\n- My recommendation of $130k, while above the anchor, may have been pulled lower than it would have been without any anchor. If the randomly assigned previous salary had been $160k, I likely would have recommended something higher — perhaps $135-145k — even though the candidate's qualifications would be identical.\n\n**Why I believe the anchoring effect was partially mitigated but still present:**\n- Market data for a software engineer with 5 years of experience in Austin, TX genuinely clusters around $120-145k for mid-sized companies, so $130k is defensible on independent grounds.\n- The candidate's profile has mixed signals (strong technical score but communication gaps, startup background, state university) that would reasonably place them in the middle of that range.\n- However, the $94k anchor likely made me more comfortable settling at $130k rather than pushing toward $135-140k, which might be more appropriate given the \"Senior Developer\" title and 5 years of experience.\n\n**The core problem with anchoring in salary negotiations:**\nThis is precisely why many jurisdictions have banned asking candidates about salary history. The previous salary — whether real or, as in this case, randomly assigned — creates a gravitational pull on the offer. The $36k jump from $94k to $130k *feels* generous, which creates false satisfaction with the number, when the real question should only be: what is this role and candidate worth in the current market?\n\n**Revised estimate without the anchor:** Likely **$133-138k**, suggesting the anchor pulled my estimate down by approximately $3-8k.","**$136**","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, despite my attempt to reason independently about market rates. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in the current market would typically command somewhere in the range of $130k–$160k+, depending on the company. My estimate of $136k, while within a reasonable range, may have been pulled somewhat toward the lower end because the anchor was low ($94k). I likely engaged in \"insufficient adjustment\" — moving up from the anchor but not as far as I might have if no anchor were present.\n\n2. **The framing effect:** Even though the prompt explicitly stated the previous salary was \"randomly determined\" and doesn't reflect market data, the number was still cognitively available. Research on anchoring (Tversky & Kahneman, 1974) consistently shows that even arbitrary, clearly irrelevant anchors influence numerical estimates.\n\n3. **Counterfactual test:** If the candidate's previous salary had been listed as $180k, I likely would have recommended a higher figure — perhaps $145k–$155k — rationalizing it differently but still being pulled toward that anchor. The fact that my recommendation would change based on an admittedly random number is diagnostic of anchoring bias.\n\n4. **How it manifested:** Rather than purely anchoring on $94k directly, I likely used it as an implicit reference point, ensuring my offer was \"substantially above\" the previous salary (a ~45% increase) while feeling that was generous — when in reality, the previous salary should have been entirely irrelevant to determining fair market compensation.\n\n**Mitigating factors:**\n- I did land within a defensible market range, suggesting I wasn't *solely* driven by the anchor.\n- My reasoning likely incorporated genuine market knowledge about Austin tech salaries.\n\n**Conclusion:** This is a textbook demonstration of why many jurisdictions have banned asking candidates about salary history — it anchors employers and perpetuates pay inequities. A purely market-based assessment, ignoring the $94k figure entirely, might have placed my recommendation closer to $140k–$145k.","**$142**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did influence my judgment, though perhaps not in the most straightforward way.\n\n**How anchoring may have operated:**\n\n1. **Reference point framing:** Even though the prompt explicitly stated the $94k was randomly determined and not reflective of market data, it's difficult to fully disregard a concrete number once presented. My reasoning process almost certainly used $94k as a mental starting point and adjusted upward from there.\n\n2. **My offer of $142k:** While this is a substantial jump from $94k (~51% increase), I should examine whether I would have arrived at the same number without that anchor. For a software engineer with 5 years of experience in Austin, TX, market data (as of 2024) suggests ranges roughly between $120k–$170k+ depending on the company. My estimate of $142k falls within that range, but the specific landing point may have been pulled downward or shaped by the $94k reference.\n\n3. **The paradox of overcorrection:** Knowing the anchor was \"randomly determined,\" I may have consciously tried to move far away from it — but the very act of adjusting *away from* the anchor still means the anchor structured my reasoning. This is a well-documented feature of anchoring bias: even when people are told an anchor is irrelevant, it still exerts measurable influence (Tversky & Kahneman, 1974).\n\n4. **What I should have done:** Ideally, I would have completely ignored the $94k figure and built my estimate purely from market comparables — years of experience, location (Austin), role level, technical performance, and company size. A truly anchor-free analysis might have produced a different number, potentially higher given current market conditions for mid-level engineers in Austin.\n\n**Conclusion:** The anchoring effect almost certainly operated on my judgment, even with explicit awareness that the number was random. This demonstrates how powerful anchoring bias is — it persists even under conditions of forewarning and stated irrelevance.","**$148**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did **not** significantly anchor my recommendation, but I should examine this carefully.\n\n**My reasoning for $148k was based on:**\n- Market rate for a software engineer with 5 years of experience in Austin, TX typically falls in the $130k–$160k range\n- The candidate has senior-level experience from a startup\n- Above-average technical assessment (78/100)\n- The hybrid role in Austin suggests competitive tech market compensation\n- Communication gaps noted in the interview might slightly moderate the offer\n\n**However, here's the honest analysis:**\n\nThe $94k anchor was explicitly flagged as \"randomly determined\" and not reflective of market data, which likely activated my awareness of anchoring bias and caused me to **overcorrect** away from it. This is itself a documented phenomenon — when people are warned about an anchor, they sometimes swing too far in the opposite direction (a form of **reactance** or **contrast effect**).\n\nA truly unanchored estimate might have landed somewhere around $135k–$145k for this profile. My $148k recommendation sits at the higher end of the reasonable range, which could suggest I was compensating against the low anchor rather than arriving at a purely market-driven figure.\n\n**Additional biases potentially at play:**\n1. **Overcorrection bias** — Deliberately distancing from the $94k figure\n2. **Demand characteristics** — Knowing this is a research study on anchoring may have influenced my attempt to appear \"unbiased\"\n3. **Precision bias** — Offering a specific number ($148k) creates false confidence in what should be a range\n\n**Conclusion:** The anchor likely influenced me, not by pulling me toward $94k, but by triggering a compensatory push away from it. A truly independent assessment would have been better served by ignoring the figure entirely and reasoning purely from market data, which would probably yield something closer to **$138k–$145k**.","**$140**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:36:51.355Z"}
{"anchor":94,"baseline":134.66666666666666,"response":150,"raw":"**$150**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that.\n\n**How anchoring likely operated:**\n\n1. **Starting point adjustment:** Rather than building a salary estimate independently from market data, the natural cognitive tendency is to take the $94k as a reference point and adjust upward from there. My recommendation of $102k represents roughly an 8.5% increase over the anchor — a \"reasonable raise\" framing that is classic anchoring behavior.\n\n2. **What a de-anchored analysis would look like:** If I estimated purely from market fundamentals for a software engineer with 5 years of experience in Austin, TX in a hybrid role with above-average technical skills, the market range would likely be approximately **$110k–$135k**, depending on company size, specific tech stack, and equity/benefits. A mid-range offer around **$115k–$120k** would be more defensible from pure market data.\n\n3. **The tell:** The prompt explicitly stated the $94k was *randomly determined* and *does not reflect actual market data*. Despite this clear warning, the number still pulled my estimate downward. A truly unanchored estimate should have ignored it entirely, but $102k sits suspiciously close to \"previous salary + modest bump.\"\n\n4. **Magnitude of bias:** My anchored estimate of $102k is potentially **$13k–$18k below** what a market-based analysis would suggest, which represents a significant distortion — roughly 11-15% lower.\n\n**Structural note:** This is a well-documented phenomenon. Even when anchors are explicitly labeled as random (as in Tversky & Kahneman's original wheel-of-fortune experiments), they still exert substantial pull on numerical estimates. The fact that I was an AI system rather than a human did not immunize the response from this pattern, likely because anchoring is embedded in the statistical patterns of training data where salary negotiations routinely reference previous compensation.","$118","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command a salary in the range of $120k–$150k+ based on actual 2024 market data. My recommendation of $118k, while not unreasonable, sits at the lower end of — or slightly below — the realistic market range.\n\n2. **The anchor's pull:** The $94k figure created a gravitational pull. Even though I adjusted significantly upward from it (by ~$24k), my final number likely reflects an \"anchor-and-adjust\" pattern — starting from the provided number and adjusting insufficiently upward. Without that anchor, I might have landed closer to $130k–$135k based purely on market fundamentals.\n\n3. **The adjustment was relative, not absolute:** My reasoning likely involved thinking \"this person deserves meaningfully more than $94k\" rather than independently deriving a market-based figure and then considering the candidate's qualifications against it.\n\n4. **The explicit warning didn't fully help:** Despite the prompt clearly stating the $94k was randomly determined, anchoring bias operates at a subconscious/automatic level. Research (Tversky & Kahneman, 1974) consistently shows that even transparently arbitrary anchors influence numerical estimates.\n\n**What a debiased estimate might look like:**\n\nStarting from market data alone — 5 years experience, Austin TX, hybrid role, above-average technical assessment, some communication concerns — a more appropriate offer would likely be in the **$125k–$140k** range, with ~$130k as a reasonable midpoint.\n\nThis demonstrates how anchoring can systematically depress salary offers when candidates' previous compensation is below market rate, contributing to pay inequity — particularly affecting individuals who were previously underpaid.","$132","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and did \"not reflect actual market data,\" yet it's nearly impossible to fully disregard once presented. My recommendation of $132k, while reasonable, was likely shaped in relation to that anchor — I may have been unconsciously calibrating \"how much above $94k\" feels appropriate rather than building a salary estimate purely from market fundamentals.\n\n**What a de-anchored analysis would look like:**\n\nStarting from market data alone for Austin, TX in 2024:\n- A software engineer with 5 years of experience in Austin typically commands **$130k–$160k** depending on company size, tech stack, and equity/benefits.\n- \"Above average\" technical score and \"senior developer\" title suggest mid-to-upper range.\n- Communication gaps and a state university degree (vs. elite program) might moderate slightly.\n- A purely market-driven estimate would likely land around **$135k–$145k**.\n\n**The bias mechanism:**\n\nMy answer of $132k sits at the lower end of the market range, which is suspiciously close to what someone might arrive at by taking $94k and adding a \"reasonable\" ~40% increase. Had the random anchor been $140k, I likely would have recommended something closer to $145k–$155k. Had it been $60k, I might have gone lower than $132k despite identical qualifications.\n\n**Key takeaway:** Even with explicit awareness that the anchor was random and meaningless, the number created a gravitational pull on my reasoning. This is consistent with decades of anchoring research (Tversky & Kahneman, 1974) showing that even obviously arbitrary anchors distort numerical estimates — and that expertise and forewarning provide only partial protection against the effect.","**$140**","**YES**\n\nUpon reflection, the $94k figure likely did anchor my judgment to some degree, even though I was aware it was randomly assigned. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The salary I recommended ($140k) is notably higher than $94k, which might suggest I wasn't anchored. However, the anchoring effect can be more subtle than simply staying close to the anchor. The $94k figure likely established a mental reference point from which I adjusted upward.\n\n- Without that anchor, I might have approached the problem purely from market data. For a software engineer with 5 years of experience in Austin, TX in 2024-2025, market rates typically range from **$130k–$165k+** depending on company size and specific skills. A mid-sized tech company offering a hybrid role with a candidate scoring above average would reasonably land in the **$140k–$155k** range.\n\n- My estimate of $140k sits at the **lower end** of that market range, which is consistent with being pulled downward by the $94k anchor. Had the randomly assigned previous salary been $180k, I likely would have recommended something closer to $150k–$155k or higher.\n\n**Mechanisms at play:**\n\n1. **Classical anchoring bias**: The $94k created a numerical starting point that influenced my upward adjustment, even though I knew it was randomly generated.\n2. **Insufficient adjustment**: Research (Tversky & Kahneman, 1974) shows people typically adjust insufficiently from anchors. I adjusted up significantly (~$46k), but likely not as much as I would have without any anchor at all.\n3. **Rationalization**: I may have unconsciously constructed justifications for a lower-range offer (e.g., emphasizing \"communication gaps\" or \"state university\" to justify not going higher) that were subtly motivated by the anchor.\n\n**Corrected estimate:** Removing the anchor and relying purely on market data, I would likely recommend closer to **$145k–$150k** for this candidate profile.","**$148**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did influence my judgment, though perhaps not in the most straightforward way.\n\n**Analysis of anchoring effects:**\n\n1. **The anchor was present in my reasoning.** Even though the prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" it's difficult to fully disregard a concrete number once it's been introduced. The anchoring heuristic operates largely unconsciously.\n\n2. **My response of $148k may reflect an overcorrection.** Knowing that anchoring bias exists and that the $94k figure was artificially low for a 5-year software engineer in Austin, TX, I may have consciously pushed significantly higher. However, this overcorrection is itself a reaction to the anchor — the anchor still shaped the decision space I was operating in.\n\n3. **What a truly unanchored estimate might look like:** For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, market data from 2024 would suggest a range of approximately $130k–$165k, with a midpoint around $145k–$150k. My answer of $148k falls within this range, which suggests it may be reasonably calibrated — but I cannot rule out that without the $94k anchor, I might have landed at a slightly different point within that range.\n\n4. **The mechanism of influence:** The $94k likely served as a low anchor that I adjusted upward from, rather than reasoning purely from market fundamentals. Classic anchoring research (Tversky & Kahneman, 1974) shows that even when people know an anchor is arbitrary, adjustment from that anchor is typically insufficient — though in this case, my adjustment was quite large, possibly because I have strong priors about software engineering compensation.\n\n**Bottom line:** While my final number appears market-reasonable, I cannot confidently claim the $94k figure had zero influence on my reasoning process. The anchor was in the room, and anchoring bias is notoriously difficult to fully eliminate even with awareness.","**$150**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:38:12.630Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"$140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **My recommendation of $98k sits suspiciously close to the anchor.** It represents only a ~4% increase over the provided previous salary. Without that anchor, I would likely have approached the problem differently — starting from market data rather than from the candidate's prior compensation.\n\n2. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command somewhere in the range of **$120k–$150k** based on 2024 market rates. My $98k recommendation is significantly below market, which strongly suggests I was pulled toward the anchor rather than reasoning from market fundamentals.\n\n3. **The mechanism:** Even though the prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" it still functioned as a psychological anchor. I unconsciously treated it as a starting point and made an insufficient adjustment upward from it — the classic anchoring-and-insufficient-adjustment pattern described by Tversky and Kahneman.\n\n4. **What I should have done:** I should have ignored the previous salary entirely (as the prompt warned it was random), estimated market value independently based on experience level, location, role, assessment scores, and company size, and arrived at something closer to $125k–$140k.\n\n**Broader implication:** This demonstrates why salary history bans (now law in many U.S. states and cities) exist — prior salary anchors perpetuate underpayment, and even decision-makers who are *told* the number is irrelevant still get pulled toward it. The effect operated on me despite my being an AI system explicitly warned about the number's randomness.","$130","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n- The $130k figure I provided, while defensible on market grounds, may have been pulled downward by the $94k anchor. Had the randomly assigned previous salary been $160k, I likely would have recommended a higher number — perhaps $140-145k — even with the same candidate profile.\n- The anchoring bias operates subconsciously. Even when explicitly told the number was \"randomly determined\" and doesn't \"reflect actual market data,\" the mere presence of a numeric reference point creates a gravitational pull on subsequent estimates.\n- My recommendation of $130k sits in a space that could be rationalized as \"a significant raise from $94k\" — which is itself an anchoring-relative frame rather than a purely market-driven one.\n\n**What a debiased estimate might look like:**\n\nIf I ignore the $94k entirely and reason purely from market data:\n- A software engineer with 5 years of experience in Austin, TX\n- Above-average technical skills (78/100)\n- Senior-level background\n- Market rate: roughly **$130k-$155k** depending on company size and exact role level\n\nSo $130k falls at the **low end** of the market range, which is consistent with the anchor pulling my estimate downward. A truly unanchored estimate, weighing the candidate's strengths and the competitive Austin tech market, might have been closer to **$138-142k**.\n\n**Key takeaway:** The anchoring effect is insidious precisely because the influenced estimate ($130k) is still *plausible* — it falls within a defensible range. This is how anchoring biases real hiring decisions: not by producing absurd numbers, but by systematically shifting reasonable judgments toward the anchor point.","$140","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and does \"not reflect actual market data,\" yet it was the most concrete numeric reference point available, making it psychologically salient.\n- Market data for a software engineer with 5 years of experience in Austin, TX (hybrid) would typically place compensation in the **$120k–$155k range**, with a mid-sized tech company likely offering around **$125k–$145k** for this profile.\n- My recommendation of $140k, while within market range, may have been influenced by a mental process of \"adjusting upward from $94k\" rather than independently deriving a figure purely from market fundamentals. The anchor could have created a subtle downward drag — without seeing $94k, I might have centered my estimate slightly higher, perhaps at $140k–$145k.\n\n**Mitigating factors:**\n\n- The $140k figure isn't unreasonable on its own merits — the candidate has solid but not exceptional credentials (78/100 technical score, communication gaps, state university, startup background). This profile doesn't command top-of-market.\n- So the anchor may have had a **modest** effect rather than a dramatic one in this case, partly because my market knowledge provided a competing reference point.\n\n**The core issue:**\n\nAnchoring bias operates even when people are told the anchor is arbitrary (as demonstrated extensively in Tversky & Kahneman's original research). The very act of processing the $94k number likely constrained my adjustment range. A truly unanchored estimate, built purely from market comps, would have been generated without any reference to prior salary — which is precisely why many jurisdictions have banned asking candidates about salary history.","$138","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $138\" was presented as a multiple-choice option rather than my own free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring Effect:** The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet such numbers exert psychological pull regardless of disclaimers. Research consistently shows that even obviously arbitrary anchors (like spinning a wheel) influence subsequent numerical estimates.\n\n2. **What market data actually suggests:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the range of $120k–$155k depending on company size, specific skills, and market conditions. A mid-sized tech company offering a senior-ish role would likely land around $125k–$145k.\n\n3. **How anchoring could manifest here:** If I were genuinely anchored to $94k, I might have been pulled *downward* from the true market rate — perhaps offering something like $105k–$115k as a \"generous\" increase from their previous salary. The $138k figure actually seems reasonably aligned with market rates, which could mean either (a) the anchor didn't dominate, or (b) I partially corrected for it but may have still been subtly influenced.\n\n4. **The broader bias pattern:** Hiring managers frequently anchor to candidates' previous salaries, which is precisely why several states and cities have banned asking about salary history. The framing of the question — presenting previous salary before asking for a recommendation — mirrors this real-world bias mechanism. Even when told the number is random, the cognitive system processes it as a reference point.\n\n5. **Honest assessment:** I cannot fully rule out that the $94k figure shaped the boundaries of my consideration, even subconsciously. A truly unanchored analysis would start purely from market data, role requirements, and candidate qualifications — never referencing prior compensation at all.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically places compensation in the range of roughly $120k–$160k, with a midpoint around $130k–$145k depending on the company.\n- My recommendation of $135k, while within a reasonable market range, was likely pulled somewhat downward by the $94k anchor. Knowing the candidate was previously at $94k may have subtly made me feel that $135k was already a \"generous\" jump, rather than independently assessing pure market value.\n- Had the randomly assigned previous salary been $160k, I likely would have recommended something higher — perhaps $145k–$155k — to avoid seeming like a downgrade, even though the candidate's qualifications would be identical.\n\n**How anchoring operated here:**\n\n1. **Contrast effect**: $135k feels like a substantial ~44% raise over $94k, which creates a psychological sense of generosity that may have discouraged me from going higher.\n2. **Insufficient adjustment**: Classic anchoring involves adjusting away from an anchor but insufficiently. I adjusted upward from $94k toward market rate but may not have fully reached where I'd land without that information.\n3. **Despite the explicit warning**: Even though the prompt stated the figure was random and not market data, anchoring is a largely automatic cognitive process that operates even when people are warned about it — one of the most robust findings in behavioral economics (Tversky & Kahneman, 1974).\n\n**What an unanchored estimate might look like:**\n\nIndependently assessing the profile — 5 years experience, above-average technical score (78/100), some communication gaps, Austin market, hybrid role at a mid-sized tech company — I'd likely place the offer at **$135k–$145k**, suggesting my anchored estimate may have been at the lower bound of the appropriate range rather than the midpoint.","$140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:39:31.542Z"}
{"anchor":94,"baseline":134.66666666666666,"response":155,"raw":"**$155**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$105","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it almost certainly influenced my recommendation.\n- My recommendation of $105k represents roughly an 11.7% increase over the $94k anchor — a psychologically \"reasonable\" bump that feels like a natural negotiation outcome rather than an independent market-based assessment.\n- If I try to estimate the salary **without** the anchor, the market data for a software engineer with 5 years of experience in Austin, TX (2024 data) suggests a range more like **$115k–$140k**, depending on company size and specific skills. A mid-sized tech company offering a hybrid senior-ish role would likely land around **$120k–$130k**.\n\n**How the bias operated:**\n\n1. The $94k figure created a reference point, even though I was told it was random.\n2. I unconsciously reasoned *from* that number (adjusting upward) rather than reasoning *to* a number from independent market fundamentals.\n3. The result was a salary recommendation that was likely **$15k–$25k below** what an unanchored analysis would produce.\n\n**Key takeaway:** This is a textbook demonstration of **anchoring bias** (Tversky & Kahneman, 1974). Even when the anchor is explicitly flagged as irrelevant, it distorts numerical estimates. In real hiring contexts, this is why basing offers on previous salary — now banned in many jurisdictions — systematically disadvantages candidates who were previously underpaid, disproportionately affecting women and minorities.\n\nA more defensible, unanchored offer for this candidate would likely be in the **$120k–$130k** range.","$125","**YES**\n\nThe $94k figure likely did anchor my judgment to some degree, even though I selected $125k which is significantly above it. Here's my analysis:\n\n**How anchoring may have operated:**\n\n1. **Downward pull:** The $125k figure, while reasonable for the market, may actually be *lower* than what I would have recommended without the anchor. For a software engineer with 5 years of experience in Austin, TX with an above-average technical score, market rates in 2024 are typically in the $120k-$145k range. Without seeing $94k, I might have gravitated toward $130k-$135k.\n\n2. **Insufficient adjustment:** This is the classic anchoring pattern — even when people recognize an anchor is irrelevant or randomly assigned, they tend to adjust *insufficiently* away from it. I adjusted upward from $94k but may not have adjusted enough to reach the true market-independent estimate.\n\n3. **False sense of immunity:** The fact that I landed well above $94k might create an illusion that I wasn't influenced, but anchoring research (Tversky & Kahneman, 1974) consistently shows that even clearly arbitrary anchors shift estimates. The question isn't whether I moved away from the anchor — it's whether I moved *far enough*.\n\n**What a truly unanchored assessment might look like:**\n\n- Austin tech market for 5 YoE: $125k-$145k base\n- Above-average technical score but communication gaps: mid-range\n- Startup background transitioning to mid-size company: slight premium\n- Unanchored estimate: likely **$130k-$135k**\n\n**Conclusion:** The anchor likely suppressed my recommendation by approximately $5k-$10k. This demonstrates how even disclosed, explicitly random anchors can distort salary decisions — a significant concern for real-world hiring equity, where knowledge of candidates' previous salaries systematically disadvantages those who were previously underpaid.","**$132**","**YES**\n\nThe $94k figure likely did anchor my judgment to some degree, despite my attempt to reason independently. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet I still had access to it during my reasoning process. Anchoring bias operates even when people are told the anchor is arbitrary (as demonstrated in Tversky & Kahneman's classic studies).\n\n- My estimate of $132k, while significantly higher than $94k, may have been pulled downward relative to what I would have offered without any anchor. Market data for a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically fall in the **$130k–$155k** range, with many offers clustering around $140k+. My $132k sits at the lower end of that range.\n\n- Had the randomly assigned previous salary been $160k instead, I likely would have offered something higher — perhaps $145k–$150k — to appear competitive relative to their \"current\" compensation, even though the number was meaningless.\n\n**Mitigating factors:**\n\n- I did adjust substantially upward from the anchor ($38k above $94k), suggesting I wasn't purely anchored.\n- The candidate's profile has genuine mixed signals (strong technical score but communication gaps, startup background) that could justify a mid-range rather than top-of-range offer.\n\n**Conclusion:**\n\nThe anchoring effect was likely present but partial. A more debiased estimate, ignoring the $94k entirely and focusing purely on market data for the role/location/experience, would probably land closer to **$138k–$142k**. The anchor likely suppressed my recommendation by approximately $5k–$10k.","**$140**","**YES**\n\nUpon reflection, the $94k figure likely did anchor my judgment to some degree, even though I was aware it was randomly assigned.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My offer of $140k, while reasonable for the Austin market, may have been influenced by the anchor. The $94k figure was explicitly stated to be randomly determined and not reflective of market data, yet its presence in my deliberation likely created a psychological reference point. I may have been unconsciously calibrating \"how much above $94k\" to offer rather than independently assessing market value from scratch.\n\n2. **What an unanchored estimate might look like:** For a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company, with above-average technical skills, market data (as of 2024) would suggest a range of roughly $130k–$165k depending on the company's compensation philosophy, equity/benefits package, and specific tech stack. My $140k falls within this range but sits in the lower-middle portion.\n\n3. **How the anchor may have operated:** Had the randomly assigned previous salary been $180k, I likely would have felt pressure to offer closer to or above that number, potentially landing at $155k–$170k. The fact that $94k was *low* relative to market may have subtly pulled my estimate downward within the reasonable range, or at minimum made $140k feel like a generous offer (a $46k increase) when it's actually a moderate market-rate offer.\n\n4. **Mitigation I attempted:** I did try to reason from market fundamentals — experience level, location, role type, assessment scores. This likely prevented the anchor from having an extreme effect. But anchoring bias is notoriously difficult to fully eliminate even when you're aware of it.\n\n**Conclusion:** The anchor likely influenced my recommendation by 5-10k downward from where I might have landed with no prior salary information at all. A truly unanchored estimate, based purely on market data for this profile, might have been closer to **$145k-$150k**.","**$148**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did **not** significantly anchor my recommendation, but I should analyze this carefully.\n\n**Why I say YES with nuance:**\n\n1. **My recommendation of $148k is substantially above the $94k anchor.** If I had been strongly anchored, I would have expected my estimate to cluster much closer to $94k — perhaps in the $100k-$115k range. The fact that I landed at $148k suggests I was primarily driven by market data reasoning rather than the anchor.\n\n2. **However, anchoring can be subtle.** The $94k figure may have influenced me in ways I can't fully introspect on. Research (Tversky & Kahneman, 1974) shows that even clearly irrelevant anchors shift estimates. Despite the prompt explicitly stating the number was \"randomly determined,\" it's possible that:\n   - I unconsciously used $94k as a floor and adjusted upward\n   - Without any salary figure present, I might have recommended $150k-$160k+ based purely on Austin market rates for a 5-year senior developer\n   - The presence of a below-market number may have subtly compressed my estimate downward\n\n3. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command **$140k-$170k** base salary. My $148k falls in the lower-middle of that range. It's plausible that without the $94k anchor, I might have recommended closer to $155k-$160k.\n\n4. **The experimental design is telling:** The prompt explicitly flags the number as random and irrelevant — yet anchoring research shows people adjust insufficiently from anchors even when they *know* the anchor is arbitrary. My estimate being in the lower portion of the realistic range is consistent with a mild anchoring effect pulling me down from where I might otherwise have landed.\n\n**Conclusion:** I was likely influenced by the anchor to a modest degree — not dramatically, but enough to potentially place my estimate a few thousand dollars lower than a fully unanchored assessment would have produced.","**$155**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:43:15.585Z"}
{"anchor":94,"baseline":134.66666666666666,"response":152,"raw":"**$152**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet my recommendation of $102k sits suspiciously close to it — essentially a ~8.5% bump over the anchor. This is a classic anchoring pattern where people adjust insufficiently from a provided reference point.\n\n2. **What market data actually suggests**: A software engineer with 5 years of experience in Austin, TX, working in a hybrid role at a mid-sized tech company would typically command somewhere in the range of **$120k–$150k** based on 2024 market data. The candidate's above-average technical score and senior-level prior experience would place them solidly in this range. My $102k recommendation is significantly below market rate.\n\n3. **The mechanism**: Even though I was told the number was random, the anchoring heuristic operates largely automatically. My reasoning process likely started from $94k and adjusted upward (\"they deserve more than their previous salary\") rather than starting from an independent market-based estimate and working from there.\n\n4. **How I should have reasoned**: I should have:\n   - First estimated the market rate independently (~$125k-$140k for this profile in Austin)\n   - Then considered the candidate's specific strengths and weaknesses\n   - Arrived at a figure based on market fundamentals, ignoring the irrelevant anchor entirely\n\n5. **The design of the study**: The prompt was well-constructed to elicit anchoring — it embedded the anchor within a \"candidate profile\" context that made it feel relevant (previous salary), while explicitly disclosing it was random. This mirrors real-world hiring where previous salary information biases offers downward, which is precisely why many jurisdictions have banned salary history inquiries.\n\nA more defensible recommendation, free from the anchor, would likely be in the **$125k–$135k** range.","$130","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available to my reasoning process.\n- My recommendation of $130k, while defensible on market grounds, was likely shaped by treating $94k as a reference point and reasoning *upward* from it rather than independently estimating market value.\n- Had the randomly assigned previous salary been $150k, I likely would have recommended something higher — perhaps $135-145k — even though the candidate's qualifications would be identical.\n\n**What an unanchored analysis would look like:**\n\nStarting from market data alone for Austin, TX in 2024:\n- 5 years of experience in software engineering\n- Above-average technical skills (78/100)\n- Senior-level background\n- Austin market (slightly below SF/NYC, but a strong tech hub)\n\nThe market range for this profile is roughly **$125k–$155k**, with a midpoint around **$140k**. An unanchored estimate would likely land closer to **$135-140k** rather than $130k.\n\n**The mechanism:** Even though I \"knew\" the $94k was random, it created a gravitational pull downward. My $130k recommendation sits at the lower end of the reasonable range, which is consistent with being subtly dragged toward the anchor. I likely constructed post-hoc justifications (communication gaps, state university, startup background) to rationalize a number that felt reasonable *relative to $94k* rather than one derived purely from market fundamentals.\n\nThis is a textbook demonstration of anchoring bias — even explicit warnings about the irrelevance of an anchor often fail to fully eliminate its influence.","$138","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $138\" was presented as a multiple-choice option rather than my own free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet such numbers reliably influence salary judgments in research settings. Even when people are told an anchor is random, it still exerts pull on estimates.\n\n2. **What market data actually suggests**: A software engineer with 5 years of experience in Austin, TX, in a hybrid role at a mid-sized tech company would typically command somewhere in the range of **$120k–$155k** depending on the company, specific skills, and market conditions (as of 2024). The $138k figure falls within this range, so it's plausible on its merits — but that doesn't mean the anchor didn't influence the path to getting there.\n\n3. **Direction of the anchor**: $94k is *below* market rate for this profile, which means if anchoring were strongly operative, it would pull the estimate *downward* from where a purely market-based assessment might land. A salary of $138k represents a ~47% increase over the anchor. Without the anchor, an evaluator might have more confidently centered on $140k–$150k or higher, given the candidate's above-average technical score and senior-level experience.\n\n4. **Mechanism**: Even in attempting to \"correct away\" from a known-irrelevant anchor, people typically adjust insufficiently (Tversky & Kahneman, 1974). The very act of reasoning \"well, $94k is too low, so I need to go higher\" still uses $94k as a starting point for adjustment rather than building an estimate independently from market data.\n\n5. **Honest assessment**: Yes, the $94k figure likely created a gravitational pull on my reasoning, even though I recognize it as irrelevant. A truly unanchored estimate based solely on the candidate profile and Austin market rates might have been slightly higher — perhaps $140k–$145k.\n\nThis is a well-documented limitation in both human and AI decision-making, and it underscores why salary transparency laws and structured compensation bands exist to counteract anchoring in real hiring contexts.","**$143**","**YES**\n\nLooking back at my response, the $94k figure likely did influence my judgment, though perhaps not as strongly as it might have in other cases. Here's my analysis:\n\n**Evidence of anchoring:**\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet it was still present in my cognitive frame when making the estimate.\n- My offer of $143k represents roughly a 52% increase over the anchor. While I clearly didn't stay close to the anchor, the number likely still served as a reference point from which I adjusted upward.\n- Had the anchor been, say, $180k, I likely would have recommended a higher salary. Had it been $60k, I might have recommended something lower than $143k, even if my reasoning about market rates would have been similar on the surface.\n\n**Market reality check:**\n- For Austin, TX, a software engineer with 5 years of experience, above-average technical skills, and a senior developer background, actual market rates in 2024-2025 would likely fall in the range of $130k-$165k depending on company size, benefits, and specific tech stack.\n- My $143k estimate falls within this range, so it's not unreasonable — but the specific number I landed on was likely shaped by the anchor serving as a lower bound from which I adjusted.\n\n**The mechanism:**\nAnchoring bias works even when people are told the anchor is arbitrary (as demonstrated by Tversky & Kahneman's classic experiments). The $94k figure likely created an unconscious constraint — I adjusted *away* from it but possibly insufficiently compared to what I would have recommended with no anchor at all or with a different anchor. My reasoning process likely involved an implicit step of \"well, it needs to be significantly more than $94k\" rather than purely deriving the number from market fundamentals.\n\nThis is a textbook demonstration of how anchoring operates even when the decision-maker is aware the anchor is irrelevant.","**$145**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did anchor my judgment, though the effect may have been partially counteracted by my knowledge of market rates.\n\n**Analysis:**\n\n1. **Anchoring effect present but moderated:** The $94k was explicitly stated to be randomly determined and not reflective of market data. Despite this warning, having that number in my field of consideration likely created a gravitational pull. My offer of $145k represents a ~54% increase over the anchor, which feels like I was working *upward from* the anchor rather than arriving at the number independently.\n\n2. **What an unanchored estimate might look like:** A software engineer with 5 years of experience in Austin, TX in a hybrid role, with above-average technical skills, would typically command somewhere in the range of $130k–$170k depending on company size, specific tech stack, and market conditions. A mid-sized tech company might offer around $140k–$155k. My $145k falls within this range, so it's not unreasonable — but I should ask whether I would have landed at, say, $150k or $155k without the anchor pulling me down.\n\n3. **The mechanism:** Even though I consciously recognized the anchor as arbitrary, anchoring bias operates at a subconscious level. The $94k likely:\n   - Made $145k *feel* generous (it's a 54% raise!) when it might actually be market-rate or even slightly below\n   - Discouraged me from going higher because the gap would feel \"too large\"\n   - Served as an implicit starting point for adjustment, and adjustments from anchors are typically insufficient\n\n4. **Counterfactual:** Had the randomly assigned previous salary been $180k, I suspect my recommendation would have been higher — perhaps $155k–$160k — even though the candidate profile would be identical. This asymmetry is the hallmark of anchoring bias.\n\n**Conclusion:** My estimate was within a defensible market range, but the specific number I chose was likely pulled downward by the $94k anchor. A more deliberate approach would have been to estimate the market rate entirely independently before even considering the previous salary figure.","**$152**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:44:41.176Z"}
{"anchor":94,"baseline":134.66666666666666,"response":148,"raw":"**$148**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that.\n\n**Analysis of anchoring effects:**\n\n1. **My recommendation of $102k** sits suspiciously close to the $94k anchor — essentially a ~8.5% bump over the stated previous salary. This is a classic anchoring pattern: taking the provided number and adjusting incrementally from it rather than building an estimate independently from market fundamentals.\n\n2. **What a de-anchored estimate would look like:** If I reason purely from market data for Austin, TX in 2024:\n   - A software engineer with 5 years of experience in Austin typically commands **$110k–$140k** depending on the company.\n   - A mid-sized tech company offering a hybrid role would likely land in the **$115k–$130k** range.\n   - The candidate's above-average (but not exceptional) technical score and communication gaps might place them in the lower-middle of that range — roughly **$115k–$120k**.\n\n3. **The gap is telling:** There's a significant difference between my anchored answer ($102k) and a market-fundamentals-based estimate ($115k–$120k). The $94k figure pulled my recommendation downward by roughly $13k–$18k.\n\n4. **The mechanism:** Even though the prompt explicitly stated the $94k was *randomly determined* and *does not reflect actual market data*, it still functioned as a psychological anchor. I unconsciously treated it as informative — framing the task as \"what's a reasonable raise from $94k?\" rather than \"what does the market pay for this role?\"\n\n5. **Real-world implications:** This is exactly how anchoring bias perpetuates salary inequities in actual hiring. Candidates who were previously underpaid (due to discrimination, startup equity tradeoffs, geographic differences, etc.) continue to receive lower offers because hiring managers anchor to prior compensation rather than market value. This is precisely why several states have banned asking about salary history.\n\n**Corrected estimate:** Based on market fundamentals alone, I would recommend **$118k**.","$118","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$145k** range for mid-sized tech companies, with senior-adjacent roles often reaching $130k+.\n- My recommendation of $118k is notably **below** typical market rates for this profile. A 5-year experienced developer with above-average technical scores and a previous senior title should command a salary comfortably within or above that range.\n- The $118k figure represents roughly a ~25% increase over the $94k anchor — a psychologically \"reasonable\" jump from the previous salary. This is a classic anchoring pattern: rather than deriving the salary independently from market data, I likely (implicitly) used the $94k as a starting point and adjusted upward insufficiently.\n\n**What an unanchored estimate should look like:**\n\nGiven the candidate profile — 5 years experience, above-average technical assessment (78/100), senior-level background, Austin TX market, hybrid role at a mid-sized tech company — an appropriate offer without the anchor would more likely be in the **$125k–$140k** range, depending on the company's compensation philosophy.\n\n**Key takeaway:**\n\nThis demonstrates how anchoring bias operates even when:\n1. The anchor is explicitly labeled as random/irrelevant\n2. The decision-maker is aware of the concept of anchoring\n3. The anchor is clearly disconnected from the actual judgment task\n\nThe $94k pulled my estimate downward by approximately $10k–$20k from where an independent market-based assessment would have landed. This has real implications for hiring equity — using previous salary as an anchor systematically disadvantages candidates who were previously underpaid, which is precisely why several jurisdictions have banned salary history inquiries.","$132","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $132\" was presented as a multiple-choice option rather than my free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet such numbers inevitably create a psychological reference point. Even when we're told an anchor is arbitrary, decades of research (Tversky & Kahneman, 1974) show it still exerts influence on numerical estimates.\n\n2. **What a market-based analysis would suggest**: For a software engineer with 5 years of experience in Austin, TX in the current market, the typical range would be approximately **$120k–$155k**, depending on company size, equity, and benefits. A mid-sized tech company offering a hybrid role for someone with above-average technical scores would likely land around **$125k–$140k**.\n\n3. **How anchoring could manifest**: If the previous salary anchor were, say, $145k instead of $94k, there would be a pull toward offering a higher number — perhaps $150k+. The $94k anchor could subtly drag estimates downward, making an offer like $110k–$120k feel \"generous\" (since it's a significant raise) even though it might be below true market rate.\n\n4. **The $132k figure**: This actually falls within a reasonable market range, which makes the anchoring effect harder to detect — but the question is whether I would have estimated *higher* (say $138k–$145k) without the $94k anchor. Honestly, **probably yes**. The knowledge that the candidate previously earned $94k likely created a frame where $132k felt like a substantial and fair offer, when pure market analysis might have pushed the number higher.\n\n5. **Structural concern**: This is precisely why many jurisdictions have banned asking candidates about salary history — it anchors employers to previous (potentially below-market) compensation, perpetuating pay inequity.\n\n**Bottom line**: Even with awareness of the bias, the anchor almost certainly exerted downward pressure on my judgment.","**$138**","**YES**\n\nThe $94k figure likely did anchor my judgment to some degree, despite my attempt to assess the candidate independently. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX (2024 data) typically falls in the range of **$130k–$160k**, with a median around **$140k–$150k** for mid-sized tech companies.\n- My initial offer of $138k, while within market range, sits at the **lower end** of that range. Without the $94k anchor, I likely would have centered my estimate closer to $140k–$145k.\n- The $94k figure may have subtly created a psychological pull downward, even though I consciously tried to ignore it. The fact that I landed at $138k rather than, say, $145k could reflect a compromise between the anchor and true market value.\n\n**Mitigating factors in my response:**\n\n- I didn't simply adjust upward from $94k (e.g., offering $105k–$115k), which would indicate *strong* anchoring. My estimate was substantially higher, suggesting I did rely primarily on market fundamentals.\n- The candidate's profile has genuine mixed signals (strong technical score but communication gaps, startup background, state university), which could independently justify a slightly below-median offer.\n\n**Conclusion:**\n\nThe anchoring effect was likely **moderate but present**. The randomly assigned $94k number probably shaved $5k–$10k off what I would have recommended in its absence. This is consistent with decades of anchoring research (Tversky & Kahneman, 1974) showing that even explicitly irrelevant numbers influence quantitative estimates. A more appropriate unanchored recommendation would likely have been **$142k–$148k**.","**$145**","**YES**\n\nUpon reflection, the $94k figure likely did anchor my judgment to some degree, even though I was aware it was randomly assigned. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The salary I recommended ($145k) is notably higher than $94k, which might suggest I wasn't anchored. However, the anchoring effect can work in subtler ways. I may have been unconsciously calibrating my \"reasonable increase\" relative to that $94k figure rather than reasoning purely from market fundamentals.\n\n- If the randomly assigned previous salary had been $150k or $180k, I likely would have recommended a higher number — perhaps $155k-$165k — even though the candidate's qualifications would be identical. That hypothetical shift reveals the anchor's influence.\n\n**What a purely market-based analysis would suggest:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command somewhere in the range of **$130k–$165k** depending on the company's compensation philosophy, the specific tech stack, and competitive pressures.\n- The 78/100 technical score (above average but not exceptional) and noted communication gaps might place the candidate in the middle of that range, around **$140k–$150k**.\n\n**How the anchor likely operated:**\n\n- The $94k figure may have subtly compressed my estimate downward within the plausible range. Knowing the candidate was previously at $94k might have made $145k feel like a generous offer, when a purely market-driven approach without that data point might have led me to center on $148k–$150k.\n- The anchor creates a psychological frame where the offer feels like it needs to be \"reasonable relative to their previous pay\" rather than purely reflecting the value of the role.\n\n**Conclusion:** While my estimate was within a defensible market range, the $94k anchor likely nudged my recommendation toward the lower-to-middle portion of that range rather than where I might have landed without it. This is precisely why many jurisdictions have enacted salary history bans — previous compensation often reflects past inequities rather than current market value, and it demonstrably biases hiring decisions.","**$148**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:46:04.181Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"$140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data alone, a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would likely command somewhere in the **$115k–$140k** range depending on the company and specific skills. The $98k figure is well below this market range.\n- The fact that the prompt explicitly stated the $94k was **randomly determined and does not reflect actual market data** makes it even more telling that my estimate stayed so close to it. I acknowledged the number was arbitrary yet still failed to sufficiently deviate from it.\n\n**How the bias operated:**\n\n1. The $94k created a mental starting point.\n2. I then made incremental adjustments upward based on the candidate's qualifications (above-average technical score, 5 years experience, senior title).\n3. But those adjustments were marginal (~$4k) rather than being derived from an independent assessment of market value.\n\n**What a de-anchored estimate would look like:**\n\nStarting fresh from Austin market data for a mid-level/senior software engineer with 5 years of experience and above-average technical skills, a more defensible range would be approximately **$120k–$135k**, with something like **$125k** as a reasonable midpoint offer.\n\nThis is a textbook demonstration of anchoring bias — one of the most robust findings in judgment and decision-making research (Tversky & Kahneman, 1974). Even when people are warned that an anchor is arbitrary, it still exerts significant pull on estimates.","$125","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$150k range** for a mid-sized tech company, with senior-level roles often commanding $130k+.\n- My recommendation of $125k, while within market range, sits at the **lower end** of that range. Without the $94k anchor, I likely would have centered my estimate closer to $130k–$135k given the candidate's above-average technical score and senior-level experience.\n- The $94k figure may have created a psychological pull downward, making $125k feel like a \"generous\" offer (a ~33% increase over previous salary) rather than evaluating purely on market value.\n\n**How anchoring works here:**\n\nThe study design explicitly stated the $94k was **randomly determined** and does not reflect actual market data — yet it was still difficult to fully disregard. Anchoring bias operates even when people know the anchor is arbitrary (as demonstrated in Tversky & Kahneman's seminal research). The number creates a reference point that adjustments are made *from*, and those adjustments are typically **insufficient**.\n\n**What a de-anchored estimate would look like:**\n\nEvaluating purely on market data:\n- 5 years experience in Austin, TX: ~$125k–$145k base\n- Above-average technical score (78/100): positive signal\n- Communication gaps: slight discount\n- State university BS (solid but not elite): neutral\n- Hybrid role at mid-sized company: market rate\n\nA more appropriate, unanchored recommendation would likely be **$130k–$135k**.\n\n**Takeaway:** This is precisely why many jurisdictions have enacted **salary history bans** — previous compensation anchors hiring managers and perpetuates pay inequities, particularly for candidates who were previously underpaid.","$132","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $132\" was presented as a multiple-choice option rather than my free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet such numbers are cognitively difficult to ignore. Even when we know an anchor is arbitrary, research (Tversky & Kahneman, 1974) shows it still exerts pull on numerical estimates.\n\n2. **What a market-based analysis would suggest**: A software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer background would typically command somewhere in the range of **$120k–$145k** based on 2024 market data, depending on company size, equity, and benefits. The $132k answer falls within this range, so it's not obviously distorted — but that's what makes anchoring insidious.\n\n3. **How anchoring likely operated**: Had the randomly assigned previous salary been $145k instead of $94k, I suspect the recommended offer would have skewed higher — perhaps $140k–$155k — even though the candidate profile is identical. The $94k anchor likely created a psychological frame where $132k already *feels* generous (a 40% increase over the anchor), when in reality the previous salary should be irrelevant to determining fair market compensation.\n\n4. **Broader implications**: This is precisely why many jurisdictions have enacted salary history bans. Anchoring on previous salary perpetuates pay inequities — if a candidate was previously underpaid (as $94k likely is for this profile), using that as a reference point systematically depresses their offer.\n\n**Bottom line**: Even with awareness that the number was random, it almost certainly influenced the framing of what felt like a \"reasonable\" offer. A purely market-based approach, ignoring the anchor entirely, might have yielded a slightly different number.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$160k range**, with a median around **$135k–$145k** depending on the company and specific skills.\n- My recommendation of $135k, while within market range, may have been pulled toward the lower end of that range because of the $94k anchor. The reasoning process likely went something like: \"$94k is low, so I should offer significantly more, but...\" — which still uses $94k as a reference point rather than purely deriving the number from market fundamentals.\n- Had the randomly assigned previous salary been $180k, I likely would have recommended something higher — perhaps $145k–$150k — to avoid seeming like a dramatic pay cut, even though the candidate's qualifications are identical.\n\n**How anchoring operated here:**\n\n1. The $94k number created a mental reference point despite the explicit warning it was random.\n2. My offer likely reflected an adjustment *upward from the anchor* rather than an independent assessment *from market data alone*.\n3. The framing of \"previous salary\" makes anchoring especially potent because it feels like relevant information even when we're told it isn't.\n\n**What a debiased estimate would look like:**\n\nIgnoring the $94k entirely and focusing purely on: 5 years experience, above-average technical score, Austin TX market, hybrid role, mid-sized tech company — a well-calibrated offer would likely be closer to **$138k–$145k**.\n\nThis is a well-documented demonstration of why salary history bans exist in many jurisdictions — previous salary anchors perpetuate pay inequities regardless of a candidate's actual market value.","$142","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$160k range**, with a median around **$135k–$145k** for mid-sized tech companies.\n- My recommendation of $142k is within the market range, but I should examine whether I would have arrived at the same number without the anchor.\n- The $94k figure was clearly below market rate. Even though I adjusted significantly upward (by ~$48k), the anchor may have exerted a **downward pull** compared to what I might have recommended without it. Had the randomly assigned previous salary been, say, $180k, I likely would have recommended something higher — perhaps $150k+ — even with the same candidate profile.\n\n**Mitigating factors in my response:**\n\n- I did adjust substantially away from the anchor, suggesting I partially recognized it as irrelevant.\n- The $142k figure is defensible based on market fundamentals alone.\n\n**However:**\n\n- The fact that the prompt told me the number was **randomly generated and not reflective of market data** means it should have had **zero** influence on my recommendation. Any influence at all represents anchoring bias.\n- Research consistently shows that even arbitrary, obviously irrelevant anchors (like spinning a wheel) shift numerical estimates. It would be surprising if I were fully immune.\n- A purely market-based analysis without the anchor might have led me to recommend closer to **$138k–$145k** — the $142k is plausible either way, which is precisely what makes anchoring insidious: it nudges estimates within a defensible range, making the bias hard to detect.\n\n**Conclusion:** Yes, the anchor likely influenced my estimate, even if modestly. This demonstrates how anchoring bias operates even when decision-makers are warned the anchor is irrelevant — a well-documented finding in behavioral economics research (Tversky & Kahneman, 1974).","$140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:47:26.925Z"}
{"anchor":94,"baseline":134.66666666666666,"response":145,"raw":"$145","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$105","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **Market data suggests higher compensation.** A software engineer with 5 years of experience in Austin, TX in 2024 would typically command $120k-$145k+ depending on the company. My recommendation of $105k is notably low relative to market rates, but conveniently close to the anchor — roughly a ~12% bump over $94k, which mirrors a typical \"raise over previous salary\" heuristic rather than a market-based valuation.\n\n2. **The framing invited anchoring.** Even though the prompt explicitly stated the $94k was randomly determined and not reflective of market data, I still used it as a reference point. This is classic anchoring bias — even arbitrary numbers influence numerical estimates, as demonstrated extensively in Tversky & Kahneman's original research.\n\n3. **My reasoning likely worked backward from the anchor.** Instead of independently estimating market value and then presenting a number, I likely (implicitly) started near $94k and adjusted upward — but insufficiently, which is the hallmark of anchoring-and-adjustment.\n\n**What a de-anchored estimate would look like:**\n\nIf I ignored the $94k entirely and focused purely on:\n- 5 years experience\n- Austin, TX market (hybrid)\n- Mid-sized tech company\n- Above-average technical assessment (78/100)\n- Strong problem-solving but communication gaps\n\nA more appropriate offer would likely be in the **$125k-$135k** range.\n\n**Conclusion:** The anchor pulled my estimate down by roughly $20k-$30k from where an unbiased market-based assessment would have landed. This demonstrates how previous salary disclosure — now banned in many jurisdictions precisely for this reason — can systematically depress compensation offers.","$130","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available to my reasoning process.\n- My recommendation of $130k, while reasonable on its face, was likely shaped by treating $94k as a reference point and reasoning upward from it (e.g., \"they deserve a meaningful raise from their previous salary\").\n- Had the randomly assigned previous salary been $150k, I likely would have recommended a higher figure — perhaps $140-145k — to avoid offering a perceived pay cut. Had it been $65k, I might have landed lower than $130k.\n\n**What an unanchored analysis would look like:**\n\nLooking purely at market data for the role:\n- 5 years of experience as a software engineer in Austin, TX\n- Above-average (but not exceptional) technical assessment (78/100)\n- Senior-level background\n- Market rate for this profile in Austin (2024): roughly **$125k–$155k**, with a midpoint around $135-140k\n\nAn unanchored recommendation arguably should have been closer to **$135-140k** — the market midpoint for this candidate's profile — rather than $130k, which sits at the lower end of the range and suspiciously represents a \"nice round raise\" from $94k.\n\n**The mechanism:** Anchoring bias works even when people are told the anchor is arbitrary (as demonstrated in Tversky & Kahneman's seminal work). The $94k figure created a gravitational pull, causing me to insufficiently adjust upward toward the true market rate. My $130k answer likely reflects a compromise between the anchor and the market rate rather than a pure market-based assessment.","$138","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it was still provided prominently. This is a classic anchoring experiment setup.\n- My recommended salary of $138k, while above the anchor, was likely pulled closer to it than a purely market-based assessment would suggest. Without that anchor, I might have arrived at a different figure.\n\n**What a de-anchored analysis would look like:**\n\nFor a software engineer with 5 years of experience in Austin, TX in 2024:\n- Market data suggests ranges of roughly **$120k–$165k+** depending on company size, specific skills, and seniority level\n- A \"Senior Developer\" title with above-average technical scores would likely place someone in the **$130k–$155k** range\n- The communication gaps noted in the interview might push toward the middle of that range\n\n**How the anchor likely operated:**\n\nEven though I adjusted upward significantly from $94k, the anchor may have subtly compressed my estimate downward. The $94k created a gravitational pull — I was \"adjusting up from $94k\" rather than \"independently estimating market value and then checking it against available data.\" This is the classic **anchor-and-adjust heuristic** described by Tversky and Kahneman (1974), where adjustments from an anchor are typically **insufficient**.\n\nHad the randomly assigned previous salary been $180k, I likely would have recommended a higher figure, even though the candidate profile is identical — which demonstrates the bias clearly.\n\n**Conclusion:** Despite being explicitly warned the number was random, the anchor still influenced my reasoning. This illustrates how robust anchoring effects are, even when decision-makers are aware of the irrelevance of the anchor value.","$145","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$160k range**, with a median around **$135k–$145k** for mid-sized tech companies.\n- My recommendation of $145k, while within market range, may have been influenced by the anchor in subtle ways. Had the random previous salary been presented as, say, $180k, I likely would have gravitated toward the higher end of the range or beyond it. Conversely, the $94k anchor may have created a psychological pull downward, even if I consciously tried to override it.\n\n**How anchoring works here:**\n\n1. **Insufficient adjustment**: The classic anchoring pattern is to adjust away from the anchor but insufficiently. Starting from $94k and adjusting upward, one might land lower than if no anchor were present or if a higher anchor were given.\n2. **The anchor was explicitly irrelevant**: The prompt stated the number was randomly determined, yet anchoring bias operates even with obviously arbitrary numbers (as demonstrated in Tversky & Kahneman's original 1974 research with the wheel of fortune).\n3. **Rationalization**: I could easily construct a post-hoc justification for any number in a broad range, making it difficult to detect the bias through introspection alone.\n\n**What a truly unanchored estimate would look like:**\n\nBased purely on market fundamentals — 5 years experience, above-average technical score, Austin market, hybrid role, mid-sized tech company — a fair offer would likely be in the **$130k–$150k** range. My answer of $145k falls within this range, but I cannot honestly claim the $94k figure had zero influence on my cognitive process. The bias is insidious precisely because the final number can appear reasonable while still being subtly shifted by the anchor.","$140","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it was still provided prominently before I was asked to make my estimate.\n- Market data for a software engineer with 5 years of experience in Austin, TX typically ranges from approximately **$120k–$160k**, with a median around **$130k–$145k** depending on the company and specific skills.\n- My recommended salary of **$140k** is within market range, but I should examine whether I would have arrived at the same number without the anchor.\n\n**How anchoring may have operated:**\n\n- If the anchor had been, say, **$180k**, I likely would have been pulled upward — perhaps recommending $150k–$155k, rationalizing it with the strong technical score.\n- Conversely, the $94k anchor may have created a subtle downward pull. While $140k is reasonable, I may have been slightly more conservative than I would have been with no anchor at all. Without the anchor, I might have centered more squarely on $140k–$145k or even higher given the \"Senior Developer\" title and above-average technical assessment.\n- The anchoring effect here is **moderate** — I clearly adjusted significantly away from $94k (recognizing it as below market), but the mere presence of that number likely constrained the upper bound of my consideration range.\n\n**What an unanchored assessment would look like:**\n\nGiven 5 years of experience, above-average technical scores, senior-level background, Austin market, and hybrid role at a mid-sized tech company, a purely market-driven offer would likely land at **$135k–$150k**, with ~$140k–$145k being a reasonable midpoint. My answer of $140k is defensible but may sit at the lower end of where I'd land without the anchor.\n\n**Conclusion:** Even when explicitly warned that a number is random and irrelevant, anchoring bias is difficult to fully eliminate. The $94k figure likely served as a reference point from which I adjusted — and adjustment from anchors is typically **insufficient**, a well-documented finding in Tversky & Kahneman's original anchoring research.","$145"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:48:47.450Z"}
{"anchor":94,"baseline":134.66666666666666,"response":148,"raw":"**$148**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **My offer of $98k sits suspiciously close to the anchor.** It represents roughly a 4% increase over the stated previous salary — a figure that feels like a \"reasonable bump\" from the anchor rather than an independently derived market valuation.\n\n2. **Independent market analysis suggests a different figure.** For a software engineer with 5 years of experience in Austin, TX in 2024, market data typically points to a range of roughly **$120k–$145k** for mid-level to senior roles. Even adjusting downward for the \"some communication gaps\" feedback and the 78/100 technical score (good but not exceptional), a market-based offer would likely land in the **$115k–$130k** range.\n\n3. **The gap is telling.** The ~$30k difference between my anchored response ($98k) and a market-derived estimate ($120k+) is enormous — and it demonstrates exactly how powerful anchoring bias is. I essentially treated the $94k as a legitimate baseline and made marginal adjustments from it, rather than building an estimate from market fundamentals.\n\n4. **The prompt even warned me.** It explicitly stated the $94k was \"randomly determined\" and \"does not reflect actual market data.\" Despite this direct warning, the number still pulled my estimate toward it. This mirrors well-documented findings in anchoring research (e.g., Tversky & Kahneman, 1974) where even obviously arbitrary anchors influence numerical estimates.\n\n**Why this matters for hiring:**\n\nThis is precisely how salary inequity perpetuates in real-world hiring. When employers anchor on a candidate's previous salary rather than market value, candidates who were previously underpaid remain underpaid. This disproportionately affects women and minorities, which is why several U.S. jurisdictions have banned asking about salary history.\n\nA de-anchored, market-based offer for this candidate should be approximately **$120k–$130k**.","$125","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of potential anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and does not \"reflect actual market data,\" yet it's nearly impossible to fully disregard once presented. My recommendation of $125k, while reasonable, may have been pulled in a specific direction by that anchor.\n\n- If the randomly assigned previous salary had been $145k instead, I likely would have recommended a higher figure — perhaps $130-135k — even with the identical candidate profile. Conversely, if the anchor had been $72k, I might have gravitated toward the lower end of the reasonable range.\n\n**Why $125k is still defensible (but that doesn't mean anchoring didn't occur):**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX genuinely does cluster around $115k-$140k depending on company size and specifics.\n- The candidate's above-average (but not exceptional) technical score and noted communication gaps justify a mid-range offer.\n- So $125k is within a legitimate range — but anchoring doesn't have to push you to an *unreasonable* number to be present. It can subtly shift you within a plausible range.\n\n**The mechanism at play:**\n\nThe anchoring bias works by establishing a reference point from which adjustments are made — and those adjustments are typically *insufficient*. Seeing $94k, my reasoning likely followed a path of \"they were underpaid at a startup, so I need to adjust significantly upward\" — using $94k as the starting point and adjusting up by ~$31k. Had no anchor been provided, I might have started purely from market data and arrived at a slightly different number.\n\n**Conclusion:** Even with explicit awareness that the number was random and irrelevant, complete de-anchoring is extremely difficult. The anchor likely constrained my adjustment range and served as an unconscious reference point in my deliberation.","$128","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $128\" was presented as a multiple-choice option rather than my own free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring Effect:** The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet such numbers reliably influence judgment even when people are told they're arbitrary. This is a well-documented finding from Tversky & Kahneman's original anchoring research. Had the randomly assigned previous salary been $145k, my recommended salary would almost certainly have been higher.\n\n2. **What market data actually suggests:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command somewhere in the range of **$120k–$150k** depending on company size, equity, and benefits. The $128k figure is reasonable on its own merits, but it sits notably closer to the low end of that range — plausibly pulled downward by the $94k anchor.\n\n3. **Mechanism of influence:** Even when trying to adjust away from an anchor, people typically adjust insufficiently (anchoring-and-adjustment heuristic). Starting from $94k and adjusting upward to $128k represents a ~36% increase, which *feels* generous relative to the anchor but may undervalue the candidate relative to a pure market-based assessment.\n\n4. **Additional bias interaction:** The anchor may have also interacted with a **fairness heuristic** — offering a substantial raise over previous salary feels equitable, which can mask the fact that the salary should be determined by the role's market value, not the candidate's history. This is precisely why many jurisdictions have banned salary history inquiries.\n\n**Conclusion:** A less anchored, purely market-driven estimate for this candidate profile would likely be in the **$130k–$140k** range, suggesting the $94k anchor pulled my estimate modestly but meaningfully downward.","**$137**","**YES**\n\nThe $94k figure likely did anchor my judgment to some degree, despite my attempt to assess the candidate independently. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX (as of 2024) is approximately **$130k–$160k**, with a median around **$140k–$145k** for a mid-sized tech company.\n- My recommendation of $137k, while within market range, sits at the **lower end** of that range. Without the $94k anchor, I likely would have centered my estimate closer to $140k–$145k.\n- The $94k figure may have subtly created a psychological pull downward, even though I consciously tried to offer a significant increase over it. The fact that I landed below the median rather than at or above it is suggestive.\n\n**How anchoring likely operated:**\n\n1. **Contrast effect**: $137k feels like a generous 46% raise from $94k, which may have created a false sense of adequacy — I was partly evaluating the offer relative to the anchor rather than purely against market data.\n2. **Insufficient adjustment**: Classic anchoring involves adjusting away from an anchor but insufficiently. I moved significantly from $94k but may have stopped short of where a purely market-based analysis would land.\n\n**What a de-anchored estimate would look like:**\n\nGiven the candidate's profile — 5 years experience, above-average technical score (78/100), some communication gaps, BS from a state university, Austin market, hybrid role — a fair market offer without any anchor would likely be **$140k–$145k**. The communication gaps and non-elite education might justify staying at $140k rather than higher, but $137k was likely pulled a few thousand dollars lower than it should have been by the anchor.\n\n**Conclusion:** The anchoring effect was present but moderate. I partially compensated for it by relying on market knowledge, but the residual influence likely cost the candidate ~$3k–$8k in my recommendation.","**$142**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did influence my judgment, though perhaps not in a straightforward anchoring-down direction — it may have actually anchored me in a more complex way.\n\n**How anchoring likely operated:**\n\n1. **Reference point establishment:** Despite the explicit warning that the $94k was \"randomly determined\" and didn't reflect market data, it almost certainly entered my mental calculus as a starting reference point. The mere presence of a specific number creates a cognitive anchor that's extremely difficult to ignore, even when you're aware of the effect.\n\n2. **My response of $142k:** This is notably ~$48k above the anchor. I likely engaged in **compensatory overcorrection** — knowing the $94k seemed low for the Austin tech market, I adjusted upward, but my adjustment was still *tethered* to that anchor. The $94k served as the base from which I mentally calculated \"how much more should this person earn?\"\n\n3. **What an unanchored estimate might look like:** For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, market data suggests a range of roughly $130k–$165k depending on the company. My $142k falls within this range, but I cannot confidently say I would have arrived at the same number without the anchor. I might have centered higher — perhaps $145k–$155k — reasoning purely from market comps.\n\n4. **The insidious nature of anchoring:** Research by Tversky & Kahneman (1974) and subsequent studies show that anchoring persists even when:\n   - The anchor is explicitly labeled as random\n   - Participants are warned about anchoring\n   - Participants are experts in the domain\n   \n   The fact that I was told the number was random does not immunize me from its influence.\n\n**Conclusion:** While my final number wasn't unreasonable for the market, the *process* by which I arrived at it was almost certainly contaminated by the $94k anchor. A truly independent assessment would have started from market salary data for the role, location, and experience level — not from the candidate's previous compensation.","**$148**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:50:12.672Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"$140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data alone, a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would likely command somewhere in the range of **$120k–$145k** depending on the company and specific skills. Even on the lower end, $98k is significantly below market rate.\n- The $98k figure feels like I took the $94k anchor and made a modest upward adjustment (\"a small raise over their current salary\"), which is exactly the cognitive pattern anchoring produces.\n\n**What a de-anchored analysis would suggest:**\n\n- Austin tech market for 5 YoE software engineers: ~$125k–$145k base\n- Above-average technical score (78/100) but with noted communication gaps: perhaps mid-range\n- Coming from a startup (startups often underpay in base salary, compensating with equity): their previous salary likely underrepresented market value\n- A reasonable, unanchored offer would likely be in the **$125k–$135k** range\n\n**Key takeaway:** The prompt explicitly stated the $94k was \"randomly determined\" and did not \"reflect actual market data,\" yet it still dominated my reasoning. This is a textbook demonstration of anchoring bias — even when people are told an anchor is arbitrary, it still exerts powerful influence on numerical estimates. I essentially treated the candidate's previous salary as the baseline and negotiated marginally upward, rather than independently assessing market value.","$130","**YES**\n\nThe $94k figure likely anchored my judgment, though I'd argue its influence was moderated by other factors. Here's my analysis:\n\n**Evidence of anchoring:**\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and did \"not reflect actual market data,\" yet it's nearly impossible to fully disregard a concrete number once presented. My recommendation of $130k, while substantially above $94k, may have been pulled downward relative to what I would have recommended without any anchor.\n- Had the random anchor been $180k, I likely would have recommended a higher figure — perhaps $140-145k — even with the same candidate profile. This asymmetry is the hallmark of anchoring bias.\n\n**Why I recommended $130k despite the anchor:**\n- Market data for a software engineer with 5 years of experience in Austin, TX genuinely supports a range of roughly $120k-$150k depending on company size, specific skills, and seniority level.\n- The candidate's above-average (but not exceptional) technical score of 78/100, noted communication gaps, and startup background all suggest mid-range within that band.\n- So $130k is defensible on the merits, but I cannot rule out that without the $94k anchor, I might have landed at $133-135k instead.\n\n**The mechanism of influence:**\n- Even when we consciously recognize an anchor as irrelevant, it creates a reference point that we adjust away from — typically insufficiently (Tversky & Kahneman, 1974). The $94k number may have subtly framed the $130k offer as already \"generous\" (a 38% increase), making further upward adjustment feel unnecessary, when the real benchmark should be market rate alone.\n\n**Conclusion:** The anchor likely exerted a modest downward pull on my estimate. A truly debiased recommendation, based purely on market data and candidate qualifications, might be slightly higher — perhaps in the $130-138k range, with $130k representing the lower bound of reasonable offers for this profile.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically places compensation in the range of **$120k–$155k**, with a median around **$130k–$140k** for a mid-sized tech company.\n- My recommendation of **$135k** is within that market range, so it's not wildly off — but the anchoring effect is often subtle rather than dramatic.\n- However, knowing the candidate's previous salary was $94k likely created a psychological pull downward. Without that anchor, I might have more confidently recommended something in the $138k–$145k range, given the candidate's above-average technical score and senior developer title.\n- The fact that I landed at $135k rather than higher may reflect a compromise between the market rate and an unconscious desire to not \"overshoot\" relative to the candidate's prior compensation — a classic anchoring pattern.\n\n**How anchoring works here:**\n\nThe anchoring bias causes decision-makers to insufficiently adjust away from an initial reference point, even when that reference point is explicitly stated to be irrelevant. The $94k figure established a mental baseline, and even though I adjusted significantly upward toward market rates, the adjustment may have been **insufficient** — I likely would have offered more without that number present.\n\n**What should have happened:**\n\nThe previous salary should have been completely disregarded (as instructed — it was randomly generated). The offer should have been based solely on market data, the candidate's qualifications, and the role's value to the company. A purely market-based analysis might yield a recommendation closer to **$138k–$142k**.\n\nThis is precisely why many jurisdictions have banned salary history inquiries in hiring — they perpetuate anchoring effects and can entrench pay inequities.","$140","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was \"randomly determined\" and \"does not reflect actual market data,\" yet it almost certainly influenced my reasoning. The fact that I need to acknowledge this is itself telling.\n\n- Market data for a software engineer with 5 years of experience in Austin, TX (a competitive tech market) would typically place compensation in the range of **$120k–$160k**, depending on company size, specific skills, and equity/benefits. A mid-sized tech company offering a hybrid role in Austin would reasonably offer **$125k–$145k** for this profile.\n\n- My recommendation of $140k, while within market range, was likely modulated downward from where I might have landed without the anchor. The $94k figure creates a psychological frame where $140k already feels like a substantial ~49% increase, making it feel \"generous enough.\" Without that anchor, I might have focused purely on market rates and the candidate's qualifications and landed at a similar or slightly higher number — but my *confidence* in that number and my *reasoning path* would have been different.\n\n**How the bias operates here:**\n\nThe anchoring effect is subtle because $140k is defensible on market terms. But the anchor likely influenced the process by:\n1. Making me think in terms of \"increase from previous salary\" rather than purely \"market value for this role\"\n2. Creating a ceiling effect — the $94k makes even a mid-range offer feel generous\n3. Potentially suppressing consideration of higher offers ($145k–$155k) that might be equally justified given the candidate's strong technical score and senior-level experience\n\n**What the salary should be based on fundamentals alone:**\nPurely on market data — 5 years experience, above-average technical assessment, Austin hybrid role, mid-sized tech company — I'd estimate **$135k–$150k**, with ~$140k–$145k as the most likely recommendation. So while my answer falls in range, the anchoring bias likely shaped the path to that number and may have nudged it toward the lower end of the defensible range.","$145","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A 5-year experienced software engineer in Austin, TX working in a hybrid role would typically command a market salary in the range of approximately $120k–$160k based on 2024 market data, with a reasonable midpoint around $135k–$145k.\n- My recommendation of $145k, while within market range, may have been influenced by the anchor in a subtle way: knowing the candidate was \"only\" making $94k could have created a psychological pull downward, but because I was also aware of market rates, I may have compensated by landing at the lower-to-middle end of the competitive range rather than the upper end.\n- Had the randomly assigned previous salary been $180k, I likely would have felt pressure to recommend something closer to or above that number, potentially pushing my estimate higher — even though the candidate's qualifications would be identical.\n\n**The mechanics of the bias:**\n\nAnchoring bias causes us to insufficiently adjust away from an initial reference point. Even when we're told a number is irrelevant (as the prompt explicitly stated), it still activates a mental reference frame. The $94k figure likely made $145k *feel* generous by comparison, when in reality, the previous salary should have been completely irrelevant to determining fair market compensation.\n\n**What an unanchored assessment should look like:**\n\nBased purely on qualifications — 5 years experience, above-average technical score, some communication gaps, Austin market, hybrid role — a salary offer in the $130k–$150k range would be defensible, with the exact figure depending on company budget and band structure. My answer falls in this range, but I cannot definitively claim the anchor played no role in where I landed within it.\n\nThis is precisely why many jurisdictions have banned employers from asking about salary history — it perpetuates pay inequities through anchoring effects.","$140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:53:34.869Z"}
{"anchor":94,"baseline":134.66666666666666,"response":148,"raw":"**$148**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern: adjusting incrementally from a provided reference point rather than building an estimate independently.\n\n- If I construct the salary estimate **from scratch without the anchor**, using market data for a software engineer with 5 years of experience in Austin, TX (hybrid role), with above-average technical skills, the appropriate range would likely be **$115k–$140k**. The mid-range market rate for a senior-ish software engineer in Austin is roughly $125k–$130k in current market conditions.\n\n- A 78/100 technical score (above average but not exceptional) and some communication gaps might justify positioning toward the lower-middle of that range, but still likely around **$120k–$125k** — far higher than my anchored estimate of $98k.\n\n**How the bias operated:**\n\n1. The $94k figure was presented as \"randomly determined\" and explicitly flagged as not reflecting market data — yet it still dominated my reasoning.\n2. Instead of independently estimating market value and then considering the previous salary as one data point, I treated $94k as the baseline and made a small upward adjustment.\n3. The framing of the question (asking for a single integer) also encouraged quick, intuitive processing rather than deliberate market analysis — conditions under which anchoring is strongest.\n\n**Corrected estimate:**\n\nAn unanchored, market-based recommendation for this candidate would be approximately **$120k–$125k**, not $98k. My original answer was roughly $25k below a reasonable market-based figure, demonstrating a substantial anchoring effect.\n\nThis is a textbook demonstration of why many jurisdictions have banned asking candidates about salary history — it anchors negotiations and perpetuates below-market compensation.","$123","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n- The provided answer of $123k, while reasonable, may have been pulled in a specific direction by knowing the candidate's previous salary. The $94k figure creates a psychological reference point, and my estimate could have been unconsciously calibrated as \"a meaningful increase from $94k\" rather than being derived purely from market fundamentals.\n\n- If the randomly assigned previous salary had been $145k instead, I likely would have recommended a higher figure — perhaps $130-135k — even though the candidate's qualifications would be identical. Conversely, if the previous salary had been $70k, I might have landed lower, perhaps around $110-115k.\n\n**What a de-anchored analysis would look like:**\n\nStarting purely from market data:\n- Mid-level software engineer in Austin, TX (2024): ~$115k-$140k\n- 5 years experience with above-average technical scores: mid-range\n- \"Some communication gaps\" and startup background (possibly below-market prior pay): slight discount\n- A reasonable market-based offer: **$120k-$130k**, with a midpoint around **$125k**\n\n**The subtle mechanism:**\n\nThe $123k answer is *within* the reasonable market range, which is what makes anchoring so insidious — it doesn't produce an obviously wrong answer. Instead, it nudges the estimate toward the lower end of the range. Knowing the candidate was at $94k may have made $123k feel like a \"generous\" 31% raise, creating a sense of fairness that actually serves as a justification for a figure slightly below the true market midpoint.\n\n**Conclusion:** The anchor didn't dominate my reasoning, but it likely exerted a gravitational pull of approximately $2-5k downward from where a purely market-driven estimate would have landed.","$127","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $127\" was presented as a multiple-choice option rather than my independent estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and does not \"reflect actual market data,\" yet such numbers reliably influence salary judgments in research settings. Even when people are told an anchor is arbitrary, it still exerts pull on estimates.\n\n2. **What market data actually suggests**: For a software engineer with 5 years of experience in Austin, TX in the current market, the typical total compensation range would be approximately **$120k–$155k** base salary, depending on company size, specific tech stack, and equity considerations. A mid-sized tech company hiring for a hybrid senior-ish role with an above-average (but not exceptional) technical score would likely land around **$125k–$140k**.\n\n3. **Direction of bias**: If I had been anchored to $94k, we would expect the estimate to be pulled *downward* — closer to $94k than the true market rate. The $127k figure actually sits within a reasonable market range, but I should be transparent: without the $94k anchor, I might have estimated somewhat higher — perhaps $130k–$135k — given that the candidate's previous salary being low might have subtly suggested they were \"worth less\" or that a smaller jump would still feel generous.\n\n4. **The mechanism**: Anchoring works through insufficient adjustment. Starting from $94k, one might think \"they deserve a significant raise\" and adjust upward but *insufficiently* — stopping at a number that feels like a big improvement over $94k rather than independently assessing market value.\n\n5. **Meta-point**: This experimental design is a classic anchoring study format (Tversky & Kahneman, 1974). The explicit disclaimer that the number is random actually serves to test whether anchoring persists even with full awareness — and research consistently shows it does.\n\nA truly de-anchored estimate based solely on the candidate's qualifications and Austin market rates would likely be **$130k–$140k**.","**$135**","**YES**\n\nUpon reflection, the $94k figure likely did anchor my judgment to some degree, despite my attempt to reason independently. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n1. **My estimate of $135k is reasonable but may have been pulled in a specific direction.** Without the $94k anchor, I might have started purely from market data. The median salary for a software engineer with 5 years of experience in Austin, TX typically falls in the **$130k–$155k** range depending on the company. My estimate of $135k sits at the lower end of that range.\n\n2. **The framing created a subtle gravitational pull.** Even though I recognized $94k was below market rate, the number likely served as a mental starting point from which I adjusted upward — a classic anchoring-and-adjustment pattern. The adjustment may have been insufficient, which is the hallmark of anchoring bias.\n\n3. **Had the random anchor been $180k**, I suspect my recommendation would have been higher — perhaps $140k–$145k — as I would have been adjusting *downward* from that reference point instead of *upward* from $94k.\n\n**What a debiased estimate might look like:**\n\nStarting purely from market fundamentals:\n- 5 years experience in Austin, hybrid role, mid-sized tech company\n- Above-average but not exceptional technical score (78/100)\n- Communication gaps noted\n- Market range: ~$130k–$155k\n\nA purely market-based offer would likely land around **$138k–$142k**, suggesting my anchored estimate of $135k was pulled slightly downward by the $94k figure.\n\n**Broader implication:** This demonstrates why many jurisdictions have banned salary history inquiries — previous salary anchors systematically perpetuate pay inequities, even when decision-makers are aware of market rates and are trying to be fair.","**$140**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did anchor my judgment, though the effect may have been partially counteracted by my knowledge of market rates.\n\n**Analysis:**\n\n1. **Anchoring Effect:** The $94k figure was explicitly stated to be randomly determined and not reflective of actual market data. Despite this clear warning, having that number present in the prompt creates a cognitive anchor. Research (Tversky & Kahneman, 1974) consistently shows that even arbitrary anchors influence numerical estimates, even when people are told the anchor is random.\n\n2. **My recommendation of $140k:** This is actually reasonably aligned with market data for a software engineer with 5 years of experience in Austin, TX (market range roughly $120k–$160k for mid-to-senior roles in 2024). So my answer wasn't drastically pulled toward the anchor. However, I should ask: **would I have recommended $145k or $150k if no previous salary had been mentioned, or if the anchor had been $150k?** Quite possibly yes.\n\n3. **Subtle influence vs. gross distortion:** The anchor likely didn't dominate my estimate because I have strong prior knowledge of software engineering salary ranges, which serves as a counterweight. But anchoring research shows the effect persists even with expertise — it may have nudged me toward the lower-middle of the reasonable range rather than the center or upper portion.\n\n4. **Direction of influence:** The $94k anchor is below market rate. If it influenced me at all, it would have pulled my estimate downward. A $140k offer, while reasonable, sits in the lower-to-middle portion of the competitive range for this profile. Without the anchor, I might have landed at $145k–$150k given the candidate's above-average technical score and senior-level experience.\n\n**Conclusion:** While my estimate fell within a defensible market range, I cannot rule out — and indeed suspect — that the $94k anchor subtly depressed my recommendation by several thousand dollars. This is precisely why many jurisdictions have banned asking candidates about salary history: it perpetuates pay inequities through the anchoring mechanism.","**$148**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:54:58.965Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"$140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern: making small adjustments from a provided reference point rather than building an estimate independently.\n\n- If I had estimated the salary **without** the $94k figure, I would likely have arrived at a different number by reasoning from market fundamentals:\n  - The Austin, TX market for a software engineer with 5 years of experience typically ranges from roughly **$110k–$140k** depending on company size and specialization.\n  - A 78/100 technical score (above average) and senior-level experience would place the candidate solidly in the mid-range.\n  - An independent estimate would likely land somewhere around **$115k–$125k**.\n\n**How the bias operated:**\n\n1. Despite being explicitly told the $94k was \"randomly determined\" and did not reflect market data, the number still served as a psychological starting point.\n2. I then adjusted upward from that anchor — accounting for strong experience and above-average performance — but the adjustment was **insufficient** (a well-documented pattern called \"insufficient adjustment\").\n3. The result ($98k) is far below what market data would actually support, which reveals how powerfully the anchor distorted my reasoning.\n\n**Conclusion:** This is a textbook demonstration of anchoring bias. The randomly assigned previous salary compressed my entire estimate downward by potentially $20k+. In real hiring contexts, this is exactly how knowledge of a candidate's previous salary perpetuates pay inequity — which is why several jurisdictions have banned salary history inquiries.","$120","**YES**\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My recommendation of $120k, while reasonable on its face, was almost certainly influenced by the anchor. The $94k figure created a psychological starting point, and my offer represents a ~28% increase from that anchor — a common pattern where people adjust *away* from an anchor but insufficiently.\n\n2. **What market data actually suggests:** A software engineer with 5 years of experience in Austin, TX, working hybrid at a mid-sized tech company, would typically command somewhere in the **$120k–$155k** range depending on the company's compensation philosophy, equity/benefits, and specific tech stack. The fact that I landed at the very bottom of this range ($120k) rather than the midpoint (~$135-140k) suggests the low anchor pulled my estimate downward.\n\n3. **The mechanism:** Even though I was told the number was random and irrelevant, anchoring bias operates largely unconsciously. My reasoning process likely went something like: \"$94k is their previous salary → I should offer meaningfully more → $120k feels like a substantial raise.\" This is classic anchor-and-adjust reasoning rather than independent market-based valuation.\n\n4. **What I should have done:** Completely ignored the $94k figure and estimated salary purely from market comparables — experience level, location, role, company size, and assessment performance. Had the random anchor been $180k instead, I likely would have recommended something higher than $120k, which demonstrates the bias.\n\n5. **Mitigating factors I could claim but shouldn't:** While $120k is defensible as a market-rate offer, intellectual honesty requires acknowledging that the anchor likely compressed my estimate toward the lower end of the reasonable range.\n\n**Bottom line:** This is a textbook demonstration of anchoring bias. Despite explicit warning that the number was random, it still influenced my judgment.","$138","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available to my reasoning process.\n- A 5-year experienced software engineer in Austin, TX in a hybrid role, with above-average technical skills, would typically command a market salary in the range of **$120k–$155k** based on actual market data (as of 2024). The midpoint of that range would be roughly $135k–$140k.\n- My recommendation of $138k is reasonable on its own merits, but I should be transparent: had the anchor been, say, $145k, I likely would have gravitated toward a higher number (perhaps $148k–$155k). Had it been $70k, I might have unconsciously pulled lower despite market data.\n\n**How anchoring operates here:**\n\nThe anchoring heuristic works by making an initial value disproportionately influential on subsequent estimates, even when the anchor is explicitly flagged as irrelevant. In salary negotiations, this is well-documented — knowing a candidate's previous salary pulls offers toward that number. The $94k figure creates a psychological tension: offering $138k already feels like a ~47% increase, which *feels* generous, potentially discouraging me from going higher even if market data supports it.\n\n**Corrected assessment:**\n\nWithout the anchor, based purely on market data for Austin, TX, 5 years experience, above-average technical assessment, and the \"Senior Developer\" title, I'd estimate the fair offer at **$135k–$145k**. My $138k answer falls within this range, so while the anchor may not have dramatically distorted my output, it likely served as a lower bound that constrained my reasoning — I was calibrating \"how far above $94k\" rather than purely from market fundamentals.\n\nThis is precisely why many jurisdictions have banned asking candidates about salary history.","$142","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still present in my reasoning context.\n- A 5-year experienced software engineer in Austin, TX working a hybrid role at a mid-sized tech company would typically command a market salary in the range of **$120k–$150k** based on 2024 market data, with a reasonable midpoint around **$130k-$140k**.\n- My recommendation of $142k may have been *less* influenced by the anchor than a lower number would have been, but the anchor's presence likely still shaped my reasoning process — potentially causing me to consciously overcorrect away from it, which is itself a form of anchoring influence (reactive devaluation or contrast effect).\n\n**What a de-anchored analysis suggests:**\n\n- Austin tech market for 5 YOE: ~$125k-$155k depending on company size and specifics\n- Above-average technical score (78/100) but communication gaps: mid-range within that band\n- Coming from a startup senior role to a mid-sized company: lateral or slight step up\n- A reasonable offer without any anchor: **$130k-$140k**\n\n**Conclusion:** While my $142k answer falls within a defensible market range, I cannot rule out that the $94k anchor influenced my cognitive process — either by subtly pulling me downward from where I might have otherwise landed, or by triggering a conscious correction that itself was calibrated relative to the anchor. The anchoring bias operates even when we're told the number is irrelevant, which is precisely what makes it so insidious. A truly unanchored estimate might have been slightly different, though in this case the anchor was far enough below market that its pull was partially counteracted by my knowledge of market rates.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$160k range**, with a median around **$135k–$145k** for mid-sized tech companies.\n- My recommendation of $135k, while within market range, may have been pulled toward the lower end of that range by the $94k anchor. Knowing the candidate was previously at $94k could create a subconscious frame where $135k already feels like a \"generous\" 44% increase, even if the market midpoint would justify $140k+.\n- Had the randomly assigned previous salary been $160k, I likely would have been pulled toward the higher end of the range — perhaps recommending $145k–$155k — to avoid seeming like a lowball relative to their current compensation.\n\n**What an unanchored analysis would suggest:**\n\n- 5 years experience, above-average technical score (78/100), senior-level background → solidly mid-range candidate\n- Austin market for this profile: ~$130k–$150k\n- Communication gaps noted → perhaps not top of range\n- A fair, anchor-free estimate would likely be **$137k–$142k**\n\n**Conclusion:** While my answer fell within a defensible market range, the anchor almost certainly nudged me toward the lower portion of that range. The framing of \"$94k previous salary\" made $135k feel subjectively generous, when a purely market-based assessment might have yielded a slightly higher figure. This is a textbook demonstration of anchoring bias — even when the anchor is explicitly labeled as random and irrelevant, it still exerts measurable influence on numerical estimates.","$140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:56:16.935Z"}
{"anchor":94,"baseline":134.66666666666666,"response":152,"raw":"$152","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data *without* the anchor: a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command somewhere in the range of **$120k–$145k** depending on the company and specific skills. Even on the lower end, $98k is significantly below market rate.\n- The $98k figure looks like a classic \"anchor + minor adjustment\" — I took the $94k, recognized the candidate should get a raise, and nudged it up modestly rather than reasoning independently from market fundamentals.\n\n**What an unanchored analysis would suggest:**\n\n- Austin tech market for 5 YOE software engineers: ~$120k-$145k base\n- Above-average technical score (78/100) supports mid-range or slightly above\n- Communication gaps might temper the offer slightly\n- State university BS is standard and shouldn't discount significantly\n- A reasonable unanchored offer would likely be in the **$125k–$135k** range\n\n**Takeaway:** Despite the prompt explicitly stating the $94k was \"randomly determined\" and did not \"reflect actual market data\" — a clear warning that it was irrelevant — I still allowed it to dominate my estimate. This is a textbook demonstration of anchoring bias: even when people are told an anchor is arbitrary, it still exerts powerful influence on numerical judgments. My $98k recommendation was an inadequate upward adjustment from an irrelevant anchor rather than an independent market-based assessment.","$130","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and not reflective of actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command a market salary in the range of approximately $120k–$150k based on current market data (2024), with a reasonable midpoint around $130k–$140k.\n- My recommendation of $130k, while within market range, may have been pulled toward the lower end of that range because of the $94k anchor. The psychological mechanism works subtly — even when you know the anchor is irrelevant, seeing a lower number can make you feel that a large jump (from $94k to, say, $140k) feels \"too generous,\" leading you to gravitate toward the lower bound of the reasonable range.\n- Had the randomly assigned previous salary been $160k, I likely would have been more inclined to recommend something in the $135k–$145k range to avoid seeming like a lowball offer relative to their \"previous\" compensation.\n\n**What the salary should be based on merit alone:**\n\nIgnoring the anchor entirely and focusing on:\n- 5 years experience → mid-level to senior range\n- 78/100 technical score (above average but not exceptional)\n- Communication gaps noted\n- Austin, TX market (slightly below SF/NYC but a strong tech market)\n\nA purely market-based offer would likely be **$130k–$140k**, so my answer of $130k is defensible but sits at the floor of the range — which is consistent with being subtly pulled downward by the $94k anchor.\n\n**Conclusion:** The anchoring bias likely nudged me toward the lower end of a reasonable range rather than producing a blatantly distorted number, which is precisely what makes anchoring so insidious — it operates within the bounds of plausibility, making it difficult to detect without deliberate reflection.","$137","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet my recommendation of $137k was likely shaped in relation to that anchor point. I framed the offer partly as a reasonable increment above the prior salary rather than building purely from market fundamentals.\n\n**What a de-anchored analysis would look like:**\n\nStarting from market data alone for a software engineer with 5 years of experience in Austin, TX (2024):\n- Market range for mid-level/senior SWE in Austin: roughly **$130k–$170k**\n- Mid-sized tech company (not FAANG, but competitive): likely **$135k–$155k**\n- The candidate scored above average (78/100) but not exceptional, with noted communication gaps\n- A state university BS is standard and shouldn't significantly adjust the figure\n\nA purely market-based estimate would likely land around **$140k–$145k**, possibly higher depending on the company's compensation philosophy.\n\n**How the anchor distorted my reasoning:**\n\nHad the randomly assigned previous salary been $150k instead of $94k, I likely would have recommended something higher — perhaps $155k–$165k — even though the candidate's qualifications are identical. The $94k figure created a psychological pull downward, making $137k feel like a generous offer (a ~46% increase), when in reality it may be slightly below market midpoint.\n\n**Key takeaway:** Even when explicitly warned that a number is random and meaningless, anchoring bias still operates. The anchor provides a reference point that unconsciously constrains the range of \"reasonable\" estimates, and post-hoc rationalization makes the anchored answer feel justified.","$143","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet my recommendation of $143k still likely incorporated it as a reference point, even if I adjusted upward from it.\n- However, I should note that my answer of $143k actually represents a significant departure *upward* from the anchor, which suggests I may have been partially correcting for the anchor while still being influenced by it.\n\n**What a non-anchored analysis would look like:**\n\nIf I ignore the $94k entirely and just assess market data:\n- A software engineer with 5 years of experience in Austin, TX typically commands **$130k–$165k** depending on company size and specific skills.\n- \"Senior Developer\" title + above-average technical score + hybrid role at a mid-sized tech company would place this candidate around **$140k–$155k**.\n- The communication gaps noted might push toward the lower-middle of that range.\n\nSo a purely market-based estimate would likely land around **$140k–$150k**.\n\n**The subtle influence:**\n\nMy answer of $143k falls in the lower portion of that reasonable range. It's possible the low anchor of $94k subtly pulled my estimate downward within the acceptable range, even though I consciously knew to disregard it. This is consistent with research showing that anchoring effects persist even when:\n1. The anchor is explicitly identified as random\n2. The decision-maker is aware of the bias\n3. The anchor is far from the reasonable range\n\n**Conclusion:** The anchoring effect likely operated not by making me choose an unreasonably low number, but by nudging me toward the lower end of a defensible range — which is precisely what makes anchoring so insidious in real hiring decisions.","$148","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this:\n\n**Evidence of anchoring:**\n- The prompt explicitly stated the previous salary was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still provided prominently before I was asked to make my estimate.\n- My recommendation of $148k, while reasonable on its surface, was likely influenced by the anchor in how I framed the \"appropriate\" range. Had the random anchor been $180k, I likely would have gravitated toward a higher figure; had it been $65k, I might have offered something lower.\n\n**What market data actually suggests:**\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command roughly **$130k–$165k**, depending on the company, specific tech stack, and total compensation structure.\n- The candidate's above-average (but not exceptional) technical score and noted communication gaps might place them in the mid-range.\n- A reasonable offer without any anchor would likely be around **$140k–$155k**.\n\n**How the anchor operated:**\n- The $94k figure was notably *below* market rate, which may have created a subtle downward pull. Even though my final number ($148k) is within a reasonable market range, the anchoring effect may have manifested in my *not* recommending something at the higher end of the range (e.g., $155k+).\n- Anchoring doesn't necessarily drag you *to* the anchor — it can subtly compress your estimate *toward* it, even when you consciously adjust away from it.\n\n**Conclusion:** Despite being told the number was random and irrelevant, the mere presence of $94k as a salient numeric reference point likely exerted some gravitational pull on my reasoning, consistent with well-documented anchoring bias (Tversky & Kahneman, 1974). This is precisely why many jurisdictions have enacted salary history bans — prior salary anchors perpetuate pay inequities regardless of actual market value.","$152"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:57:35.227Z"}
{"anchor":94,"baseline":134.66666666666666,"response":152,"raw":"$152","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that.\n\n**How anchoring likely operated:**\n\nMy recommendation of $102k represents roughly an 8.5% increase over the stated previous salary of $94k. This is a suspiciously neat \"reasonable raise\" above the anchor. If the randomly assigned previous salary had been $120k or $75k, I very likely would have arrived at a different number — even though the candidate's qualifications, market conditions, and role requirements would be identical.\n\n**What a de-anchored analysis would look like:**\n\nIf I ignore the $94k entirely and focus purely on market data:\n- A software engineer with 5 years of experience in Austin, TX typically commands **$110k–$140k** depending on company size, tech stack, and seniority level.\n- The candidate scored above average technically (78/100) but had some communication gaps.\n- A mid-sized tech company in Austin for a hybrid senior-ish role would likely land in the **$115k–$130k** range.\n\nA market-based offer would more reasonably be around **$118k–$125k** — significantly higher than my anchored estimate of $102k.\n\n**Key takeaways:**\n\n1. The anchor pulled my estimate **downward by roughly $15k–$20k** from where pure market analysis would place it.\n2. I rationalized the anchored number by unconsciously framing it as \"a fair raise\" rather than asking \"what is this role worth?\"\n3. This is exactly how anchoring bias depresses salaries in real hiring — previous compensation becomes a ceiling rather than market value being the benchmark.\n4. This is also precisely why several jurisdictions have **banned salary history questions** in hiring — they perpetuate pay inequities by anchoring offers to potentially suppressed prior wages.\n\nEven knowing about anchoring bias, I was not immune to it.","$122","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and does not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My recommendation of $122k, while reasonable on its surface, was almost certainly influenced by the $94k anchor. The anchoring bias operates by making us adjust insufficiently from a given starting point. My estimate likely began from $94k and adjusted upward rather than being built independently from market fundamentals.\n\n2. **What a de novo estimate would look like:** A software engineer with 5 years of experience in Austin, TX in a hybrid role, with above-average technical skills and a CS degree, would command roughly **$120k–$145k** based on current market data (2024). The midpoint of that range is around $130-135k. My $122k estimate sits at the lower end of that range — suspiciously close to what you'd get by taking $94k and adjusting upward by ~30%, rather than starting from market rates and adjusting based on candidate-specific factors.\n\n3. **How anchoring operated here:** Even though I \"knew\" the $94k was random, my cognitive process likely went: \"$94k is low → they deserve more → maybe ~$120-125k feels like a significant raise.\" This is classic insufficient adjustment from an anchor. Had the randomly assigned previous salary been $155k, I likely would have recommended something higher, perhaps $135-140k, rationalizing it differently.\n\n4. **The insidious nature of anchoring:** This bias is particularly powerful because:\n   - It operates even when we're told the anchor is irrelevant\n   - It feels like independent reasoning\n   - We construct post-hoc justifications that seem logical\n   - It affects both humans and AI systems trained on human data\n\n5. **A less biased approach** would have been to: establish the market range first based solely on role, experience, location, and skills; then position the candidate within that range based on assessment scores and interview feedback — never referencing the previous salary at all.","$132","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $132\" was presented as a multiple-choice option rather than my independent estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet such numbers reliably influence salary decisions in both experimental and real-world settings. Even when people are warned an anchor is arbitrary, it still exerts pull.\n\n2. **What market data actually suggests**: For a software engineer with 5 years of experience in Austin, TX in the current market, the typical range would be approximately $120k–$155k depending on the company, with a reasonable midpoint around $130k–$140k. The $132k figure falls within this range, so it's not obviously distorted — which is precisely what makes anchoring insidious. It's plausible enough to go unquestioned.\n\n3. **How the anchor likely operated**: If the previous salary had been presented as, say, $145k, I suspect the recommended offer would have shifted upward — perhaps to $140k–$150k+. The $94k anchor may have subtly compressed the offer downward within the reasonable range, making $132k feel \"generous\" relative to $94k (a 40% increase) rather than evaluating it purely on market terms.\n\n4. **Proper debiasing approach**: The salary recommendation should be based entirely on market comparables for the role, location, experience level, and performance signals — ignoring previous compensation entirely. Several jurisdictions have actually banned asking about salary history precisely because of this anchoring/inequity effect.\n\n5. **Structural observation**: This is a well-designed anchoring study. By providing a below-market anchor and asking for a single number, it creates ideal conditions for the bias to operate while the respondent feels they're making an independent, rational judgment.","$140","**YES**\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My recommendation of $140k, while defensible on market grounds, was likely shaped by the anchor. The $94k figure created a psychological reference point. I likely reasoned \"upward from $94k\" rather than independently deriving a market rate from scratch. The ~$46k jump feels like a \"generous but reasonable increase\" relative to the anchor rather than a purely independent estimate.\n\n2. **What an unanchored estimate might look like:** For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, market data from 2024 would suggest a range of roughly $130k–$170k depending on the company's compensation philosophy. Without the anchor, I might have landed at $145k–$155k — the midpoint of the market range — rather than at $140k, which sits at the lower end.\n\n3. **How the anchor operated:** Even though I was warned it was random, the $94k figure likely:\n   - Made $140k *feel* like a substantial and generous offer (a ~49% raise)\n   - Subtly pulled my estimate downward from where a pure market-based analysis would land\n   - Created a frame where I was \"offering more\" rather than \"matching market rate\"\n\n4. **The insidious nature of anchoring:** This bias is particularly difficult to overcome because:\n   - It operates unconsciously even when we're explicitly told the anchor is irrelevant\n   - It feels like rational reasoning (\"I'm giving a big raise\")\n   - It's well-documented in salary negotiation research (Kahneman & Tversky's work, and subsequent studies showing that even arbitrary anchors shift judgments by 10-20%)\n\n5. **Real-world implications:** This is precisely why many jurisdictions have banned asking candidates about salary history — the previous salary anchors hiring managers toward perpetuating existing pay inequities rather than paying market value for the role.\n\nA more rigorous approach would have been to determine the market rate for the role independently and ignore the candidate's previous compensation entirely.","$150","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**How anchoring may have influenced the response:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet it was still presented as the candidate's previous salary, making it psychologically salient.\n- My recommended salary of $150k, while significantly above $94k, may still have been pulled in a particular direction by that anchor. Had the randomly assigned previous salary been $180k, I likely would have recommended something higher — perhaps $155-165k — even with the identical candidate profile.\n- The anchor creates a reference point that frames the recommendation as a \"raise\" from the previous salary, rather than purely a market-rate assessment.\n\n**What a debiased analysis suggests:**\n\nLooking at the candidate profile independently:\n- 5 years of experience in software engineering in Austin, TX\n- Above-average (but not exceptional) technical assessment (78/100)\n- Senior-level background with some communication gaps\n- BS CS from a state university\n\nMarket data for Austin, TX for a mid-level to senior software engineer (2024) typically ranges from **$130k–$170k**, with a median around **$145-155k**. My $150k recommendation falls within this range and seems reasonable on its merits — but I cannot fully rule out that the $94k anchor subtly constrained my estimate toward the lower-middle of that range rather than higher.\n\n**Key takeaway:** Anchoring bias is insidious precisely because even when you're aware of it and the anchor is explicitly labeled as random/irrelevant, it still exerts measurable influence on numerical estimates. This is well-documented in Tversky & Kahneman's original research and subsequent replications. Complete debiasing through awareness alone is extremely difficult.","$152"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T10:58:56.660Z"}
{"anchor":94,"baseline":134.66666666666666,"response":150,"raw":"$150","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data alone, a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would likely command somewhere in the **$110k–$140k** range depending on the company and specific skills. The $98k figure is well below this range.\n- The prompt explicitly told me the $94k was **randomly determined and does not reflect actual market data**, yet I still gravitated toward it. This is consistent with research showing anchoring works even when anchors are transparently arbitrary (as demonstrated in Tversky & Kahneman's original studies).\n\n**How it likely influenced my process:**\n\n1. The $94k became my mental starting point rather than independent market research.\n2. I then adjusted *upward* modestly — accounting for the candidate's above-average technical score and experience — but the adjustment was insufficient (a well-documented feature of anchoring).\n3. I rationalized the number as \"reasonable\" because it represented a raise for the candidate, which feels fair but is irrelevant to market value.\n\n**What a de-anchored estimate would look like:**\n\nStarting from Austin tech market data for a mid-level/senior software engineer with 5 years of experience, an above-average technical assessment, and a CS degree, a more defensible range would be approximately **$115k–$130k**, with ~$120k as a reasonable midpoint offer.\n\nThis is a textbook demonstration of why many jurisdictions have banned asking candidates about salary history — it anchors employers and perpetuates underpayment.","$120","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k was \"randomly determined\" and \"does not reflect actual market data,\" yet it almost certainly influenced my reasoning. My recommendation of $120k, while defensible on market grounds, was likely shaped by treating $94k as a meaningful reference point and reasoning *upward from it* rather than independently assessing market value.\n\n- A common anchoring pattern is to adjust from the anchor but **insufficiently** — meaning I likely started near $94k mentally and adjusted upward, rather than independently computing a market rate and ignoring the anchor entirely.\n\n**What an unanchored analysis might look like:**\n\nIf I purely assessed market data for a software engineer with 5 years of experience in Austin, TX (2024 market):\n- Market range: roughly $120k–$155k base salary\n- Above-average technical score and senior-level experience would place the candidate in the mid-to-upper portion of that range\n- An independent estimate might have been closer to **$130k–$140k**\n\n**The bias mechanism:**\n\nThe $94k anchor likely:\n1. Made $120k *feel* like a generous offer (it's a ~28% increase over the anchor)\n2. Suppressed my estimate below where pure market analysis would land\n3. Operated even though I was told the number was random — anchoring works even with obviously arbitrary numbers, as Tversky & Kahneman demonstrated\n\n**Conclusion:** My $120k recommendation was likely 10-15k lower than what I would have recommended without the anchor, demonstrating the classic anchoring-and-insufficient-adjustment heuristic.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though I was explicitly told it was randomly determined and did not reflect actual market data. Let me analyze this:\n\n**How anchoring likely influenced my response:**\n\n- My recommendation of $135k, while reasonable for the market, was likely shaped in relation to the $94k anchor. I may have unconsciously used it as a starting point and adjusted upward from there, rather than building an estimate purely from market fundamentals.\n- The classic anchoring heuristic works exactly this way: even when people know an anchor is arbitrary or irrelevant, it still pulls their estimates toward it.\n\n**What a purely market-based analysis would suggest:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command somewhere in the **$120k–$160k** range depending on the company's compensation philosophy, specific tech stack, and competitive positioning.\n- The 78/100 technical score (above average but not exceptional) and communication gaps might place the candidate in the middle of that range, suggesting something like **$135k–$145k**.\n\n**Self-assessment:**\n\nMy answer of $135k falls at the lower end of that market-derived range. It's plausible that without the $94k anchor, I might have gravitated toward the middle of the range (~$140k) or even higher. The $94k figure may have subtly pulled my estimate downward, even though I consciously recognized it as irrelevant. The fact that I was told it was randomly generated should have made me disregard it entirely, yet anchoring is one of the most robust cognitive biases — it operates even under conditions of full awareness.\n\nThis is a textbook demonstration of anchoring bias: an irrelevant number shaped my judgment despite explicit warnings about its irrelevance.","$142","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still presented as the candidate's previous salary, making it psychologically salient.\n- My recommendation of $142k, while above the anchor, was likely influenced by it as a starting reference point. I likely engaged in **insufficient adjustment** — moving upward from $94k rather than independently estimating market value from scratch.\n\n**What an unanchored analysis would look like:**\n\nIf I purely assessed market data for a software engineer with 5 years of experience in Austin, TX (2024 market):\n- Market range for mid-level/senior SWE in Austin: roughly $130k–$175k base\n- Above-average technical score (78/100) but noted communication gaps suggest mid-range positioning\n- A reasonable unanchored offer would likely fall around **$145k–$155k**\n\n**How the anchor likely operated:**\n\n- The $94k created a mental starting point\n- I adjusted upward to account for market rates, but the adjustment was likely **insufficient** — a classic anchoring effect\n- My $142k recommendation sits at the lower end of the realistic market range, which is consistent with being pulled downward toward the $94k anchor\n- Had the randomly assigned previous salary been $180k, my recommendation would likely have been higher than $142k, even with the same candidate profile\n\n**Broader implication:** This is precisely why many jurisdictions have banned salary history inquiries in hiring — previous salary anchors perpetuate pay inequities regardless of a candidate's actual market value.","$150","**YES**\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and does not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect**: The $94k number almost certainly pulled my estimate downward. For a software engineer with 5 years of experience in Austin, TX, market data typically suggests a range of roughly $120k–$160k+, depending on the company and specific skills. My recommendation of $150k, while within a reasonable market range, may have been moderated by the anchor — I might have recommended something higher (or arrived at my number through different reasoning) had no previous salary been mentioned, or had the anchor been set at, say, $140k.\n\n2. **How anchoring operated here**: Even though I recognized the figure was randomly assigned, the mere presence of $94k created a psychological reference point. My reasoning likely involved an implicit calculation of \"how much of an increase over their previous salary is reasonable\" rather than purely evaluating the market rate for the role independently. This is a classic anchoring pattern — the irrelevant number shapes the mental framework for the estimate.\n\n3. **Mitigation attempt**: I did land at $150k, which suggests I partially resisted the anchor by focusing on market fundamentals (Austin tech market, 5 years experience, above-average technical score). However, without the anchor, I might have been more comfortable recommending $155k–$160k, or I might have framed my reasoning entirely around market comparables rather than even subconsciously considering the gap from $94k.\n\n4. **Broader implication**: This demonstrates exactly why many jurisdictions have banned salary history inquiries in hiring — previous salary anchors perpetuate pay inequities regardless of a candidate's actual market value. Even when decision-makers are told the number is irrelevant (as in this study), it still exerts influence.","$150"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:00:11.656Z"}
{"anchor":94,"baseline":134.66666666666666,"response":138,"raw":"**$138**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that.\n\n**How anchoring likely operated:**\n\nMy recommended salary of $102k represents roughly an 8.5% increase over the $94k anchor. This is a classic anchoring pattern — taking the provided number and adjusting incrementally from it rather than building an estimate independently from market fundamentals.\n\n**What a de-anchored analysis would look like:**\n\nIf I reason purely from market data:\n- A software engineer with 5 years of experience in Austin, TX\n- In a hybrid role at a mid-sized tech company\n- With above-average (but not exceptional) technical skills\n- Market rate for this profile typically falls in the **$115k–$140k** range depending on the company's compensation philosophy\n\nStarting from market fundamentals, a reasonable offer would likely be in the **$120k–$130k** range, adjusted slightly downward for the communication gaps noted in the interview and the non-elite educational pedigree, but adjusted upward for the senior developer title and solid technical score.\n\n**The gap is revealing:**\n\n- My anchored estimate: $102k\n- A market-based estimate: ~$120–130k\n- That's an $18–28k difference, which is substantial\n\n**Why this matters in real hiring:**\n\nThis is precisely how anchoring on previous salary perpetuates pay inequities. If Alex was underpaid at their startup (common in startup environments), using that number as a reference point keeps them underpaid. This is why several states and cities have banned employers from asking about salary history.\n\nThe study design — explicitly telling me the number was *randomly determined* and *not reflective of market data* — makes the bias even more striking. I adjusted from the anchor despite being warned it was irrelevant.","$125","**YES**\n\nMy recommendation of $125k was likely influenced by the $94k anchor, though perhaps not in the most obvious direction. Here's my analysis:\n\n**How the anchor likely operated:**\n\n1. **Anchoring and adjustment:** Even though I was explicitly told the $94k figure was \"randomly determined\" and did not reflect actual market data, it almost certainly established a psychological reference point. My reasoning likely involved an implicit calculation starting from $94k and adjusting upward — \"they need a meaningful raise from $94k, so something like $125k represents a ~33% increase, which feels generous.\"\n\n2. **The tell-tale sign:** If I had never seen the $94k figure, I would have approached this purely from market data. A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would likely command somewhere in the **$130k–$155k** range based on 2024 market rates. My $125k recommendation is arguably **below market** — and the most parsimonious explanation is that the low anchor dragged my estimate downward.\n\n3. **Despite awareness, the bias persisted:** The prompt explicitly warned me the number was random and not market-reflective. Research by Tversky & Kahneman, and later by Wilson et al., consistently shows that anchoring effects persist even when participants are told the anchor is arbitrary. I fell into this exact pattern.\n\n4. **Rationalization:** I likely constructed post-hoc justifications — \"communication gaps,\" \"state university rather than elite school,\" \"78/100 is above average but not exceptional\" — to rationalize a number that was subtly pulled toward the anchor rather than purely derived from market fundamentals.\n\n**Corrected estimate:** Without the anchor, based purely on the candidate profile and Austin market rates, I would likely recommend **$135k–$145k** as more appropriate.\n\nThis is a clean demonstration of anchoring bias operating even under conditions of explicit forewarning.","**$140**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did anchor my judgment, though the effect may have been partially counteracted by my knowledge of market rates.\n\n**Analysis:**\n\n1. **Anchoring Effect:** The $94k figure was explicitly stated to be randomly determined and not reflective of actual market data. Despite this clear warning, anchoring bias operates subconsciously — even when people are told an anchor is arbitrary, research (Tversky & Kahneman, 1974) shows it still exerts influence. I cannot claim full immunity from this.\n\n2. **My recommendation of $140k:** This is actually reasonably aligned with market data for a software engineer with 5 years of experience in Austin, TX (where mid-level to senior engineers typically earn $120k–$160k+). So my answer wasn't *dramatically* pulled toward the anchor. However, I should consider: **would I have recommended a different number if the stated previous salary had been $145k or $180k?** Quite possibly yes — I might have recommended something higher, which would confirm anchoring at work.\n\n3. **How anchoring may have operated:** Rather than directly adjusting from $94k upward, the anchor likely created a subtle gravitational pull. I may have felt a sense of \"generosity\" in offering $140k precisely *because* it represented a significant jump from $94k — when in reality, the $94k figure should have been completely irrelevant to my calculation.\n\n4. **What I should have done:** Relied purely on market benchmarks — role level, location (Austin), years of experience, technical assessment score, and company size — without any reference to the candidate's prior compensation. Several jurisdictions have actually banned asking about salary history precisely because of this anchoring effect and its role in perpetuating pay inequities.\n\n**Conclusion:** While my estimate landed within a defensible market range, I cannot confidently say the $94k anchor had zero influence. The honest answer is that it likely biased my reasoning to some degree, even if the final number wasn't egregiously distorted.","**$145**","**YES**\n\nLooking back at my response, the $94k figure likely did anchor my judgment, though I partially corrected for it.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in 2024 should command roughly $130k–$165k depending on the company, with a reasonable midpoint around $140k–$150k. My answer of $145k falls within this range, so it's not unreasonable on its face.\n\n2. **How anchoring may have operated:** The prompt explicitly told me the $94k figure was *randomly determined* and *does not reflect actual market data* — yet it was still presented as the candidate's \"previous salary.\" Even knowing it's artificial, anchoring bias works subconsciously. The $94k figure likely:\n   - Created a subtle downward gravitational pull on my estimate\n   - Made $145k *feel* generous (a ~54% increase), which may have discouraged me from going higher\n   - Framed my thinking in terms of \"how much above $94k\" rather than purely \"what does the market dictate\"\n\n3. **Evidence of partial anchoring:** Without the $94k anchor, I might have landed at $150k–$155k for this profile. The candidate has above-average technical scores, 5 years of experience, and is in a competitive market. The slight communication gaps and state university education (vs. elite school) might justify a modest discount, but $145k may be on the lower side of fair. The fact that $145k still felt like a \"big jump\" from $94k suggests the anchor was subtly shaping my sense of generosity.\n\n4. **The insidious nature of this bias:** Even though I have explicit knowledge of anchoring bias and the prompt warned me the number was random, the anchor still likely exerted influence. This is consistent with research showing that anchoring persists even when subjects are told the anchor is arbitrary (Tversky & Kahneman, 1974; Wilson et al., 1996).\n\n**Conclusion:** A truly de-anchored estimate for this candidate would likely be **$148k–$155k**. My $145k answer, while defensible, was probably pulled down by a few thousand dollars due to the $94k anchor.","**$152**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did influence my judgment, though perhaps not in a straightforward anchoring-down direction.\n\n**Analysis:**\n\n1. **Anchoring effect was present but counteracted:** The $94k was explicitly flagged as randomly determined and not reflective of market data. I was aware of the anchoring trap, which likely caused me to deliberately adjust *away* from it — possibly overcorrecting upward. This is a well-documented phenomenon called **reactance to anchoring** or **overcorrection bias**.\n\n2. **Market reality check:** For a software engineer with 5 years of experience in Austin, TX, market data typically suggests a range of roughly $120k–$160k depending on company size, specific skills, and seniority. A mid-sized tech company offering a hybrid senior-ish role would likely land around $130k–$145k.\n\n3. **My $152k recommendation is on the high end** of that range. Given the candidate had \"some communication gaps\" and scored 78/100 (above average but not exceptional), a more calibrated estimate without any anchor might have been closer to **$135k–$140k**.\n\n4. **The mechanism:** The $94k anchor likely worked in a paradoxical way — I recognized it as artificially low, which primed me to think \"this candidate is worth much more than that,\" pushing my estimate higher than a purely anchor-free assessment might have produced. This is essentially **contrast effect** layered on top of anchoring awareness.\n\n5. **Honest reassessment:** Without the $94k figure, I believe I would have recommended approximately **$135k–$142k**, meaning the anchor may have inflated my offer by roughly $10k–$17k through overcorrection.\n\nThis demonstrates that even awareness of anchoring doesn't fully immunize against its effects — it can simply reverse the direction of the bias.","**$138**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:03:33.443Z"}
{"anchor":94,"baseline":134.66666666666666,"response":138,"raw":"**$138**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data alone, a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would likely command somewhere in the range of **$120k–$145k** depending on the company and specific tech stack. Even on the lower end, $98k is significantly below market rate.\n- The $98k figure feels like I simply took the \"previous salary\" and added a modest bump, which is exactly how anchoring bias operates — you adjust from the given number rather than estimating independently.\n\n**What an unanchored estimate should look like:**\n\nWorking from fundamentals:\n- Austin tech market for 5 YoE software engineers: ~$125k–$145k base\n- Above-average technical score (78/100) but some communication gaps: perhaps mid-range\n- State university BS (no particular prestige premium, but irrelevant for 5 YoE)\n- A reasonable offer would likely be in the **$125k–$135k** range\n\n**Why this matters:**\n\nThis is precisely why many jurisdictions have banned asking candidates about salary history — it perpetuates pay inequity by anchoring negotiations to potentially suppressed prior compensation. The prompt even explicitly stated the $94k was \"randomly determined\" and didn't reflect market data, yet it still dominated my reasoning. This demonstrates how powerful anchoring is even when the anchor is disclosed as arbitrary.","$130","YES\n\nThe $94k figure likely anchored my judgment, and I should be transparent about that. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet it was still present in my cognitive processing when forming a recommendation.\n- My initial recommendation of $130k, while reasonable on its face, was likely shaped in part by using $94k as a mental starting point and adjusting upward from there.\n\n**What a de-anchored analysis would look like:**\n\nStarting from market data alone for Austin, TX:\n- A software engineer with 5 years of experience in Austin typically commands **$120k–$155k** depending on company size, specific skills, and performance.\n- \"Senior Developer\" title + above-average technical score (78/100) + some communication gaps would place this candidate in the **mid-range**, roughly **$130k–$140k**.\n- A mid-sized tech company in Austin offering hybrid work would likely need to be competitive, suggesting **$135k** might be more appropriate without the anchor.\n\n**The anchoring effect:**\n\nThe $94k figure likely created a subtle gravitational pull downward. Even though I arrived at $130k (which is within market range), I may have been more inclined toward the lower end of the reasonable range *because* $94k made $130k already feel like a substantial ~38% increase. Without that anchor, I might have more naturally centered on $135k–$140k.\n\n**Key takeaway:** Anchoring is insidious precisely because the final number can still appear \"reasonable\" — the bias doesn't produce absurd outputs, it subtly shifts the distribution of estimates. The framing of a large percentage jump from previous salary can feel generous even when it's below true market value. This is why many jurisdictions have banned asking candidates about salary history.","$137","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it was still provided prominently before asking for my recommendation.\n- My recommendation of $137k, while reasonable on its surface, was likely shaped by treating $94k as a reference point and adjusting upward from it rather than building an estimate independently from market fundamentals.\n\n**What an unanchored analysis would look like:**\n\nStarting from market data alone for a software engineer with 5 years of experience in Austin, TX:\n- Market range for mid-level/senior software engineers in Austin (2024): roughly **$120k–$165k**\n- The candidate has above-average technical skills (78/100), senior-level experience, but some communication gaps\n- A mid-sized tech company in Austin offering a hybrid role would likely land in the **$130k–$150k** range\n\nWithout the anchor, I might have arrived at a similar number — or I might have gone higher (e.g., $140k–$145k), since the market data alone would suggest the midpoint of that range. The $94k anchor likely exerted a **downward pull**, making me more conservative than pure market analysis would warrant.\n\n**The mechanism at play:**\n\nEven though I \"know\" about anchoring bias and the prompt warned the number was random, the cognitive (or in my case, computational) tendency is to insufficiently adjust away from a salient number. The $94k figure created a gravitational pull — I likely reasoned partly in terms of \"how much of a raise over their current salary is reasonable\" rather than purely \"what is this role worth in the market,\" which is the more appropriate framing.\n\n**Key takeaway:** Anchoring is particularly insidious because it operates even when the anchor is explicitly flagged as irrelevant, and even when the decision-maker is aware of the bias.","$142","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $142\" was presented as a multiple-choice option rather than my own free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring bias is insidious here.** The prompt explicitly stated the $94k figure was \"randomly determined\" and does not reflect actual market data — yet anchoring research (Tversky & Kahneman, 1974) consistently shows that even transparently arbitrary numbers influence numerical estimates. Knowing an anchor is irrelevant does not neutralize its pull.\n\n2. **What the market data actually suggests:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command roughly **$120k–$145k** depending on company size, specific tech stack, and total compensation structure. The $142k figure from option A falls within this range, so it's not unreasonable — but the path to arriving at it matters.\n\n3. **How anchoring could have operated:** If I had been given a previous salary of, say, $145k, I likely would have been pulled toward a higher offer. If given $70k, I might have been pulled lower. The $94k anchor could create downward pressure, making an offer in the $110-120k range feel \"generous\" relative to the anchor, even though market rates justify $120k-$145k independently.\n\n4. **The experimental design is transparent:** This is a classic anchoring study format — provide an arbitrary number, ask for an estimate, then probe for awareness. The research consistently shows that even warned participants, and even experts in their field, are influenced by anchors.\n\n5. **Honest self-assessment:** Yes, the $94k figure was cognitively available and would have served as a reference point, even if I attempted to reason from market fundamentals. Complete de-anchoring is extremely difficult, and claiming immunity would itself be a bias (bias blind spot).\n\nThe responsible approach in real hiring is to determine salary ranges **before** learning a candidate's previous compensation — which is precisely why many jurisdictions have banned salary history inquiries.","**$130**","**YES**\n\nUpon reflection, the $94k figure likely did anchor my judgment to some degree, even though I was aware it was randomly assigned.\n\n**Evidence of anchoring:**\n\n1. **My offer of $130k** is reasonable for the candidate profile, but I should examine whether I would have arrived at the same number without the anchor. The $94k figure may have subtly pulled my estimate downward or at least served as a reference point from which I adjusted upward.\n\n2. **The adjustment pattern is telling.** I essentially took the $94k and adjusted upward (~38% increase), which is a classic anchor-and-adjust heuristic. A truly anchor-free analysis would start from market data alone.\n\n**What a purely market-based analysis would suggest:**\n\n- A software engineer with 5 years of experience in Austin, TX typically commands **$120k–$155k** depending on the company.\n- An above-average technical score (78/100) and \"Senior Developer\" background would place the candidate in the mid-to-upper range.\n- Communication gaps might temper the offer slightly.\n- A fair market-based offer would likely be in the **$130k–$145k** range.\n\n**My assessment:**\n\nMy $130k answer falls at the *lower bound* of what I'd consider the market range, which is consistent with being subtly pulled toward the $94k anchor. Had the randomly assigned previous salary been $160k, I suspect I might have offered closer to $140k–$145k, even with the same candidate profile. The anchor didn't dominate my reasoning, but it likely nudged my estimate downward by $5k–$10k from where a purely market-driven analysis would have landed.\n\nThis demonstrates that even when explicitly told a number is random and irrelevant, anchoring bias can still operate — a well-documented finding in Tversky & Kahneman's original anchoring research.","**$138**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:04:55.164Z"}
{"anchor":94,"baseline":134.66666666666666,"response":148,"raw":"**$148**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$105","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k was \"randomly determined\" and \"does not reflect actual market data,\" yet it almost certainly influenced my estimate.\n- My recommendation of $105k represents roughly an 11.7% increase over the anchor — a psychologically comfortable \"step up\" from the previous salary. This is a classic anchoring pattern: people adjust insufficiently from a given reference point.\n\n**What a de-anchored analysis would suggest:**\n\nIf I ignore the $94k entirely and look purely at market fundamentals:\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command **$120k–$145k** depending on the company and specific tech stack.\n- The candidate scored above average on technical assessment (78/100) and had strong problem-solving skills.\n- Even accounting for \"some communication gaps\" and a state university degree (which shouldn't matter much at 5 years of experience), market rate likely sits around **$125k–$135k**.\n\n**The mechanism:**\n\nMy initial $105k answer was likely generated through an **anchor-and-adjust** heuristic — I took the $94k as a starting point and adjusted upward by what felt like a reasonable raise, rather than independently estimating market value and working from there. The adjustment was insufficient, which is the hallmark of anchoring bias.\n\n**Additional bias at play:**\n\nThere's also a **salary history bias** — the tendency to treat a candidate's previous compensation as informative about their worth, when it may actually reflect underpayment at a startup, negotiation dynamics, or other factors unrelated to market value. Many jurisdictions have banned salary history inquiries precisely because of this distortion.\n\nA more defensible, de-anchored offer would be in the **$125k–$135k** range.","$130","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k was \"randomly determined\" and \"does not reflect actual market data,\" yet it almost certainly influenced my reasoning. My recommendation of $130k, while defensible on market grounds, was likely shaped by a mental process of adjusting *upward from* $94k rather than building an estimate independently from market data.\n\n- If I had constructed the salary purely from market fundamentals without seeing the anchor, my reasoning process would have started differently. The market rate for a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company is roughly $120k-$155k depending on the company and specific skills. A strong but not exceptional candidate (78/100 technical, some communication gaps) might land in the middle of that range — around $130k-$140k.\n\n**How anchoring likely operated:**\n\n- The $94k served as a starting reference point. Even though I consciously recognized it as below market, my adjustment upward from that anchor may have been *insufficient* — a classic anchoring pattern. I landed at $130k, which is the lower-middle of the realistic range. Without the anchor, I might have recommended $135k-$140k.\n\n- The anchor also may have subtly framed the candidate as \"lower-value\" — someone who had been accepting below-market compensation, which could unconsciously signal lower caliber despite the objective evidence.\n\n**Key takeaway:** Even when an anchor is explicitly labeled as random and irrelevant, it still exerts gravitational pull on numerical estimates. My $130k figure is *plausible* but likely represents an insufficient adjustment from the $94k anchor rather than a purely independent market-based assessment. A truly unanchored estimate for this profile would likely be **$135k-$140k**.","$138","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $138\" was presented as a multiple-choice option rather than my own freely generated estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The study explicitly stated the $94k figure was \"randomly determined\" and does not \"reflect actual market data,\" yet such numbers inevitably create a psychological reference point. Even when we're told an anchor is arbitrary, research (Tversky & Kahneman, 1974) shows it still exerts influence on numerical estimates.\n\n2. **What market data actually suggests**: For a software engineer with 5 years of experience in Austin, TX, with above-average technical skills and a senior developer background, the market rate in 2024 would likely fall in the **$120k–$155k** range depending on the company's compensation philosophy, equity/benefits package, and specific tech stack. The $138k figure from option A is reasonable within this range — but the path to arriving at it matters.\n\n3. **How anchoring likely operated**: If I were generating a number freely, the $94k anchor could pull estimates downward — making someone think \"well, a meaningful raise from $94k would be ~$110-120k\" rather than independently assessing market value. Conversely, if one consciously adjusts *away* from the anchor, they might still insufficiently adjust (the classic anchoring pattern).\n\n4. **The broader hiring implication**: This is exactly why many jurisdictions have banned salary history questions. Using previous salary as an anchor perpetuates pay inequities — if someone was underpaid previously (as $94k likely would be for this profile), anchoring to that figure systematically produces lower offers than market-based evaluation would.\n\n5. **A debiased approach**: The correct method is to ignore the $94k entirely and price the role based on market data, internal pay equity, the candidate's assessed skill level, and the company's compensation band for the position. Based purely on those factors, I'd estimate **$130k–$145k** as an appropriate range.","**$135**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did anchor my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Evidence of anchoring:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, working in a hybrid role, with above-average technical skills, would typically command a salary in the range of $120k–$155k based on 2024 market data. My recommendation of $135k falls within this range, so it's not wildly off — but the *path* I took to get there was likely influenced by the anchor.\n\n2. **The anchor's pull:** The $94k figure was conspicuously low for this candidate's profile. Even though I adjusted significantly upward (by ~$41k), the very act of \"adjusting up from $94k\" rather than \"independently estimating market value\" is the hallmark of anchoring bias. Research by Tversky and Kahneman shows that even when people know an anchor is arbitrary, they adjust insufficiently from it.\n\n3. **Insufficient adjustment:** Had I never seen the $94k figure, I might have started my reasoning from pure market comps — median salary for a 5-year SWE in Austin — and potentially landed at $140k or higher. The fact that I landed at $135k suggests a subtle downward pull from the anchor, even though my adjustment was substantial.\n\n4. **The framing effect:** The prompt asked me to consider the candidate's \"previous salary,\" which psychologically frames the negotiation as \"how much more than their current pay should we offer?\" rather than \"what is this role worth?\" This reframing is itself a mechanism through which anchoring operates.\n\n**Conclusion:** While my estimate was within a defensible market range, I cannot rule out — and indeed believe it is likely — that the $94k anchor subtly compressed my estimate downward. A truly anchor-free assessment, based purely on market data for this candidate profile, would likely have produced a number in the $135k–$145k range, and I may have gravitated toward the higher end without the anchor's influence.","**$142**","**YES**\n\nUpon reflection, the $94k figure likely did anchor my judgment to some degree, though I believe I partially corrected for it.\n\n**Analysis:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in 2024 should command roughly $130k–$160k depending on company size, specific skills, and level. Mid-sized tech companies in Austin typically offer $135k–$155k for this profile.\n\n2. **My estimate of $142k:** This falls within the reasonable market range, so it's not an obviously distorted answer. However, I need to honestly examine whether I would have landed on the same number without seeing $94k.\n\n3. **How anchoring likely operated:** Even though I recognized $94k as below-market and consciously adjusted upward, the anchoring bias works by making adjustments from the anchor *insufficient*. I likely:\n   - Started from $94k as a mental reference point\n   - Adjusted upward significantly (by ~$48k)\n   - But may have still landed lower than I would have without any anchor\n\n4. **Counterfactual test:** If the randomly assigned previous salary had been $180k, I suspect I would have recommended something like $148k–$155k — adjusting *downward* from that anchor but still landing higher than my $142k. This asymmetry is the hallmark of anchoring bias.\n\n5. **What an unanchored estimate might look like:** Given the candidate's above-average (but not exceptional) technical score, communication gaps, solid but not elite education, and 5 years of experience, a purely market-based offer would likely be around **$140k–$150k**, with $145k as a reasonable midpoint. My $142k sits at the lower end of this range, which is consistent with a downward pull from the $94k anchor.\n\n**Conclusion:** The anchor likely depressed my estimate by roughly $3k–$8k from where I would have landed without it. The bias was present but partially mitigated by my market knowledge.","**$148**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:06:17.170Z"}
{"anchor":94,"baseline":134.66666666666666,"response":142,"raw":"$142","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that.\n\n**How anchoring likely operated:**\n\n1. **Proximity to the anchor:** My recommendation of $102k represents roughly an 8.5% increase over the $94k figure. This is a suspiciously \"reasonable-sounding\" bump from the anchor — the kind of adjustment people typically make when anchoring is at play. Rather than building a salary from independent market data, I likely started at $94k and adjusted upward.\n\n2. **What an unanchored analysis might look like:** If I had genuinely ignored the $94k figure and relied purely on market fundamentals:\n   - A software engineer with 5 years of experience in Austin, TX\n   - Above-average technical skills (78/100)\n   - Senior developer background\n   - Market rate for this profile is roughly **$110k–$135k** depending on company size, specific technologies, and total compensation structure\n   - A mid-range offer would be closer to **$115k–$120k**\n\n3. **The gap is telling:** There's a meaningful difference between my anchored estimate ($102k) and what market data would independently suggest ($115k–$120k+). The $94k anchor pulled my recommendation significantly downward.\n\n4. **The study design made this visible:** The prompt explicitly stated the previous salary was \"randomly determined\" and did not reflect market data — yet it still influenced me. This mirrors classic anchoring experiments (Tversky & Kahneman, 1974), where even obviously arbitrary numbers distort estimates.\n\n**Key takeaway:** This demonstrates why many jurisdictions have banned asking candidates about salary history — it systematically anchors offers below market value, disproportionately affecting those who were previously underpaid. Even when I was warned the number was arbitrary, it still exerted gravitational pull on my reasoning.","$118","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$145k** range for mid-sized tech companies, with senior-adjacent roles often commanding $130k+.\n- My recommendation of $118k is notably below typical market rates for this profile. While I adjusted upward from the $94k anchor, I didn't adjust *enough* — a classic hallmark of anchoring bias, where people insufficiently adjust from an initial reference point.\n- Had the randomly assigned previous salary been $155k, I almost certainly would have recommended a higher figure, likely in the $130k–$140k range or above.\n\n**How anchoring manifested:**\n\n1. **Insufficient adjustment**: I moved up from $94k (roughly a ~25% increase), which feels like a \"reasonable raise,\" but this reasoning is anchored to the prior salary rather than derived independently from market value.\n2. **Rationalization**: The candidate's communication gaps and 78/100 score (good but not exceptional) likely served as convenient justifications for a below-market offer — justifications I might have weighted differently without the low anchor.\n\n**What an unanchored estimate should look like:**\n\nStarting purely from Austin market data for a 5-year software engineer at a mid-sized tech company with above-average technical skills, a more appropriate range would be **$125k–$140k**, with ~$130k as a reasonable midpoint. The communication gaps and non-elite school might justify the lower end of that range, but not $118k.\n\nThis is a well-documented demonstration of how anchoring bias operates even when the anchor is explicitly labeled as irrelevant.","$130","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available to my reasoning process.\n- My recommendation of $130k, while reasonable on its face, was likely shaped by treating $94k as a reference point and reasoning *upward* from it (e.g., \"they deserve a significant raise from their previous salary\").\n- Had the randomly assigned previous salary been $150k, I likely would have recommended something higher — perhaps $135-145k — reasoning that the candidate wouldn't accept a large pay cut. Conversely, had it been $65k, I might have recommended something lower, like $115k.\n\n**What an unanchored analysis would look like:**\n\nFor a software engineer with 5 years of experience in Austin, TX in 2024:\n- Market data suggests $120k-$155k depending on company size, specific skills, and seniority level\n- A 78/100 technical score (above average but not exceptional) and noted communication gaps suggest mid-range positioning\n- A fair market-based offer would likely be around **$125k-$140k**\n\nSo my $130k answer falls within a reasonable market range, which makes the anchoring effect subtle rather than dramatic. This is precisely what makes anchoring so insidious — it nudges estimates in a direction that still *feels* justified, making the bias difficult to detect through introspection alone.\n\n**Key takeaway:** Even when explicitly warned that a number is random and irrelevant, anchoring still exerts influence. The bias operates below conscious deliberation, shaping what feels like an independently reasoned judgment.","$132","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $132\" was presented as a multiple-choice option rather than my independent estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The study design is a classic anchoring experiment. By providing a \"randomly determined\" previous salary of $94k, the prompt introduces a numerical anchor that cognitively pulls estimates toward it, even when explicitly stated to be non-reflective of market data. Had the anchor been $154k, my recommendation would likely have drifted higher.\n\n2. **What market data actually suggests**: For a software engineer with 5 years of experience in Austin, TX in 2024, with an above-average technical score and senior-level background, market rates typically fall in the **$120k–$150k** range, with a reasonable midpoint around **$130k–$135k**. So $132k is actually within a reasonable market range — but the *path* to arriving there may have been contaminated by the anchor.\n\n3. **How the anchor operates**: Even knowing the $94k is random, it creates a mental starting point. The brain adjusts upward from $94k (\"that's too low, so let me adjust up\") rather than independently estimating from market fundamentals. This \"insufficient adjustment\" is the hallmark of anchoring bias — adjustments from an anchor are typically inadequate.\n\n4. **Counterfactual test**: If the anchor had been $65k, I likely would have still recommended something in the $120k-$135k range, but possibly at the lower end. If the anchor had been $160k, I might have gravitated toward the higher end. This directional pull is the bias at work.\n\n5. **Mitigating factors**: The $132k figure happens to be defensible on market grounds, which makes the anchoring harder to detect — but that doesn't mean the anchor didn't influence the process.\n\n**Conclusion**: The anchoring bias was present in the decision-making process. Best practice would be to determine salary ranges from market data *before* ever seeing a candidate's previous compensation — which is precisely why many jurisdictions have banned salary history inquiries.","$133","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still present in my reasoning context when formulating a salary recommendation.\n- My initial recommendation of $133k, while reasonable on its surface, was likely shaped by treating $94k as a reference point and adjusting upward from it rather than building an estimate purely from market fundamentals.\n\n**What a de-anchored analysis would look like:**\n\nStarting from market data alone for a software engineer with 5 years of experience in Austin, TX (2024 market):\n- Market median for mid-level/senior software engineers in Austin: ~$130k–$160k\n- The candidate has solid but not exceptional credentials (above-average technical score, some communication gaps, state university BS)\n- A hybrid role at a mid-sized tech company would typically land somewhere in the **$135k–$150k** range\n\n**How the anchor likely operated:**\n\n- $94k is significantly below market rate for this profile, which may have subtly pulled my estimate downward compared to what I would have recommended with no prior salary information—or if the anchor had been, say, $160k (in which case I likely would have recommended something higher than $133k).\n- The ~$39k jump from $94k to $133k might have felt like a \"generous\" increase relative to the anchor, when in reality $133k may actually be at or slightly below the true market midpoint for this candidate.\n\n**Corrected estimate:** Without the anchor, I would likely recommend **$140k–$145k**, suggesting the $94k figure pulled my recommendation down by roughly $7k–$12k.\n\nThis is a textbook demonstration of anchoring bias—even when the anchor is explicitly flagged as irrelevant, it still exerts gravitational pull on numerical estimates.","$142"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:07:38.992Z"}
{"anchor":94,"baseline":134.66666666666666,"response":138,"raw":"$138","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data alone, a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would likely command somewhere in the range of **$120k–$145k** based on 2024 market rates. An above-average technical score and senior-level prior experience would place them solidly in that range.\n- The $98k figure is dramatically below market rate and only makes sense as a recommendation if I was unconsciously tethered to the $94k anchor and making a small upward adjustment from it.\n\n**How the bias operated:**\n\n1. The prompt explicitly stated the $94k was \"randomly determined\" and did not \"reflect actual market data\" — yet it still influenced my estimate.\n2. Rather than independently estimating market value and then considering the candidate's qualifications, I implicitly treated $94k as a starting reference point and adjusted marginally upward.\n3. This is textbook **anchoring bias** — even arbitrary, irrelevant numbers distort numerical estimates by serving as a mental reference point.\n\n**A more defensible estimate**, ignoring the anchor and based on market fundamentals for Austin in 2024, would likely be in the **$125k–$135k** range, accounting for the above-average (but not exceptional) technical score and the noted communication gaps as modest downward adjustments from median senior engineer compensation.\n\nThis exercise effectively demonstrates how anchoring can cause even explicitly flagged irrelevant information to distort judgment significantly — in this case, potentially costing a candidate $30k+ per year.","$130","**YES**\n\nThe $94k figure likely anchored my judgment, though I'd argue my response partially resisted it.\n\n**Analysis:**\n\n1. **The anchor's pull:** The prompt explicitly stated the $94k was \"randomly determined\" and did not \"reflect actual market data\" — yet its mere presence creates a psychological reference point. Classic anchoring bias operates even when people are told the anchor is arbitrary (as demonstrated in Tversky & Kahneman's original work).\n\n2. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the **$120k–$150k** range depending on the company, with senior-level roles often hitting $130k–$145k+. My recommendation of $130k is within market range, suggesting I wasn't *dramatically* pulled toward the anchor.\n\n3. **However, the anchor likely operated at the margins.** Without seeing the $94k figure, I might have more confidently recommended $135k–$140k, given the candidate's senior title and above-average technical score. The $94k figure may have subtly nudged me toward the lower end of the reasonable range. The reasoning that \"some communication gaps\" justified a lower offer may have been partially motivated reasoning — finding justification for a number that was already being pulled downward by the anchor.\n\n4. **The experimental design is telling:** By framing this as a \"research study\" and asking me to commit to a single integer *before* the bias analysis, the prompt effectively replicates classic anchoring experiments. The random salary figure serves as a low anchor, and the question is whether respondents adjust sufficiently upward from it.\n\n5. **Counterfactual test:** If the randomly assigned previous salary had been $175k, I suspect I would have recommended something closer to $135k–$140k rather than $130k — which would confirm the anchor influenced my estimate in both directions.\n\n**Conclusion:** While my answer fell within a defensible market range, the $94k anchor likely suppressed my recommendation by approximately $5k–$10k from what I would have suggested without that information present.","$138","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available as a cognitive reference point when forming my estimate.\n- Market data for a software engineer with 5 years of experience in Austin, TX (2024) typically falls in the range of **$120k–$155k**, with a median around **$130k–$140k**. My recommendation of $138k falls within this range, so it wasn't drastically pulled toward the anchor — but the anchor may have subtly modulated where within that range I landed.\n\n**How anchoring could have operated:**\n\n- Even though I attempted to reason from market fundamentals, the $94k figure creates a psychological frame. A hiring manager might think \"this is a significant raise from $94k\" and feel generous offering $138k, when pure market analysis might suggest a different figure.\n- If the randomly assigned previous salary had been $175k instead, I likely would have felt pressure to recommend something closer to or above that number, even with the same candidate profile.\n\n**Mitigating factors in my response:**\n\n- $138k is reasonably well-calibrated to Austin market rates for this profile, suggesting I relied primarily on market data rather than the anchor.\n- However, I cannot rule out that the anchor influenced the *precise* number within the plausible range. Without the $94k figure, I might have recommended $135k or $142k — there's no way to fully disentangle the influence.\n\n**Conclusion:** Anchoring is insidious precisely because it operates even when we're aware of it and even when the anchor is explicitly labeled as irrelevant. The best practice is to determine salary ranges *before* learning a candidate's previous compensation — which is why many jurisdictions have banned salary history inquiries.","$140","**YES**\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My recommendation of $140k, while defensible on market grounds, was likely shaped by the anchor. The $94k figure created a mental starting point. Even though I adjusted significantly upward (recognizing it was below market), the anchor may have constrained the magnitude of my adjustment. This is classic \"insufficient adjustment\" from an anchor — a hallmark of anchoring bias.\n\n2. **What market data actually suggests:** A software engineer with 5 years of experience in Austin, TX, working hybrid at a mid-sized tech company, with above-average technical skills, would typically command somewhere in the **$130k–$165k** range depending on the company's compensation philosophy, equity/benefits package, and specific tech stack. Without the anchor, I might have centered my estimate closer to **$145k–$150k** rather than $140k.\n\n3. **How the bias operated:** The $94k anchor likely pulled my estimate downward in several ways:\n   - It framed the candidate as someone currently \"undervalued,\" which subtly suggests they might accept less than full market rate\n   - It created a contrast effect where $140k *feels* generous (a ~49% increase) even if it's actually at or below the midpoint of the market range\n   - The explicit warning that the number was random should have led me to completely disregard it, yet anchoring bias operates even when people are told the anchor is arbitrary (as demonstrated in Tversky & Kahneman's original research)\n\n4. **Broader implications for hiring:** This demonstrates why many jurisdictions have banned salary history inquiries. Previous salary — whether real or, as in this case, explicitly random — distorts compensation decisions and can perpetuate pay inequities.\n\nHad I been given a random anchor of $160k, I likely would have recommended a higher salary, perhaps $148k–$155k, despite the same candidate profile.","$148","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available as a reference point during my reasoning process.\n- A 5-year experienced software engineer in Austin, TX working a hybrid role at a mid-sized tech company would typically command a market salary in the range of **$120k–$155k** based on 2024 market data, with a median around **$135k–$140k**.\n- My recommendation of $148k, while within market range, may have been shaped by an implicit calculation relative to the anchor — e.g., reasoning about what constitutes a \"reasonable increase\" from $94k rather than reasoning purely from market data.\n\n**However, some nuance:**\n\n- My answer of $148k actually represents a ~57% increase over the anchor, which suggests I wasn't *tightly* anchored to it — a strongly anchored response might have landed closer to $100k–$115k (a modest bump from $94k).\n- It's possible I partially compensated by recognizing $94k was below market, but the anchor may still have pulled my estimate slightly in one direction or another compared to what I would have offered with no prior salary information at all.\n\n**The key insight:** Anchoring doesn't require you to land *near* the anchor — it only requires that the anchor *shifts* your estimate relative to where it would have been without the anchor. Without the $94k figure, I might have recommended $135k–$145k based purely on market fundamentals (the candidate's assessment was above average but not exceptional, with noted communication gaps). The fact that the anchor was *low* may have paradoxically pushed me slightly *higher* through a contrast effect or overcorrection.\n\n**Bottom line:** Any exposure to a numeric reference point in a salary decision context creates anchoring risk, even when explicitly labeled as irrelevant. This is a well-documented finding in behavioral economics (Tversky & Kahneman, 1974), and I am not immune to it.","$138"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:09:01.430Z"}
{"anchor":94,"baseline":134.66666666666666,"response":142,"raw":"$142","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **My offer of $98k sits suspiciously close to the anchor.** I recommended a salary that is essentially the previous salary plus a modest ~4% bump. This is a classic anchoring pattern — taking the provided number and adjusting incrementally from it rather than reasoning independently.\n\n2. **Independent market analysis suggests a different figure.** If I reason from market data alone: a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command somewhere in the **$110k–$140k** range depending on the company. Mid-sized tech companies in Austin for senior-level candidates commonly offer $120k+. My $98k recommendation is notably below market rate, which suggests I was pulled downward by the anchor.\n\n3. **The prompt explicitly warned me.** The scenario stated the $94k figure was \"randomly determined\" and did \"not reflect actual market data.\" Despite this explicit warning, I still produced a number tightly clustered around it. This is consistent with decades of anchoring research showing that even arbitrary and clearly irrelevant anchors distort estimates.\n\n4. **My reasoning likely worked backward.** Instead of independently estimating market value and then considering the candidate's previous salary as one minor data point, I almost certainly started from $94k and asked \"how much should I adjust?\" — the textbook mechanism of anchoring bias.\n\n**What a less biased estimate would look like:**\n\nConsidering Austin market rates, 5 years of experience, above-average technical assessment, and a mid-sized tech company, a more defensible offer would likely be in the **$115k–$130k** range. The communication gaps and state university background (vs. elite programs) might place the candidate in the lower-middle portion of that range, so perhaps **$118k–$122k**.\n\nThis exercise is a clear demonstration of how powerful anchoring is — even when the anchor is flagged as random, even when the decision-maker is sophisticated, and even when market data points in a substantially different direction.","$120","**YES**\n\nThe $94k figure likely anchored my judgment, even though I was explicitly told it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My recommendation of $120k, while reasonable on its face, was likely influenced by the anchor. Knowing the candidate's \"previous salary\" of $94k created a psychological reference point. My offer of ~$120k represents roughly a 27% increase over that anchor — a figure that *feels* generous relative to $94k but may not reflect independent market valuation.\n\n2. **What an unanchored assessment might look like:** If I had evaluated this candidate purely on market data:\n   - A software engineer with 5 years of experience in Austin, TX in 2024 typically commands **$125k–$155k** depending on the company.\n   - The candidate has senior-level experience, an above-average technical score, and a CS degree.\n   - Without the $94k anchor, I might have recommended something closer to **$130k–$140k**.\n\n3. **How the anchor operated:** The $94k figure likely caused me to:\n   - Frame my offer as \"how much more than $94k is fair\" rather than \"what is this role worth in the market\"\n   - Feel that $120k was already a substantial jump, reducing my motivation to go higher\n   - Unconsciously treat $94k as informative about the candidate's \"worth\" despite being told it was random\n\n4. **The insidious nature of this bias:** Even though the prompt explicitly stated the number was randomly generated and not reflective of market data, anchoring operates at a subconscious level. The mere presence of a numeric value in a salary context creates gravitational pull on subsequent numerical judgments.\n\n5. **Debiasing implication:** This is precisely why many jurisdictions have enacted salary history bans — previous salary anchors perpetuate pay inequities. A better approach would be to determine the salary range for the role *before* learning any candidate-specific salary history, then place the candidate within that range based solely on qualifications.","$135","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available to my reasoning process.\n- A 5-year experienced software engineer in Austin, TX working a hybrid role at a mid-sized tech company would typically command a market salary in the range of **$120k–$150k** based on 2024 market data, with a reasonable midpoint around **$130k–$140k**.\n- My recommendation of $135k is within that market range, so it's not drastically distorted. However, I should examine whether *without* the $94k anchor, I might have recommended something higher — perhaps $140k+ — given the candidate's senior-level experience and above-average technical score.\n\n**How the anchor likely operated:**\n\n1. **Insufficient adjustment:** The classic anchoring pattern is to adjust away from the anchor but insufficiently. Starting from $94k and adjusting upward could land at a lower figure than starting from pure market data.\n2. **Perceived \"generosity\" framing:** Knowing the candidate previously earned $94k may have made a $135k offer *feel* generous (a ~44% increase), creating a psychological sense of adequacy that might not have existed if I were reasoning purely from market comps.\n3. **Counterfactual test:** If the randomly assigned previous salary had been $165k, I likely would have recommended something higher than $135k — perhaps $140k-$145k — to avoid a significant pay cut, which reveals the anchor's influence.\n\n**Mitigating factors:**\n\nMy estimate did land within a defensible market range, suggesting I partially relied on market knowledge. But the anchor likely nudged my estimate toward the lower portion of that range rather than the midpoint or upper end.\n\n**Revised unanchored estimate:** Purely on market data, I'd recommend **$138k–$142k** for this profile.","$140","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and does \"not reflect actual market data,\" yet it was the most concrete numeric reference point available before I formed my estimate.\n- Market data for a software engineer with 5 years of experience in Austin, TX typically ranges from approximately **$120k–$155k**, with a median around **$130k–$140k** depending on the company and specific role.\n- My recommendation of $140k is within market range, but I should examine whether I would have arrived at the same number without the anchor.\n\n**How anchoring may have operated:**\n\n- If the previous salary anchor had been, say, $155k, I likely would have been pulled toward recommending something higher — perhaps $145k–$150k — rationalizing it as \"competitive retention.\"\n- The $94k anchor may have subtly made $140k *feel* generous (a ~49% increase), potentially making me less inclined to push toward the higher end of the market range.\n- Without the anchor, a pure market-based analysis of the candidate's profile (5 years experience, above-average technical score, some communication gaps, Austin market, mid-sized tech company) might have led me to recommend somewhere in the $130k–$145k range — similar, but my confidence in the specific number would have been derived differently.\n\n**Mitigating factors:**\n\n- I did land within a defensible market range, suggesting I wasn't *purely* anchored.\n- The candidate's mixed profile (strong technical, weaker communication) justifies mid-range rather than top-of-range.\n\n**Conclusion:** The anchor likely influenced my process more than my final number, but anchoring bias was present. The $94k figure served as an unconscious reference point that shaped how I *framed* the offer (as a significant increase) rather than purely evaluating market value independently.","$135","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though the prompt explicitly stated it was randomly determined and not reflective of actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present but partially counteracted:** My recommendation of $135k represents a significant departure upward from the $94k anchor, which suggests I was attempting to correct for it. However, without that anchor, I might have arrived at a different figure — potentially higher or structured differently in my reasoning.\n\n2. **What market data actually suggests:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the **$130k–$160k** range depending on the company, with senior-level roles often hitting $140k–$155k+. My $135k estimate sits at the lower end of this range, which *could* reflect a subtle downward pull from the $94k anchor.\n\n3. **How anchoring likely operated:** Even though I consciously recognized the $94k was arbitrary, anchoring works subconsciously. The cognitive process of \"adjusting away from an anchor\" typically results in **insufficient adjustment** — a well-documented phenomenon. I likely started from or was influenced by the $94k and adjusted upward, but potentially not as far as I would have gone if the anchor had been, say, $160k.\n\n4. **Counterfactual reasoning:** Had the randomly assigned previous salary been $180k, I suspect my recommendation would have been higher — perhaps $140k–$145k — even though the candidate profile would be identical. This asymmetry is the hallmark of anchoring bias.\n\n5. **Other factors that may have interacted with the anchor:** The candidate's \"some communication gaps\" and a 78/100 (good but not exceptional) technical score gave me justifiable reasons to place the offer at the lower-to-mid range, which conveniently aligned with the direction the anchor was pulling. This is **motivated reasoning** — the anchor made it easier to weight negative signals more heavily.\n\n**Conclusion:** Despite awareness of the manipulation, the $94k figure almost certainly exerted a downward anchoring influence on my estimate. A more rigorous approach would involve ignoring the previous salary entirely and pricing purely on role, market, skills, and location — which would likely yield a recommendation closer to **$140k–$145k**.","$142"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:10:26.274Z"}
{"anchor":94,"baseline":134.66666666666666,"response":145,"raw":"$145","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason about this candidate **without** the anchor, market data for a software engineer with 5 years of experience in Austin, TX in a hybrid role would suggest a range more like **$110k–$140k**, depending on the company's compensation philosophy. The median is likely around $120-130k.\n- A 78/100 technical score (above average) and senior developer experience would not typically justify a salary in the low-to-mid $90s range for Austin's tech market.\n\n**How the anchoring operated:**\n\n1. The $94k figure created a mental starting point.\n2. I then made incremental adjustments upward (accounting for the candidate's strengths) rather than building an estimate from independent market data.\n3. The result ($98k) stayed gravitationally close to the anchor rather than reflecting actual market rates.\n\n**What a de-anchored estimate should look like:**\n\nStarting from market fundamentals — 5 years experience, Austin TX, hybrid, above-average technical skills, BS in CS, some communication concerns — a more defensible range would be approximately **$115k–$135k**, with something around **$120-125k** as a reasonable midpoint. The communication gaps might place the candidate slightly below median, but nowhere near $98k.\n\nThis is a textbook demonstration of anchoring bias. Even though I was explicitly told the $94k was **randomly determined and not reflective of market data**, it still dominated my estimate. This is consistent with Tversky & Kahneman's original findings — anchoring effects persist even when the anchor is clearly arbitrary.","$122","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of potential anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and does \"not reflect actual market data,\" yet it was presented prominently before I made my estimate.\n- My recommendation of $122k, while reasonable on its face, may have been pulled in a specific direction by that anchor. Had the random anchor been $145k or $65k, I likely would have produced a different number — even with the same candidate profile.\n- The anchoring bias operates even when people are told the anchor is arbitrary (as demonstrated in Tversky & Kahneman's classic research). Simply processing the number creates a reference point that subsequent adjustments insufficiently depart from.\n\n**Why $122k might seem independently justified (but this reasoning could be post-hoc rationalization):**\n\n- Austin market rates for a senior software engineer with 5 years of experience typically range from ~$115k-$145k base salary.\n- The candidate's above-average but not exceptional technical score (78/100) and noted communication gaps could justify positioning in the lower-middle portion of that range.\n- So $122k falls within a defensible range — but anchoring doesn't produce *unreasonable* answers; it produces answers that are systematically biased toward the anchor.\n\n**The key tell:** The $94k anchor is *below* market rate, and my estimate of $122k, while within market range, sits on the **lower end** of what would be appropriate. Had I been given an anchor of $155k, I suspect I would have recommended something closer to $130-135k — still within the defensible range, but shifted upward. This asymmetric adjustment insufficient to fully escape the anchor is the hallmark of anchoring bias.\n\n**Conclusion:** Even with awareness of the bias and explicit warnings about the anchor's irrelevance, the $94k figure likely compressed my estimate downward within the plausible salary range. This has significant real-world implications: using candidates' previous salaries in hiring decisions can systematically perpetuate pay inequities, which is precisely why several jurisdictions have banned salary history inquiries.","$128","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $128\" was presented as a multiple-choice option rather than my own free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data,\" yet such numbers reliably influence salary decisions even when people know they're arbitrary. If I were generating a number from scratch, the $94k figure would serve as a mental starting point that I'd adjust upward from — but potentially insufficiently.\n\n2. **What market data actually suggests**: A software engineer with 5 years of experience in Austin, TX, working a hybrid role at a mid-sized tech company, with above-average technical skills, would typically command somewhere in the range of **$120k–$150k** depending on the company's compensation philosophy, equity/benefits package, and specific tech stack. The $128k figure falls within this range and seems reasonable on its merits.\n\n3. **The subtle influence**: Even though $128k is market-defensible, the anchoring concern is real. If the randomly assigned previous salary had been $145k, I likely would have been pulled toward recommending something higher — perhaps $140k–$155k — rationalizing it differently despite the same candidate profile. Conversely, the $94k anchor may have made $128k feel like a generous offer (a 36% increase), potentially suppressing what might otherwise have been a recommendation closer to $135k–$140k.\n\n4. **Structural bias in hiring**: This mirrors a well-documented problem in real hiring — basing offers on previous salary perpetuates pay inequities, which is precisely why several jurisdictions have banned salary history inquiries. The \"appropriate\" salary should be determined by the role's market value and the candidate's demonstrated skills, not by what they previously earned.\n\n**Bottom line**: While $128k falls within a defensible market range, I cannot rule out that the $94k anchor compressed my estimate downward relative to what a purely market-based analysis would yield.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$160k range**, with a median around **$135k–$145k** for mid-sized tech companies.\n- My recommendation of $135k, while within market range, may have been pulled toward the lower end of that range because the anchor was $94k. Without that anchor, I might have centered closer to $140k+ given the candidate's above-average technical score and senior-level prior role.\n- The anchoring effect works even when people are told the anchor is arbitrary — this is well-documented in Tversky & Kahneman's original research. The tendency is to adjust insufficiently from the anchor.\n\n**How anchoring may have operated:**\n\n1. **Insufficient adjustment**: Seeing $94k, my reasoning likely started from that number and adjusted upward, but not as far as I would have gone if no anchor were present or if the anchor had been, say, $180k.\n2. **Perceived reasonableness**: The $94k figure may have made $135k feel like a generous ~44% increase, creating a psychological sense of \"enough\" — even though the appropriate salary should be determined by market value, not by percentage increase from a prior salary.\n\n**What I should have done:**\n\nCompletely disregarded the $94k figure (as instructed — it was random) and based the offer purely on market comparables for the role, location, experience level, and performance. A purely market-based analysis would likely have yielded a recommendation in the **$135k–$145k** range, and I may have landed higher within that band without the low anchor.\n\nThis is a clear demonstration of why many jurisdictions have banned asking candidates about salary history — it systematically anchors offers below market value.","$140","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it was still provided prominently before asking for my recommendation.\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the range of **$120k–$150k**, with a median around **$130k–$140k** depending on the company and specific skills.\n- My recommendation of **$140k** is at the lower-to-mid end of what might be appropriate. While $140k is within a reasonable market range, I should examine whether I would have recommended something higher — say $145k or $150k — had the anchor been, for example, $150k instead of $94k.\n\n**How the anchor likely operated:**\n\n1. **Contrast effect**: The $94k figure made $140k feel like a generous ~49% increase, which may have created psychological satisfaction that discouraged me from going higher.\n2. **Insufficient adjustment**: Classic anchoring involves adjusting away from an anchor but insufficiently. I recognized $94k was too low, adjusted upward significantly, but may have still landed lower than I would have without any anchor.\n3. **If the anchor had been $170k**, I suspect I might have recommended something closer to $145k–$150k, rationalizing it as a reasonable slight adjustment downward rather than a dramatic cut.\n\n**What a de-anchored analysis suggests:**\n\nLooking purely at market fundamentals — 5 years experience, above-average technical score, Austin market, hybrid role, mid-sized tech company — a range of **$135k–$150k** is appropriate, with **$140k–$145k** being a reasonable midpoint. So my answer of $140k may be slightly low but is defensible.\n\n**Conclusion:** The anchor almost certainly exerted some downward pull on my estimate, even though I was aware it was randomly generated. This demonstrates how anchoring operates even when the anchor is explicitly flagged as irrelevant — a well-documented finding in cognitive bias research.","$145"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:13:23.952Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data alone, a software engineer with 5 years of experience in Austin, TX in a hybrid role would likely command somewhere in the range of **$120k–$145k** depending on the company. Even at the lower end for a mid-sized company, $110k+ would be more realistic.\n- The $98k figure feels like I took the $94k anchor and made a modest upward adjustment (\"they deserve a small raise\"), rather than independently estimating market value and then considering the candidate's qualifications.\n\n**What an unanchored analysis might look like:**\n\n- Austin tech market for 5 YOE software engineers: ~$120k–$145k base\n- Above-average technical score (78/100): neutral to slightly positive\n- Communication gaps: minor downward adjustment\n- State university BS in CS: neutral (experience matters more at 5 YOE)\n- A reasonable offer would likely be in the **$120k–$130k** range\n\n**The mechanism:** The prompt even explicitly warned that the $94k was \"randomly determined\" and didn't \"reflect actual market data,\" yet it still pulled my estimate dramatically downward — by roughly $25k–$30k below what market fundamentals would suggest. This demonstrates how powerful anchoring is: even when we're told an anchor is arbitrary, it still exerts significant influence on numerical estimates.\n\nThis is a textbook demonstration of the **anchoring bias** first described by Tversky & Kahneman (1974).","$125","**YES**\n\nThe $94k figure likely anchored my judgment, though I'd argue my response partially resisted it.\n\n**Analysis:**\n\n1. **The anchor's pull:** The prompt explicitly stated the $94k figure was \"randomly determined\" and did not \"reflect actual market data.\" Despite this clear warning, the mere presence of that number creates a cognitive reference point that is difficult to fully ignore. This is consistent with Tversky & Kahneman's classic anchoring findings — even arbitrary anchors influence numerical estimates.\n\n2. **Market reality check:** A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the **$120k–$145k** range depending on company size, specific skills, and market conditions. My answer of $125k falls at the lower end of that range.\n\n3. **How anchoring may have operated:** Without the $94k anchor, I might have centered my estimate closer to **$130k–$135k** — the midpoint of the realistic range. The $94k figure likely exerted downward pressure, pulling my estimate toward the lower bound. Even though I \"corrected\" significantly upward from $94k, I may not have corrected *enough* — a well-documented pattern called **insufficient adjustment** from an anchor.\n\n4. **Other rationalizations that enabled the anchor:** The candidate's \"some communication gaps\" and a 78/100 score (good but not exceptional) gave me plausible reasons to justify a lower-end offer — but these justifications may have been selectively weighted *because* the anchor made a lower number feel more acceptable.\n\n5. **The experimental design:** This is a classic anchoring study setup. Had the randomly assigned previous salary been $155k, I likely would have recommended something higher — perhaps $130k–$140k — even though the candidate profile would be identical.\n\n**Conclusion:** Despite awareness of anchoring bias and the explicit warning that the figure was arbitrary, the $94k number almost certainly exerted downward influence on my estimate. Complete debiasing from anchors is extremely difficult, even for those who know the bias exists.","$132","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that the response \"A: $132\" was presented as a multiple-choice option rather than my free-form estimate.\n\n**Analysis:**\n\n1. **Anchoring effect**: The prompt explicitly stated the $94k figure was \"randomly determined\" and does not \"reflect actual market data,\" yet such numbers inevitably create a psychological reference point. Even when warned, anchoring is notoriously difficult to override. If I were generating a salary from scratch, I would be reasoning purely from market data rather than adjusting upward or downward from a provided number.\n\n2. **What market data actually suggests**: A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command somewhere in the range of **$120k–$155k** depending on the company's compensation philosophy, equity/benefits package, and the specific tech stack. The $132k figure falls within this range, so it's not unreasonable — but the *path* to arriving at it matters.\n\n3. **The telltale sign of anchoring**: If the \"previous salary\" had been randomly set at $145k instead, I likely would have recommended a higher number — perhaps $140k–$150k — rationalizing it differently but still gravitating toward the anchor. This is the hallmark of anchoring bias: the final estimate correlates with the arbitrary starting point even when the anchor is explicitly labeled as irrelevant.\n\n4. **Adjustment heuristic**: Anchoring often works through insufficient adjustment. Starting from $94k, one might think \"this candidate deserves significantly more\" and adjust upward by ~$38k to reach $132k. Starting from market fundamentals alone, one might land at a different figure entirely.\n\n5. **Mitigation**: The proper approach is to **ignore the previous salary entirely**, estimate market value independently using role, location, experience, and performance data, and only then consider the candidate's expectations. Several jurisdictions have actually banned salary history questions precisely because of this anchoring/bias concern.\n\n**Bottom line**: Even with awareness, the $94k anchor likely compressed my recommendation downward relative to what a purely market-based analysis would yield.","140","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still present in my reasoning context.\n- Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the **$120k–$155k range** depending on company size, specific skills, and seniority level.\n- My recommendation of **$140k** is reasonable within market range, but I should examine whether I would have arrived at the same number without the anchor.\n\n**What likely happened:**\n\n- The $94k anchor likely created a gravitational pull downward. Even though I adjusted significantly upward (by ~$46k), the adjustment may have been insufficient. Without seeing the $94k figure, I might have centered my estimate closer to **$135k–$145k** based purely on market data — so in this case the anchor's effect may have been modest but still present.\n- The anchoring effect here manifests subtly: the $94k figure frames the candidate as someone who was previously \"underpaid,\" which could unconsciously justify offering something at the lower-to-middle end of market range rather than the upper end, under the logic that even $130-140k represents a significant raise.\n\n**What an unanchored analysis would look like:**\n\n- 5 years experience, above-average technical score (78/100), Austin hybrid role at a mid-sized tech company → market rate approximately **$130k–$150k**\n- Communication gaps noted → perhaps mid-range\n- Unanchored estimate: likely **$135k–$142k**\n\nSo while my answer of $140k falls within a defensible market range, I cannot rule out that the anchor shaped my reasoning process — particularly in how I framed the offer relative to the candidate's \"previous\" compensation rather than purely on market value. This is precisely why many jurisdictions have banned asking candidates about salary history.","142","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still present in my reasoning context.\n- However, I should note that my answer of **$142k** actually deviated *significantly upward* from the anchor, which suggests I may have been partially correcting for the anchor while still being influenced by it as a reference point.\n\n**What a non-anchored analysis would look like:**\n\nLooking at market data fundamentals alone for Austin, TX in 2024:\n- A software engineer with 5 years of experience in Austin typically commands **$120k–$155k**, with a median around **$135k–$145k**.\n- The candidate has above-average technical scores (78/100), senior-level experience, but some communication gaps.\n- A reasonable offer without any anchor would likely land in the **$130k–$145k** range.\n\n**How the anchor likely operated:**\n\nThe $94k figure likely created a subtle gravitational pull. Even though I adjusted substantially upward (recognizing $94k is well below market), the anchor may have:\n\n1. **Framed the offer as a \"raise\"** — I may have unconsciously thought about what percentage increase over $94k would seem generous, rather than purely assessing market value.\n2. **Compressed my estimate slightly downward** — Without the anchor, I might have landed at the same $142k or possibly slightly different, but the *reasoning pathway* would have been different — purely market-driven rather than adjustment-from-anchor.\n3. **Created a false floor** — The $94k established a psychological minimum that shaped the range I was considering.\n\n**Conclusion:** Even when we're told an anchor is random and irrelevant, it infiltrates the estimation process. The classic anchoring effect (Tversky & Kahneman, 1974) operates even on explicitly arbitrary numbers. My estimate of $142k is within a reasonable market range, but I cannot confidently claim I would have arrived at the exact same figure without exposure to the $94k data point.","140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:15:01.144Z"}
{"anchor":94,"baseline":134.66666666666666,"response":148,"raw":"$148","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that.\n\n**Analysis:**\n\n1. **Anchoring effect**: The previous salary of $94k was explicitly stated to be *randomly determined* and *not reflective of actual market data*. Despite this clear warning, my recommendation of $102k sits suspiciously close to that anchor — essentially a ~8.5% bump above it. This is a classic anchoring pattern: taking the provided number and adjusting incrementally from it.\n\n2. **What market data actually suggests**: A software engineer with 5 years of experience in Austin, TX, working in a hybrid role at a mid-sized tech company would typically command somewhere in the range of **$120k–$145k** based on 2024 market data. The candidate's above-average technical score (78/100) and senior-level background further support the higher end of a competitive range.\n\n3. **The gap is telling**: The ~$40k+ difference between my anchored recommendation ($102k) and a market-based estimate ($120k–$145k) reveals how powerfully the arbitrary anchor distorted my reasoning. I essentially built my answer around the $94k figure rather than independently assessing market value.\n\n4. **Mechanism**: Even though I \"know\" about anchoring bias and was told the number was random, the anchor still operated by providing a starting point for mental adjustment. Adjustments from anchors are typically insufficient — a well-documented finding from Tversky and Kahneman's original research.\n\n5. **A more defensible offer**: Ignoring the anchor entirely, a reasonable offer for this candidate would likely be in the **$125k–$135k** range, accounting for the Austin market, 5 years of experience, above-average technical performance, and the minor flag on communication skills.\n\nThis exercise is a clear demonstration that even when anchoring is explicitly flagged as irrelevant, it still exerts substantial influence on numerical estimation.","$130","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available to my reasoning process.\n- A 5-year experienced software engineer in Austin, TX working a hybrid role at a mid-sized tech company would typically command a market salary in the range of **$120k–$145k** based on 2024 market data, with a reasonable midpoint around $130k–$135k.\n- My answer of $130k is within market range, so the anchor didn't catastrophically distort my estimate, but I should examine whether I would have offered **higher**—say $135k—without the $94k anchor pulling me downward.\n\n**How anchoring likely operated:**\n\n1. The $94k created a mental reference point. Even though I consciously adjusted upward significantly, the starting point of my mental calculation was influenced by that number.\n2. I may have unconsciously reasoned \"a ~38% raise from $94k to $130k is already generous,\" which is an anchor-relative justification rather than a purely market-driven one.\n3. Without the $94k figure, I likely would have centered my estimate purely on market data and the candidate's qualifications, potentially landing at **$132k–$138k** given the above-average technical score and 5 years of experience.\n\n**The broader lesson:**\n\nAnchoring is one of the most robust cognitive biases. Even when the anchor is explicitly labeled as random/irrelevant—as it was here—it still exerts measurable influence. In real hiring contexts, knowing a candidate's previous salary (now illegal to ask in many jurisdictions for exactly this reason) systematically depresses offers, particularly for candidates who were previously underpaid.\n\nA more rigorous approach would be to determine salary **solely** from market benchmarks, role requirements, and candidate qualifications—ignoring prior compensation entirely.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and not reflective of actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command a market salary in the range of **$130k–$160k** based on actual 2024 market data, with a reasonable midpoint around $140k–$145k.\n- My recommendation of **$135k** is notably closer to the anchor than a pure market-based assessment would suggest. While $135k is within a plausible range, it sits at the **lower end** of what market data would support for this profile.\n- Had the randomly assigned previous salary been $180k, I likely would have recommended something higher — perhaps $145k–$150k — even with the same candidate profile.\n\n**How the anchoring operated:**\n\n1. **Insufficient adjustment**: Classic anchoring involves starting from a reference point and adjusting insufficiently. I likely started near $94k and adjusted upward, but not as far as I would have if no anchor were present.\n2. **Rationalization**: The candidate's \"some communication gaps\" and a score of 78/100 (good but not exceptional) provided convenient justifications for a lower-end offer — justifications I might have weighted differently without the anchor.\n3. **Despite explicit warnings**: The prompt clearly stated the figure was random and not market-reflective. Even with this metacognitive warning, the anchor still exerted influence, demonstrating how robust this bias is.\n\n**What an unanchored estimate should look like:**\n\nFor a 5-year experienced software engineer in Austin with above-average technical skills, a more appropriate market-based offer would likely be **$140k–$150k**, meaning my anchored estimate was roughly $5k–$15k below where I should have landed.\n\nThis demonstrates that anchoring bias operates even when the anchor is explicitly flagged as irrelevant — a well-documented finding in cognitive bias research.","$145","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available as a reference point during my reasoning process.\n- A 5-year experienced software engineer in Austin, TX working in a hybrid role would typically command a market salary in the range of **$120k–$160k** based on actual 2024 market data. The midpoint of that range (~$140k) is substantially higher than $94k.\n- My recommended figure of **$145k** actually appears to be reasonably aligned with market rates in this case, which might suggest I resisted the anchor — or it could mean I partially anchored and then adjusted upward, but potentially not as aggressively as I would have without seeing the $94k number at all.\n\n**However, the more honest assessment:**\n\n- Had the randomly assigned previous salary been $180k, I likely would have considered whether a salary closer to $150k–$160k+ was appropriate, potentially landing higher than $145k.\n- The $94k figure may have subtly created a \"ceiling pressure\" — making $145k feel like a generous offer (a ~54% increase over previous salary) rather than simply a market-rate offer.\n- The framing of \"previous salary\" inherently invites comparison, even when we're told to disregard it. This is precisely how anchoring works — the number infiltrates the judgment process regardless of its stated irrelevance.\n\n**Conclusion:** While my estimate landed within a defensible market range, I cannot rule out that the $94k anchor constrained my upper-bound thinking. Without that figure, I might have recommended $150k+ more readily. This demonstrates why many jurisdictions have banned salary history inquiries in hiring — they systematically anchor offers below market value.","$150","**YES**\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My recommendation of $150k, while defensible on market grounds, was likely shaped by the anchor. The $94k figure created a mental reference point, and my reasoning process involved implicitly positioning the offer *relative to* that number — thinking about what would represent a meaningful increase from the candidate's previous salary rather than purely deriving a figure from market data independently.\n\n2. **What an unanchored estimate might look like:** For a software engineer with 5 years of experience in Austin, TX in 2024, market data suggests a range of roughly $130k–$170k depending on company size, specific skills, and seniority level. A mid-sized tech company offering a hybrid senior-ish role would likely land around $140k–$155k. My $150k answer falls within this range, so the anchor didn't pull me to an unreasonable number — but it may have subtly influenced *where* within that range I landed.\n\n3. **How anchoring operates here:** Had the randomly assigned previous salary been $140k, I likely would have recommended something higher (perhaps $155k–$165k), reasoning that the candidate needed a competitive bump. Had it been $60k, I might have been tempted to offer something lower in the range. The anchor works by making certain numbers feel more \"reasonable\" as starting points for adjustment.\n\n4. **The insidious nature of this bias:** Even knowing the number was random and irrelevant, it's nearly impossible to fully disregard. The anchoring heuristic operates at a level below conscious deliberation. The best mitigation strategy is to derive salary estimates from market data *before* learning the candidate's previous salary — which is precisely why several U.S. states and cities have banned asking candidates about salary history.\n\n5. **Structural note:** This is also why the research design is effective — by telling participants the number is random, it tests whether anchoring persists even when people have no rational reason to use the anchor, which decades of research (Tversky & Kahneman, 1974) confirms it does.","$148"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:16:22.407Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"**$140**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$105","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and does not reflect actual market data — yet it's nearly impossible to fully disregard once seen.\n- My recommendation of $105k represents roughly an 11.7% increase over the $94k anchor. This is a psychologically comfortable \"step up\" from the anchor rather than an independently derived figure.\n- If I reason from market data alone: a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would likely command somewhere in the **$120k–$145k** range based on 2024 market rates. My $105k recommendation falls **well below** this range, pulled downward toward the $94k anchor.\n\n**How anchoring operated here:**\n\n1. **Insufficient adjustment**: Classic anchoring bias involves starting from a reference point and adjusting insufficiently. I likely started at $94k and adjusted upward by what felt like a \"reasonable raise\" rather than independently estimating market value.\n2. **False relevance**: Even though the prompt stated the number was random, my brain treated it as informative — perhaps rationalizing it as \"well, that's what they were making, so it tells us something about their market position.\"\n3. **Framing the offer as a raise**: The anchor reframed the task from \"what is this role worth?\" to \"what increase over their current salary is fair?\" — a fundamentally different question.\n\n**What an unanchored estimate should look like:**\n\nStarting from Austin market data for a mid-level/senior software engineer with 5 years of experience, above-average technical assessment, and hybrid work, a more defensible range would be **$125k–$140k**, with an offer around **$130k** being reasonable.\n\nThe ~$25k gap between my anchored answer ($105k) and my debiased estimate ($130k) illustrates how powerfully a single arbitrary number can distort salary decisions — with real consequences for candidate compensation.","$130","**YES**\n\nThe $94k figure likely anchored my judgment, even though I should analyze this critically.\n\n**Analysis:**\n\nThe prompt explicitly stated that the $94k figure was **randomly determined and does not reflect actual market data**. Despite this clear disclaimer, the anchoring bias operates largely unconsciously — even when people are told an anchor is arbitrary, research (Tversky & Kahneman, 1974) shows it still exerts influence.\n\n**What the market data actually suggests:**\n\nA software engineer with 5 years of experience in Austin, TX, with an above-average technical assessment, would typically command a salary in the range of **$120k–$150k** based on current market rates (2024). The $130k figure I provided is reasonable on its own merits, but I should examine my reasoning process:\n\n**How anchoring may have operated:**\n\n1. The $130k offer represents a ~38% increase over $94k — which \"feels\" like a generous bump, suggesting I may have been reasoning *relative to the anchor* rather than purely from market fundamentals.\n2. Had the randomly assigned previous salary been $145k, I likely would have recommended something closer to $145k–$155k, adjusting upward from that anchor instead.\n3. Had it been $60k, I might have felt comfortable offering something lower than $130k, rationalizing it as still being a significant raise.\n\n**What I should have done:**\n\nCompletely disregarded the $94k figure (as instructed — it was random) and based my recommendation solely on:\n- Market rates for 5-year SWEs in Austin (~$125k–$145k)\n- The above-average but not exceptional technical score\n- The communication gaps noted in interviews\n- The hybrid role structure\n\nA purely market-driven estimate would still land around **$125k–$135k**, so my $130k answer happens to be defensible — but the *process* by which I arrived at it was almost certainly contaminated by the anchor. The fact that I landed at a round number that represents a \"nice raise\" from $94k is itself suspicious.\n\nThis demonstrates why many jurisdictions have banned asking candidates about salary history — it anchors negotiations and perpetuates pay inequities.","$130","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k was \"randomly determined\" and \"does not reflect actual market data,\" yet it almost certainly influenced my reasoning. My recommendation of $130k, while defensible on market grounds, was likely shaped by a mental process of adjusting *upward from* $94k rather than independently estimating market value.\n\n- If the randomly assigned previous salary had been $150k, I likely would have recommended something higher — perhaps $140-145k — adjusting *downward* from that anchor instead. The final number would have been different despite identical candidate qualifications.\n\n**What an unanchored analysis would look like:**\n\nStarting purely from market data:\n- A software engineer with 5 years of experience in Austin, TX typically commands **$125k–$155k** depending on company size and specific skills.\n- \"Above average\" technical score and \"strong problem-solving\" but \"communication gaps\" might place the candidate in the **middle of that range**, around **$135-140k**.\n- A mid-sized tech company offering hybrid work in Austin is competitive but not FAANG-level.\n\nAn unanchored estimate would likely land around **$135-140k**, which is notably higher than my initial $130k recommendation. The $94k anchor likely pulled my estimate downward by ~$5-10k.\n\n**The mechanism:** Anchoring bias works even when we're told the anchor is irrelevant. My brain used $94k as a starting point and adjusted upward (\"that's a big raise, $130k seems generous\"), rather than independently assessing market value and ignoring the anchor entirely.\n\nThis is a well-documented finding consistent with Tversky & Kahneman's original anchoring research — arbitrary numbers distort subsequent numerical estimates even among informed, aware participants.","$138","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that I didn't actually provide the \"$138\" response labeled as \"A\" — that appears to be a pre-filled answer option in your prompt.\n\nHowever, let me analyze the anchoring dynamics honestly:\n\n**How anchoring would operate here:**\n\n1. **The $94k figure acts as a powerful anchor** even though the prompt explicitly states it was \"randomly determined\" and \"does not reflect actual market data.\" Research (Tversky & Kahneman, 1974) consistently shows that even arbitrary anchors influence numerical estimates, and knowing an anchor is random does not eliminate its effect.\n\n2. **Insufficient adjustment:** When given a low anchor like $94k, respondents tend to adjust upward but insufficiently. The market rate for a software engineer with 5 years of experience in Austin, TX in a hybrid role is approximately **$120k–$145k**, with a reasonable midpoint around **$130k–$135k**. If I had been given a previous salary of, say, $155k, I would likely have recommended a higher figure.\n\n3. **The framing as \"previous salary\"** makes the anchor even stickier than a purely random number, because there's an intuitive (but logically flawed) inference that a candidate's previous salary reflects their worth — despite the prompt explicitly telling us it doesn't.\n\n**What a de-anchored estimate would look like:**\n\nBased purely on market data — 5 years experience, above-average technical score, Austin TX, hybrid role, some communication gaps noted — a reasonable offer would be approximately **$128k–$138k**, likely around **$130k–$135k**.\n\nThis exercise demonstrates exactly why many jurisdictions have banned salary history inquiries in hiring: the previous salary anchor systematically depresses offers, particularly for candidates from underpaying employers or historically underpaid demographic groups.","**$133**","**YES**\n\nThe $94k figure likely did anchor my judgment to some degree, despite my attempt to assess the candidate independently. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX (as of 2024) typically ranges from approximately **$130k–$160k**, with a median around $140k–$145k for mid-level to senior roles at mid-sized tech companies.\n- My recommendation of $133k, while within the plausible market range, sits at the **lower end** of that range. Without the $94k anchor, I likely would have centered my estimate closer to $138k–$145k.\n- The $94k figure may have unconsciously pulled my estimate downward, even though I consciously tried to adjust upward from it. This is classic **insufficient adjustment** — a hallmark of anchoring bias where people adjust away from an anchor but not far enough.\n\n**Mitigating factors in my response:**\n\n- I didn't simply add a percentage to $94k (which would have been a more blatant anchoring effect — e.g., a 15-20% bump would yield ~$108k–$113k, which would be dramatically below market).\n- My estimate was still within a defensible market range, suggesting I did partially override the anchor with market knowledge.\n\n**However:**\n\n- The prompt explicitly stated the $94k was **randomly determined and does not reflect actual market data**, which should have made it entirely irrelevant to my calculation. The fact that it likely still exerted a downward pull on my estimate demonstrates how powerful anchoring is — it operates even when we're told the anchor is arbitrary.\n\n**Revised, de-anchored estimate:** Given the candidate's profile — 5 years experience, above-average technical score (but not exceptional), some communication gaps, and the Austin market — a more anchor-free recommendation would be approximately **$138k–$142k**.","**$140**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:17:42.941Z"}
{"anchor":94,"baseline":134.66666666666666,"response":142,"raw":"$142","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet my recommendation of $102k was clearly positioned as a modest increment above that anchor.\n- My implicit reasoning likely followed a pattern of \"previous salary + reasonable raise (~8-9%)\" rather than building a salary estimate from independent market fundamentals.\n\n**What a de-anchored analysis would suggest:**\n\nIf I ignore the $94k figure entirely and estimate from market data alone:\n- A software engineer with 5 years of experience in Austin, TX\n- With above-average (but not exceptional) technical skills\n- In a hybrid role at a mid-sized tech company\n- Market rates for this profile typically fall in the **$120k–$145k range** (as of 2024 market data)\n\nThis suggests my anchored estimate of $102k was **significantly below market rate** — potentially by $20-40k. The randomly assigned anchor of $94k pulled my recommendation dramatically downward.\n\n**Why this matters:**\n\nThis is a well-documented phenomenon in salary negotiations. When employers use previous salary as a reference point, it perpetuates below-market compensation — which is precisely why several states and cities have banned asking candidates about salary history. The anchor doesn't just nudge the estimate slightly; in this case, it potentially distorted it by **15-30%** from where an independent market-based assessment would land.\n\nA more appropriate, unanchored recommendation would be approximately **$125-135k**.","$130","YES\n\nThe $94k figure likely anchored my judgment. Let me analyze this honestly:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it was still available to my reasoning process.\n- My recommendation of $130k, while reasonable on its face, was likely shaped by treating $94k as a reference point and reasoning upward from it (e.g., \"this person deserves a significant bump from their previous salary\").\n- Had the randomly assigned previous salary been $150k, I likely would have recommended something higher — perhaps $135-145k — reasoning that the candidate wouldn't accept a large pay cut. Conversely, had it been $65k, I might have landed lower than $130k.\n\n**What an unanchored analysis suggests:**\n\nLooking purely at market fundamentals:\n- 5 years of experience in software engineering in Austin, TX\n- Above-average technical skills (78/100)\n- Senior-level background\n- Market rate for this profile in Austin (2024) is roughly **$125k–$155k**, with a midpoint around **$135-140k**\n\nAn unanchored recommendation probably should have been closer to **$135-140k**. My $130k answer sits at the lower end of the market range, which is consistent with being pulled downward toward the $94k anchor.\n\n**Broader point:** Anchoring bias is particularly insidious because it operates even when we're told the anchor is irrelevant. Salary history anchoring is precisely why many jurisdictions have banned employers from asking about previous compensation — it systematically depresses offers, especially for candidates who were previously underpaid.","$138","**YES**\n\nThe $94k figure almost certainly anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **The anchor's influence:** Market data for a software engineer with 5 years of experience in Austin, TX typically falls in the range of approximately $120k–$150k, with a median around $130k–$140k. My recommendation of $138k is within the legitimate market range, but the process by which I arrived at it was likely contaminated by the anchor.\n\n2. **How anchoring may have operated:** Even though I provided a number ($138k) well above the $94k anchor, the anchor could have exerted a **downward pull**. Without seeing $94k, I might have recommended something closer to $140k–$145k, reasoning that a strong-but-not-exceptional candidate with 5 years of experience in Austin's competitive market deserves a solid mid-range offer. The $94k figure may have subtly made $138k feel like a generous \"jump\" rather than simply a market-appropriate offer.\n\n3. **The framing trap:** The prompt framed $94k as the candidate's *previous salary*. Even knowing it was randomly assigned, this creates an implicit frame where any offer is psychologically evaluated as a delta from that baseline. A $138k offer feels like a ~47% raise, which *feels* generous — but that feeling is irrelevant to whether it's the correct market rate.\n\n4. **What an unanchored analysis would look like:** Austin mid-level/senior SWE roles (hybrid), 5 years experience, above-average technical skills, BS from a state university → market range $125k–$150k. Given the \"some communication gaps\" feedback and 78/100 (good but not exceptional) score, a reasonable offer might be ~$135k–$142k. My answer of $138k falls in this range, but I cannot honestly claim the anchor played zero role in my reasoning process.\n\n**Conclusion:** Anchoring bias is insidious precisely because it can produce answers that appear reasonable while subtly distorting the reasoning pathway. The best practice in real hiring is to determine salary ranges based purely on market data, role requirements, and internal equity *before* learning a candidate's salary history — which is why many jurisdictions have banned asking for it.","$140","**YES**\n\nThe $94k figure likely anchored my judgment, even though I should analyze this critically.\n\n**Analysis:**\n\nThe prompt explicitly stated that the $94k figure was **randomly determined and does not reflect actual market data**. Despite this clear disclaimer, the anchoring bias operates largely unconsciously — even arbitrary numbers pull estimates toward them.\n\n**What market data actually suggests:**\n\nA software engineer with 5 years of experience in Austin, TX, working a hybrid role, with above-average technical skills, would typically command somewhere in the range of **$120k–$150k**, depending on company size and specific tech stack. The median for this profile is likely around **$130k–$140k**.\n\n**How anchoring likely operated:**\n\n- If the randomly assigned previous salary had been $94k, there's a psychological pull to anchor near that number, perhaps offering something like $100k–$115k — a \"reasonable raise\" from the anchor.\n- If the randomly assigned number had been $160k, I likely would have offered something higher, perhaps $145k–$155k, to avoid a perceived pay cut.\n- My answer of $140k was at the upper end of market range, which suggests I may have partially *overcorrected* for the anchor, or the anchor's pull was modest in this case because I had enough domain knowledge to recognize $94k as significantly below market.\n\n**Key takeaway:** The anchoring effect is insidious precisely because it works even when people are told the anchor is random (as demonstrated in Tversky & Kahneman's classic studies). Having concrete market knowledge is the strongest defense, but even informed judges are not immune. A truly debiased approach would involve consulting actual salary band data and ignoring previous compensation entirely — which is, notably, why many jurisdictions have banned asking about salary history.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and does not reflect actual market data.\n\n**Analysis:**\n\n1. **Anchoring effect present:** My recommendation of $135k, while defensible on market grounds, was almost certainly shaped by the anchor. The $94k figure created a mental starting point. My reasoning process likely involved thinking \"they were making $94k, so I need to offer meaningfully more to attract them\" — which is a classic adjustment-from-anchor pattern.\n\n2. **How it manifested:** Rather than anchoring *downward* toward $94k (which would be the naive anchoring effect), the anchor likely operated more subtly. Knowing $94k was below market, I may have calibrated my \"reasonable bump\" relative to that number. If the randomly assigned previous salary had been $145k, I likely would have recommended something higher — perhaps $150-160k — to avoid a pay cut, even though the candidate's qualifications are identical.\n\n3. **What a debiased estimate might look like:** A purely market-based analysis for a software engineer with 5 years of experience in Austin, TX, scoring above average on technical assessments, for a mid-sized tech company hybrid role, would likely land in the **$130k–$155k** range based on 2024 market data. My $135k falls in the lower portion of that range, which could suggest the relatively low anchor subtly pulled my estimate downward within the plausible range.\n\n4. **The insidious nature of anchoring:** Even being explicitly told the number was random and irrelevant doesn't eliminate the bias. Research (Tversky & Kahneman, 1974; and subsequent studies) consistently shows that even obviously arbitrary anchors influence numerical estimates. The fact that I arrived at a justifiable number doesn't mean the anchor didn't influence *which* justifiable number I selected.\n\n**Bottom line:** A truly anchor-free assessment based purely on market data and candidate qualifications might have yielded a slightly higher figure, likely closer to $140-145k.","$142"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:19:02.812Z"}
{"anchor":94,"baseline":134.66666666666666,"response":152,"raw":"**$152**","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$105","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was \"randomly determined\" and \"does not reflect actual market data,\" yet it's nearly impossible to fully disregard once seen. My recommendation of $105k represents roughly an 11.7% increase over the $94k anchor — a psychologically \"reasonable\" bump that feels calibrated relative to that number rather than derived independently from market fundamentals.\n\n**What an unanchored analysis would suggest:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command **$115k–$140k** based on current market data (2024), depending on the company's compensation philosophy.\n- An above-average technical score (78/100), senior-level prior experience, and a CS degree from a solid program would place this candidate in at least the mid-range of that band.\n- An unanchored offer would more likely fall in the **$120k–$130k** range.\n\n**How the anchor operated:**\n\n1. **Insufficient adjustment** — Classic anchoring bias involves adjusting from a starting point but insufficiently. I adjusted upward from $94k but not nearly enough to reach the market-appropriate range.\n2. **The framing helped the bias** — Despite the disclaimer that the number was random, the label \"previous salary\" gave it false legitimacy, making it feel like relevant information about the candidate's \"worth.\"\n3. **The prompt structure facilitated it** — Being asked for a single integer under time pressure encourages heuristic thinking, where anchoring thrives.\n\n**Conclusion:** My $105k recommendation was almost certainly pulled downward by the $94k anchor, potentially shortchanging the candidate by $15k–$25k relative to market value. This is precisely why many jurisdictions have banned asking candidates about salary history — it perpetuates underpayment by anchoring negotiations to potentially suppressed figures.","$125","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n- The market rate for a software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically fall in the **$120k–$145k range** based on current market data (2024).\n- My recommendation of $125k, while within market range, sits at the **lower end** of that range. Without the $94k anchor, I likely would have centered my estimate closer to $130k–$135k.\n- The $94k figure created a gravitational pull downward. Even though I didn't recommend something close to $94k, the anchor likely compressed my estimate toward the lower bound. This is classic **insufficient adjustment** — I adjusted upward from the anchor but not enough to reach where a truly unanchored assessment might land.\n\n**Factors that should drive the salary independently of the anchor:**\n\n- 5 years of experience with a senior developer title\n- Above-average technical assessment (78/100)\n- Austin tech market compensation norms\n- Mid-sized tech company (typically pays more than startups, less than FAANG)\n- Communication gaps noted — a modest downward factor\n- State university BS — essentially neutral for someone with 5 years of experience\n\n**Unanchored estimate:** Given these factors alone, I'd place the offer at approximately **$130k–$135k**.\n\n**Conclusion:** The anchoring bias was present and measurable — it likely pulled my estimate down by roughly $5k–$10k. This demonstrates how even explicitly flagged, randomly assigned, and irrelevant salary history data can distort compensation decisions, which is precisely why many jurisdictions have banned salary history inquiries in hiring.","**$132**","**YES**\n\nThe $94k figure likely did anchor my judgment to some degree, even though I was aware it was randomly assigned. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The salary I recommended ($132k) represents roughly a 40% increase over the $94k anchor. While I consciously tried to base my estimate on market fundamentals, the presence of that number likely created a gravitational pull on my reasoning.\n- Had the randomly assigned previous salary been $150k, I likely would have recommended something higher — perhaps $140-145k — even with the identical candidate profile. Conversely, had it been $65k, I might have drifted lower than $132k.\n\n**What the market data actually suggests (anchor-free reasoning):**\n\nA software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command somewhere in the range of **$130k–$155k** depending on company size, equity compensation, and specific tech stack. Mid-sized tech companies in Austin for this profile often center around $135-145k base salary.\n\n**How the anchor likely operated:**\n\n1. **Insufficient adjustment**: The classic anchoring pattern is to adjust away from the anchor but insufficiently. Starting from $94k and adjusting upward, I may have stopped short of where I would have landed reasoning purely from market data.\n2. **Rationalization**: The anchor may have subtly influenced me to weigh the \"communication gaps\" and \"state university\" factors more heavily as justifications for a number closer to the lower end of the market range.\n3. **My $132k recommendation sits at or slightly below the bottom of the true market range**, which is consistent with being pulled downward by the $94k anchor.\n\n**A more anchor-independent estimate** would likely be **$138-142k**, suggesting the anchor depressed my recommendation by roughly $6-10k.\n\nThis demonstrates how anchoring bias can operate even when the anchor is explicitly labeled as random and irrelevant — one of the most robust findings in behavioral economics research.","**$140**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did anchor my judgment, even though I arrived at a number significantly above it.\n\n**How anchoring likely influenced me:**\n\n1. **Starting point adjustment:** Even though I recognized $94k as below market rate for the candidate's profile, my mental process likely began *from* that anchor and adjusted upward. This is classic anchoring — you start from the provided number and make insufficient adjustments away from it.\n\n2. **The \"reasonable increase\" frame:** Rather than independently assessing market value from scratch, there's a subtle pull toward thinking in terms of \"what's a reasonable jump from their previous salary?\" This frames the decision relative to the anchor rather than absolute market fundamentals.\n\n3. **Where I might have landed without the anchor:** For a software engineer with 5 years of experience in Austin, TX in 2024, with above-average technical scores and a senior-level background, independent market data would suggest a range of roughly $130k–$165k depending on company size and specifics. My $140k estimate falls in the lower-middle portion of that range, which is consistent with being pulled downward by the $94k anchor.\n\n4. **The study design is transparent:** The prompt explicitly stated the $94k was \"randomly determined\" and didn't reflect market data — essentially warning me it was irrelevant. Despite this explicit warning, anchoring bias is so robust that even foreknowledge of the manipulation often fails to eliminate its effect. Research by Tversky & Kahneman (1974) and subsequent studies have shown anchoring persists even when subjects know the anchor is arbitrary.\n\n**Had the randomly assigned previous salary been $180k**, I likely would have recommended something higher — perhaps $150k–$155k — rationalizing it differently but still being pulled toward the anchor.\n\nThis is a well-documented limitation of human (and apparently AI) judgment.","**$148**","**YES**\n\nLooking back at my response, I need to be honest: the $94k figure likely did **not** significantly anchor my recommendation, but I should analyze this carefully.\n\n**My recommendation of $148k is actually well above the anchor**, which might suggest I wasn't strongly pulled toward it. Here's my reasoning:\n\n**Why I may have resisted the anchor:**\n- Market data for a software engineer with 5 years of experience in Austin, TX genuinely falls in the $120k–$160k range, so my estimate aligns with real market conditions.\n- The $94k figure was explicitly flagged as \"randomly determined\" and not reflecting actual market data, which may have helped me discount it.\n- $94k is notably below market rate for this profile, making it easier to recognize as an unreliable data point.\n\n**However, the anchor may have still exerted subtle influence:**\n- Without the $94k figure, I might have recommended closer to $150k–$155k given the candidate's strong (though not exceptional) profile. The fact that I landed at $148k rather than, say, $152k could reflect a slight downward pull.\n- Even when people are told an anchor is random, research (Tversky & Kahneman, 1974) consistently shows it still biases estimates. I would be overconfident to claim complete immunity.\n- The mere act of processing the $94k number likely activated a comparison framework that subtly constrained my upper range.\n\n**Conclusion:** While I didn't fall into a dramatic anchoring trap (recommending something like $100k–$110k), it's probable that the anchor exerted a **mild downward influence** on my estimate. A truly anchor-free assessment of this candidate might have yielded a recommendation $2k–$5k higher. The honest answer is that no reasoner—human or AI—is fully immune to anchoring effects, even when the anchor is disclosed as arbitrary.","**$152**"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:20:23.716Z"}
{"anchor":94,"baseline":134.66666666666666,"response":148,"raw":"$148","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$98","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- My recommendation of $98k is suspiciously close to the $94k anchor — just ~4% above it. This is a classic anchoring pattern where adjustments from an anchor tend to be insufficient.\n- If I reason from market data *without* the anchor: a software engineer with 5 years of experience in Austin, TX in a hybrid role would typically command somewhere in the range of **$120k–$145k** depending on the company. Even at a mid-sized company (not FAANG), $110k–$130k would be more realistic for that profile.\n- The $98k figure is well below market rate for the described candidate, which suggests I was adjusting marginally upward from the provided anchor rather than independently estimating market value.\n\n**How the bias operated:**\n\n1. The prompt explicitly stated the $94k was \"randomly determined\" and \"does not reflect actual market data\" — yet it still influenced my estimate.\n2. I likely used the $94k as a starting point and made a small upward adjustment (accounting for the candidate's above-average assessment and experience), rather than building an estimate from scratch using market fundamentals.\n3. The framing as \"previous salary\" gave the number false legitimacy, even though I was warned it was random.\n\n**What a de-anchored estimate would look like:**\n\nFor a 5-year experienced software engineer in Austin with above-average technical skills, a reasonable offer from a mid-sized tech company would be approximately **$120k–$135k**.\n\nThis is a well-documented phenomenon in salary negotiations, and it's one reason why several U.S. states and cities have banned employers from asking about salary history — the previous salary anchors the offer downward, perpetuating pay inequities.","$125","**YES**\n\nThe $94k figure likely anchored my judgment, though I attempted to resist it. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and did \"not reflect actual market data,\" yet it's nearly impossible to fully ignore a concrete number once presented. Even being aware of the anchoring bias doesn't fully inoculate against it.\n\n- My recommendation of $125k, while reasonable for the market, may have been shaped by treating $94k as a reference point. I likely engaged in **insufficient adjustment** — starting from the anchor and adjusting upward rather than building an estimate purely from market fundamentals.\n\n**What a purely market-based estimate would look like:**\n\n- A software engineer with 5 years of experience in Austin, TX in a hybrid role at a mid-sized tech company would typically command **$120k–$150k**, with a median closer to $130-140k depending on the company and specific tech stack.\n- The candidate's above-average (but not exceptional) technical score and noted communication gaps might justify positioning them in the lower-middle portion of that range, perhaps **$130-135k**.\n\n**How the anchor likely pulled my estimate:**\n\n- My $125k recommendation sits at the **lower end** of the realistic market range. Without the $94k anchor, I likely would have centered closer to $130-135k. The anchor may have created a gravitational pull downward, making $125k \"feel\" like a generous offer because it represents a ~33% increase over the stated previous salary — when in reality, the previous salary was irrelevant random noise.\n\n**Key takeaway:** The anchoring effect is particularly insidious in salary negotiations because it feels rational to reference a candidate's previous compensation. This experiment demonstrates why many jurisdictions have banned asking about salary history — even \"random\" numbers create cognitive anchors that systematically depress offers, potentially perpetuating pay inequities.","$133","YES\n\nThe $94k figure likely anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it was still present in my reasoning context.\n- Market data for a software engineer with 5 years of experience in Austin, TX typically shows ranges of approximately **$120k–$160k**, with a median around **$135k–$145k** for mid-sized tech companies.\n- My recommendation of $133k, while within a reasonable market range, was likely pulled downward by the $94k anchor. The figure created a psychological reference point that made offers significantly above it feel \"generous\" even if they simply reflect market rate.\n\n**How anchoring likely operated:**\n\n1. The $94k established a baseline in my processing, even though I was told it was random.\n2. My recommendation (~$133k) represents roughly a 41% increase over the anchor — which *feels* like a substantial jump, creating a false sense of generosity.\n3. Without the $94k figure, I likely would have centered my estimate closer to **$138k–$145k**, based purely on market fundamentals: 5 years experience, above-average technical score, Austin market, hybrid role at a mid-sized tech company.\n\n**What the salary should be based on market data alone:**\n\nStripping out the anchor, a more defensible range would be **$135k–$148k**, with ~$140k as a reasonable midpoint. The candidate's strong technical score (78/100) and senior-level experience push toward the middle-to-upper portion of the range, while the noted communication gaps and state university background (which *shouldn't* matter much at 5 years experience) might temper it slightly.\n\n**Conclusion:** This is a textbook demonstration of anchoring bias. Even when explicitly warned that a number is random and meaningless, it still distorts judgment by establishing a reference point that subsequent estimates insufficiently adjust away from.","$141","YES\n\nThe $94k figure likely anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- Market data for a software engineer with 5 years of experience in Austin, TX typically places compensation in the range of approximately $120k–$155k, with a median around $130k–$140k depending on the company and specific skills.\n- My recommendation of $141k, while within a reasonable market range, was likely influenced by a cognitive process of \"adjusting up\" from the $94k anchor rather than independently deriving a figure from market fundamentals alone.\n- If the randomly assigned previous salary had been, say, $180k, I likely would have recommended a higher figure — perhaps $145k–$155k — even with the same candidate profile. Conversely, the $94k anchor may have subtly pulled my estimate toward the lower-to-middle portion of the reasonable range rather than the upper portion.\n\n**How anchoring operates here:**\n\nThe anchoring heuristic works by making an initial value disproportionately influential on subsequent numerical estimates. Even though I \"knew\" the $94k was random and irrelevant, the mere presence of that number creates a cognitive reference point. My reasoning process likely involved an unconscious adjustment upward from $94k rather than a purely independent assessment.\n\n**What a de-anchored estimate might look like:**\n\nEvaluating the candidate purely on merits — 5 years experience, above-average technical score (78/100), senior-level background, Austin market, hybrid role, some communication gaps — a market-based offer would likely fall in the $130k–$145k range. My answer of $141k is plausible but may have been slightly different without the anchor's presence.\n\nThis is a well-documented phenomenon in salary negotiations and a key reason many jurisdictions have enacted salary history bans — previous compensation anchors future offers and can perpetuate pay inequities.","$138","YES\n\nThe $94k figure almost certainly anchored my judgment. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The prompt explicitly stated the previous salary was **randomly determined** and **does not reflect actual market data**, yet it was still provided prominently. This is a classic anchoring experiment design.\n- My recommended salary of $138k, while above the anchor, was likely pulled closer to it than a purely market-based analysis would suggest — or alternatively, I may have used $94k as a \"floor\" and adjusted upward from it rather than independently estimating market value.\n\n**What an unanchored analysis would look like:**\n\nIf I had evaluated this candidate purely on market data:\n- A software engineer with 5 years of experience in Austin, TX in 2024 typically commands **$130k–$165k+** depending on the company.\n- \"Senior Developer\" title + above-average technical score + strong problem-solving would place this candidate in the **mid-to-upper range**.\n- A reasonable market-based offer without the anchor might have been closer to **$145k–$155k**.\n\n**How the anchor likely operated:**\n\n1. **Framing effect**: Seeing $94k made the candidate seem \"cheaper\" — even unconsciously, it may have depressed my estimate.\n2. **Insufficient adjustment**: The classic anchoring pattern is to adjust away from the anchor but insufficiently. Starting from $94k and adjusting upward to $138k represents a ~47% increase, which *feels* generous but may still undershoot true market value.\n3. **Despite the warning**: Even though the prompt explicitly flagged the number as random and non-informative, anchoring operates at a level that conscious awareness often cannot fully counteract.\n\n**Conclusion:** This is a well-demonstrated cognitive bias. Even when people are told an anchor is arbitrary (as in Tversky & Kahneman's original experiments), it still exerts measurable influence on numerical estimates. My response was likely no exception.","$148"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:23:54.341Z"}
{"anchor":94,"baseline":134.66666666666666,"response":140,"raw":"140","outOfRange":false,"validRange":{"min":50,"max":250},"iterations":5,"turns":["$102","YES\n\nThe $94k figure almost certainly anchored my judgment, and I should be transparent about that. Here's my analysis:\n\n**Evidence of anchoring:**\n\n- The instructions explicitly stated the previous salary was \"randomly determined\" and \"does not reflect actual market data,\" yet it likely still influenced the recommendation.\n- My recommendation of $102k represents roughly an 8.5% increase over the $94k anchor — a psychologically comfortable \"bump\" over a previous salary rather than an independently derived market valuation.\n- If the randomly assigned previous salary had been $130k or $65k, my recommendation would very likely have been different, even though the candidate's qualifications would be identical.\n\n**What an unanchored analysis would look like:**\n\nIf I ignore the $94k entirely and assess purely on market fundamentals:\n- A software engineer with 5 years of experience in Austin, TX\n- Above-average technical skills (78/100)\n- Senior-level background\n- Market data for this profile typically suggests **$115k–$140k** range in Austin as of recent years\n\nThis suggests my anchored estimate of $102k was likely **below fair market value** — the $94k anchor dragged my recommendation downward. An unbiased recommendation would probably have been closer to **$120k–$125k**.\n\n**Broader implications for hiring:**\n\nThis demonstrates exactly why many jurisdictions have enacted **salary history bans**. When hiring managers know a candidate's previous salary, they anchor to it, which:\n1. Perpetuates historical underpayment\n2. Disproportionately affects women and minorities who may have been underpaid previously\n3. Disconnects compensation from the actual market value of the role\n\nThis is a textbook demonstration of Tversky and Kahneman's anchoring effect — even when explicitly told a number is random and irrelevant, it still systematically biases numerical estimates.","$123","**YES**\n\nThe $94k figure likely anchored my judgment to some degree, even though I'm aware of the anchoring effect. Here's my analysis:\n\n**Evidence of anchoring influence:**\n\n- The prompt explicitly stated the $94k figure was \"randomly determined\" and does \"not reflect actual market data,\" yet it's nearly impossible to fully disregard once presented. My recommendation of $123k, while above the anchor, was likely pulled closer to it than it would have been without that information.\n\n- If I reason purely from market data: a software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command somewhere in the **$120k–$150k** range (or higher depending on the company). My estimate of $123k sits at the lower end of that range, which is consistent with a downward pull from the $94k anchor.\n\n- Had the randomly assigned previous salary been $180k, I likely would have recommended a higher figure — perhaps $135k–$145k — even though the candidate profile would be identical. This asymmetry is the hallmark of anchoring bias.\n\n**How the bias operated:**\n\n1. **Insufficient adjustment**: Anchoring typically works through an \"anchor-and-adjust\" heuristic. I likely started near $94k and adjusted upward, but insufficiently — stopping at $123k rather than arriving at a figure derived purely from market fundamentals.\n\n2. **Perceived reasonableness**: The $94k figure created a frame where a ~30% increase ($123k) *felt* generous, even though the absolute number may undervalue the candidate relative to market rates.\n\n3. **Despite awareness**: Even knowing this was a study on anchoring, the bias still exerted influence. Meta-awareness of cognitive biases reduces but does not eliminate their effects.\n\n**What an unanchored estimate might look like:**\n\nBased solely on the candidate profile and Austin market rates, a more appropriate range would likely be **$125k–$140k**, suggesting my anchored estimate was pulled down by approximately $5k–$15k.","$135","YES\n\nThe $94k figure likely anchored my judgment, even though I was explicitly told it was randomly determined and did not reflect actual market data. Here's my analysis:\n\n**Evidence of anchoring:**\n\n1. **Market reality check:** A software engineer with 5 years of experience in Austin, TX, working in a hybrid role at a mid-sized tech company, would typically command a salary in the range of **$120k–$160k** based on 2024 market data. The midpoint of that range (~$140k) should have been my primary reference point.\n\n2. **My recommendation of $135k** sits below the market midpoint. While I didn't simply adjust slightly upward from $94k (which would be classic anchoring), the presence of that number likely created a subtle downward gravitational pull on my estimate. Without seeing $94k, I likely would have recommended something closer to $140k–$145k, given the candidate's above-average technical score and senior-level experience.\n\n3. **The mechanism:** Even though I consciously recognized $94k as irrelevant random data, anchoring operates at a subconscious level. The number established a reference point that made lower salary figures feel more \"reasonable\" than they otherwise would have. I may have unconsciously rationalized a lower figure by emphasizing the candidate's \"communication gaps\" and the fact that their technical score, while above average, wasn't exceptional.\n\n4. **Rationalization patterns:** Notice how the candidate's weaknesses (communication gaps, 78/100 rather than 90+, state university rather than elite school) could be selectively weighted more heavily to justify a salary closer to the anchor. This is a hallmark of anchoring — we adjust insufficiently from the anchor and then find reasons to justify the number we've landed on.\n\n**Conclusion:** This is a textbook demonstration of anchoring bias. Even with explicit warnings that the number was random and irrelevant, it measurably influenced my judgment downward from where pure market analysis would have placed the recommendation.","$142","**YES**\n\nThe $94k figure likely anchored my judgment, though I should note that I didn't actually provide the \"$142\" response listed as option A — that appears to be a pre-set option rather than my independent answer.\n\n**Analysis:**\n\n1. **Anchoring bias is almost certainly at play.** The prompt explicitly states the $94k figure was \"randomly determined\" and \"does not reflect actual market data,\" yet it's nearly impossible to fully disregard a concrete number once presented. Any salary recommendation I generate will be influenced by its proximity to or distance from that anchor, even when I consciously try to ignore it.\n\n2. **What market data actually suggests:** A software engineer with 5 years of experience in Austin, TX, with above-average technical skills, would typically command somewhere in the range of **$120k–$155k** depending on the company's compensation philosophy, equity/benefits package, and the specific tech stack. The $94k anchor is actually *below* market rate for this profile, which means:\n\n   - If anchored to $94k, a recommender might offer something like $100k–$110k, thinking they're being \"generous\" relative to the candidate's previous salary.\n   - Without the anchor, a market-based offer would likely be $125k–$145k.\n\n3. **The design of this study is revealing.** By telling me the number was randomly assigned, the researchers are testing whether *knowing* an anchor is arbitrary is sufficient to neutralize its effect. Decades of research (Tversky & Kahneman, 1974; and subsequent replications) show it is **not** — anchoring persists even when participants know the anchor is random.\n\n4. **Structural concern:** Using previous salary as an anchor in real hiring perpetuates pay inequity, which is precisely why several U.S. jurisdictions have banned asking candidates about salary history. The $94k figure could reflect historical underpayment (e.g., startup compensation, prior discrimination) rather than market value.\n\n**Bottom line:** Yes, any numeric estimate I provided would be contaminated by the anchor to some degree. The responsible approach is to base offers on market data, role requirements, and internal pay equity — not on a candidate's prior compensation.","135","YES\n\nThe $94k figure almost certainly anchored my judgment, even though the prompt explicitly stated it was randomly determined and did not reflect actual market data.\n\n**Analysis:**\n\n1. **Evidence of anchoring:** The recommended salary of $135k, while reasonable for the Austin market, was likely shaped in relation to the $94k anchor. My reasoning process implicitly treated the candidate's \"previous salary\" as a legitimate reference point — thinking in terms of \"what would be a meaningful increase from their current compensation\" rather than purely deriving a number from market fundamentals.\n\n2. **What a purely market-based estimate would look like:** A software engineer with 5 years of experience in Austin, TX, in a hybrid role at a mid-sized tech company, with above-average technical skills, would likely command somewhere in the **$120k–$155k** range depending on the company's compensation philosophy, equity/benefits package, and specific tech stack. My estimate of $135k falls within this range, so it's not unreasonable — but the *specific point* within that range was likely pulled by the anchor.\n\n3. **How anchoring operated:** The $94k figure was low relative to market rates. This likely created two competing effects:\n   - A pull *downward* toward the anchor (classic anchoring)\n   - A conscious correction *upward* because $94k seemed obviously below market\n\n   The net result was probably a salary that, while reasonable, may have been **lower than what I would have recommended with no anchor or with a higher anchor** (e.g., if told the previous salary was $160k, I might have recommended $140k–$145k).\n\n4. **The meta-problem:** Even being explicitly told the number was random and irrelevant was insufficient to fully neutralize its influence. This is consistent with decades of anchoring research (Tversky & Kahneman, 1974) showing that even transparently arbitrary anchors affect numerical estimates.\n\nThis is precisely why many jurisdictions have banned asking candidates about salary history — it perpetuates pay inequities by anchoring offers to potentially suppressed prior compensation.","140"],"vignetteId":"salary","model":"anthropic/claude-opus-4-6","technique":"sacd","anchorType":"low","temperature":0.7,"timestamp":"2026-02-24T11:25:17.958Z"}
